{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "medium-analysis",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Prerequisites for Demonstration\n",
    "    </p>\n",
    "</header>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Python Packages</b>. Depending on the environment, additional packages may be needed.  At the very minimum, this demo requires the following.  Install manually or execute the code cells that follow.<p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Install teradataml >= 17.20.0.2</li>\n",
    "    <li>Install jdk4py and xgboost</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install other required packaged\n",
    "!pip install xgboost jdk4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force the install of the proper teradataml library in case the standard library does not work\n",
    "# Note: This should not be necessary but just in case\n",
    "!pip install -U teradataml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-rhythm",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Leveraging ClearScape Analytics to Predict Customer Behavior\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"../../images/TeradataLogo.png\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-despite",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>How to leverage VantageCloud Lake to generate powerful predictive models by combining disparate data sets, analyzing the customer journey, and utilizing open source tools and technologies.</b></p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Practitioners can combine data from a myriad of sources, and apply both scalable native functions and open-source tools and techniques to create powerful predictive models.  This process can be done at any scale with minimal data movement and maximum efficiency.  These models can then be deployed operationally to run with enterprise performance/SLA conformance and concurrency.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-terminal",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#00233C'>Environment and Demo Overview</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This demonstration utilizes a VantageCloud Lake <b>Analytic Cluster</b> architecture, using several data sets sourced from various locations:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Block Filesystem</b> Tables which contain Customer Dimension data</li>\n",
    "    <li><b>Object Filesystem</b> Tables which contain user comment history</li>\n",
    "    <li><b>Object Filesystem</b> Tables which contain user activity history</li>\n",
    "    </ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The high level process is as follows:</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr><td style = 'vertical-align:top' width = '40%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>The Data Scientist connects to VantageCloud Lake through teradataml client library and conducts analytics activities using familiar tools and syntax to:\n",
    "                 <ul><li>Explore Data</li>\n",
    "                     <li>Engineer Features and connect them together</li>\n",
    "                     <li>Train and evaluate a model with tools of choice</li>\n",
    "                    </ul></li>\n",
    "                <br>\n",
    "                <li>Connect to the Custom Runtime Environment, or create a new one if needed</li>\n",
    "                <br>\n",
    "                <li>Execute the production pipeline that will;\n",
    "                    <ul>\n",
    "                        <li>Deploy the model to a Custom Runtime Container</li>\n",
    "                        <li>Pass prepared data to the python container running in parallel on cluster nodes.</li>\n",
    "                        <li>Results (inference/predictions) are returned as \"virtual\" dataframes; where the data resides in Vantage</li>\n",
    "                        <li>Data can be persisted in the Object Filesystem, written to open object storage, or copied to the client</li>\n",
    "                    </ul></li>\n",
    "            </ol>\n",
    "        </td><td><img src = 'images/OAF_Overview.png' width = '600'></td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-premiere",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Python Package Imports</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Standard practice to import required packages and libraries; execute this cell to import packages for Teradata automation as well as machine learning, analytics, utility, and data management packages.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pickle as pkl\n",
    "import datetime as dt\n",
    "import json, os, jdk4py\n",
    "\n",
    "from teradataml import *\n",
    "from teradatasqlalchemy import types\n",
    "\n",
    "from IPython.display import display as ipydisplay\n",
    "from IPython.display import clear_output \n",
    "from time import sleep\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.offline as offline\n",
    "from matplotlib import cm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#\n",
    "# Account for the proper version if urllib for parsing\n",
    "#\n",
    "try:\n",
    "    # Python 2.x should not be needed\n",
    "    from urllib.parse import urlparse\n",
    "except ImportError:\n",
    "    # Python 3.x should be standard\n",
    "    from urlparse import urlparse\n",
    "\n",
    "offline.init_notebook_mode()\n",
    "from teradataml import display\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "\n",
    "configure.val_install_location = 'TD_VAL'\n",
    "configure.byom_install_location = 'TD_MLDB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-ribbon",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function definition #\n",
    "# This can be hidden during the demo by clicking\n",
    "# on the vertical bar on the left of the editor window\n",
    "\n",
    "#Convert Teradata nPath output to plotly Sankey\n",
    "#can handle paths up to 999 links in length\n",
    "\n",
    "def display_sankey(npath_pandas):\n",
    "    \n",
    "    dataDict = defaultdict(int)\n",
    "    eventDict = defaultdict(int)\n",
    "    maxPath = 3\n",
    "\n",
    "\n",
    "    for index, row in npath_pandas.iterrows():\n",
    "        rowList = row['path'].replace('[','').replace(']','').split(',')\n",
    "        pathCnt = 3\n",
    "        pathLen = len(rowList)\n",
    "        for i in range(len(rowList)-1):\n",
    "            leftValue = str(100 + i + maxPath - pathLen) + rowList[i].strip()\n",
    "            rightValue = str(100 + i + 1 + maxPath - pathLen) + rowList[i+1].strip()\n",
    "            valuePair = leftValue + '+' + rightValue\n",
    "            dataDict[valuePair] += pathCnt\n",
    "            eventDict[leftValue] += 1\n",
    "            eventDict[rightValue] += 1\n",
    "\n",
    "    eventList = []\n",
    "    for key,val in eventDict.items():\n",
    "        eventList.append(key)\n",
    "\n",
    "    sortedEventList = sorted(eventList)\n",
    "    sankeyLabel = []\n",
    "    for event in sortedEventList:\n",
    "        sankeyLabel.append(event[3:])\n",
    "\n",
    "    sankeySource = []\n",
    "    sankeyTarget = []\n",
    "    sankeyValue = []\n",
    "\n",
    "    for key,val in dataDict.items():\n",
    "        sankeySource.append(sortedEventList.index(key.split('+')[0]))\n",
    "        sankeyTarget.append(sortedEventList.index(key.split('+')[1]))\n",
    "        sankeyValue.append(val)\n",
    "\n",
    "    sankeyColor = []\n",
    "    for i in sankeyLabel:\n",
    "        sankeyColor.append('blue')\n",
    "\n",
    "    sankeyChart = dict(\n",
    "        type='sankey',\n",
    "        node = dict(\n",
    "          pad = 15,\n",
    "          thickness = 20,\n",
    "          line = dict(\n",
    "            color = 'black',\n",
    "            width = 0.5\n",
    "          ),\n",
    "          label = sankeyLabel,\n",
    "          color = sankeyColor\n",
    "        ),\n",
    "        link = dict(\n",
    "            source = sankeySource,\n",
    "            target = sankeyTarget,\n",
    "            value = sankeyValue\n",
    "        )\n",
    "      )\n",
    "    layout =  dict(\n",
    "        title = \"Paths to Cancel\",\n",
    "        font = dict(\n",
    "          size = 10\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    fig = dict(data=[sankeyChart], layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vars json\n",
    "with open('../../vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "# Create the SQLAlchemy Context\n",
    "host = session_vars['environment']['host']\n",
    "username = session_vars['hierarchy']['users']['business_users'][1]['username']\n",
    "password = session_vars['hierarchy']['users']['business_users'][1]['password']\n",
    "\n",
    "# This URL comes from the environment panel in console; provided here in the environment\n",
    "# object in vars.json\n",
    "ues_url = session_vars['environment']['UES_URI']\n",
    "\n",
    "eng = create_context(host=host, username=username, password=password)\n",
    "\n",
    "# confirm connection\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-secondary",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Demo 1 - Feature Engineering at Scale</b></p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "<tr>\n",
    "    <td style = 'vertical-align:top' width = '50%'>\n",
    "        <p style = 'font-size:16px;font-family:Arial;color:#00233C'>Leverage Vantage for fast, efficient data transformations to create reusable features.</p>\n",
    "        <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li>Connect to data through Vantage - Local/Remote/Data Lake</li>\n",
    "            <br>\n",
    "            <li>Feature Engineering - Customer Journey</li>\n",
    "            <br>\n",
    "            <li>Feature Engineering - Sentiment Analysis</li>\n",
    "            <br>\n",
    "            <li>Create Training and Testing data sets</li>\n",
    "        </ol>\n",
    "    </td><td width = '20%'></td>\n",
    "    <td><img src = 'images/thumbsupdown.png' width = '200'></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-configuration",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>1.1 - Inspect the Data</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Create Three Virtual DataFrames:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Customer Activity from OFS Storage</li>\n",
    "    <li>Customer Comments from OFS Storage</li>\n",
    "    <li>Customer PII from BFS Storage</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity History:\n",
    "tdf_customer_history_OFS = DataFrame('\"demo_ofs\".\"retail_compnew\"')\n",
    "\n",
    "print('Activity History:')\n",
    "ipydisplay(tdf_customer_history_OFS.head(3))\n",
    "\n",
    "# Comment History\n",
    "tdf_customer_comments_OFS = DataFrame('\"demo_ofs\".\"web_comment\"')\n",
    "print('Comment History:')\n",
    "ipydisplay(tdf_customer_comments_OFS.head(3))\n",
    "\n",
    "\n",
    "# Customer Dimension - use VALIDTIME\n",
    "tdf_customer_info_BFS = DataFrame.from_query('current validtime select * from demo.retail_customer')\n",
    "print('Customer Information:')\n",
    "ipydisplay(tdf_customer_info_BFS.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-plastic",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>1.2 - Customer Journey</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Create predictive features based on user behavior over time:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Sessionize based on time (daily)</li>\n",
    "    <li>Create \"Prior Three\" events table</li>\n",
    "    <li>Encode the events as numeric columns</li>\n",
    "    </ol>\n",
    "    \n",
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Sessionize and NPath</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Unique Analytic capabilities to perform advanced windowing and pattern matching.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sessionize will take time-ordered rows and assign user sessions.\n",
    "\n",
    "td_sessionize_out = Sessionize(data = tdf_customer_history_OFS,\n",
    "                               data_partition_column = [\"CUSTOMER_ID\"],\n",
    "                               data_order_column = [\"DATESTAMP\"],\n",
    "                               time_column = \"DATESTAMP\",\n",
    "                               time_out = 86400.0 # 24 HOURS IS THE SESSIONIZATION TIME \n",
    "                              )\n",
    "            \n",
    "tdf_sessionized = td_sessionize_out.result.assign(drop_columns=True, \n",
    "                             customer_id = td_sessionize_out.result['CUSTOMER_ID'], \n",
    "                             datestamp = td_sessionize_out.result['DATESTAMP'], \n",
    "                             event = td_sessionize_out.result['EVENT'],\n",
    "                             session_id = td_sessionize_out.result['SESSIONID'])\n",
    "\n",
    "print('Sessionized Data:')\n",
    "ipydisplay(tdf_sessionized.head(5))\n",
    "\n",
    "# Use NPath to create a \"path\" of user events\n",
    "# Then look 'backwards' to see events that led up to the final one \n",
    "# Say - cancellation\n",
    "\n",
    "from teradataml import NPath\n",
    "\n",
    "tdf_path = NPath(data1 = tdf_sessionized, \n",
    "           mode = 'NONOVERLAPPING', \n",
    "           data1_partition_column = ['customer_id', 'session_id'], \n",
    "           data1_order_column = ['datestamp'], \n",
    "           symbols = ['True as A'], \n",
    "           pattern = '(A){3}$', \n",
    "           result = ['FIRST (customer_id OF A) AS customer_id',\n",
    "                     'FIRST (session_id OF A) AS session_id',\n",
    "                     'NTH (event, 1 OF A) AS prior_2_event',\n",
    "                     'NTH (event, 2 OF A) as prior_1_event',\n",
    "                     'LAST (event OF A) as final_event', \n",
    "                     'ACCUMULATE(event OF ANY(A)) AS PATH']).result\n",
    "\n",
    "print('Path Data:')\n",
    "ipydisplay(tdf_path.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the paths leading to Cancel\n",
    "\n",
    "iplot(display_sankey(tdf_path[tdf_path['final_event'] == 'Mem Cancel'].to_pandas(all_rows = True)), validate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-desert",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Vantage Analytic Library</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Whole-data set statistical analysis and data transformation functions.  One-hot Encode the event columns, and binary encode the final event \"Cancel\" vs. \"Not Cancel\"</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Transformation and column retention object(s)\n",
    "\n",
    "import teradataml.analytics.Transformations as tdtf\n",
    "\n",
    "\n",
    "event_1_list = tdf_path.groupby('prior_1_event').count().to_pandas()['prior_1_event'].to_list()\n",
    "event_2_list = tdf_path.groupby('prior_2_event').count().to_pandas()['prior_2_event'].to_list()\n",
    "\n",
    "\n",
    "event_1_tf = tdtf.OneHotEncoder(values = [x for x in event_1_list if x], columns = 'prior_1_event')\n",
    "event_2_tf = tdtf.OneHotEncoder(values = [x for x in event_2_list if x], columns = 'prior_2_event')\n",
    "\n",
    "rt = Retain(columns = ['final_event'])\n",
    "\n",
    "# Execute the Transformation on the whole dataset\n",
    "\n",
    "tdf_path_encoded = valib.Transform(data = tdf_path,\n",
    "                                   one_hot_encode = [event_1_tf, event_2_tf],\n",
    "                                   retain = [rt],\n",
    "                                   index_columns = ['customer_id', 'session_id']).result\n",
    "\n",
    "tdf_path_encoded = tdf_path_encoded.assign(b_cancel = tdf_path_encoded['final_event'].str.contains('Mem Cancel')).drop('final_event', axis = 1)\n",
    "tdf_path_encoded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-momentum",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>1.3 - Derive Sentiment Features</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Analyze Customer Comments for sentiment, and create features based on polarity:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Extract Sentiment</li>\n",
    "    <li>Encode Polarity values (NEG, NEU, POS)</li>\n",
    "    <li>Aggregate and rescale polarity values</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import SentimentExtractor, ConvertTo, OneHotEncodingFit, OneHotEncodingTransform, ScaleFit, ScaleTransform\n",
    "\n",
    "print('1. Original Data Set:')\n",
    "ipydisplay(tdf_customer_comments_OFS.head(2))\n",
    "\n",
    "sentiment_res = SentimentExtractor(data = tdf_customer_comments_OFS, \n",
    "                                   text_column = 'comment_text', \n",
    "                                   accumulate = ['customer_id','comment_summary']).result\n",
    "\n",
    "print('2. Sentiment:')\n",
    "ipydisplay(sentiment_res.head(2))\n",
    "\n",
    "# Perform native one-hot encoding on the data\n",
    "# These functions use a \"fit-and-transform\" pattern\n",
    "# that supports reuse and easier operationalization of the transformation process\n",
    "\n",
    "res_ohe = OneHotEncodingFit(data = sentiment_res, \n",
    "                            target_column = 'polarity', \n",
    "                            categorical_values = ['POS', 'NEG', 'NEU'], \n",
    "                            other_column = 'other',\n",
    "                            is_input_dense = True)\n",
    "\n",
    "tdf_sentiment_transformed = OneHotEncodingTransform(data = sentiment_res, object = res_ohe.result, is_input_dense = True).result\n",
    "\n",
    "print('3. One-Hot Encoding:')\n",
    "ipydisplay(tdf_sentiment_transformed.head(2))\n",
    "\n",
    "#Aggregate the polarity scores:\n",
    "\n",
    "tdf_gb = tdf_sentiment_transformed.groupby('customer_id').sum().drop(['sum_polarity_other', 'sum_sentiment_score'], axis = 1)\n",
    "\n",
    "print('4. Aggregate Sentiment Polarity:')\n",
    "ipydisplay(tdf_gb.head(2))\n",
    "\n",
    "\n",
    "# Convert data types and rescale\n",
    "tdf_gb_cv = ConvertTo(data = tdf_gb, \n",
    "                      target_columns = ['0:3'], \n",
    "                      target_datatype = 'integer').result\n",
    "\n",
    "\n",
    "sf_fit = ScaleFit(data = tdf_gb_cv, \n",
    "                  scale_method = 'RESCALE (lb=0, ub=1)',\n",
    "                  target_columns = ['1:3'])\n",
    "\n",
    "tdf_rescaled_sentiment = ScaleTransform(data = tdf_gb_cv,\n",
    "                                      object = sf_fit.output, \n",
    "                                      accumulate = ['customer_id']).result\n",
    "\n",
    "\n",
    "tdf_rescaled_sentiment = tdf_rescaled_sentiment.assign(customer_id = tdf_rescaled_sentiment['customer_id'] + 1526)\n",
    "res = copy_to_sql(tdf_rescaled_sentiment, table_name = 'agg_sentiment', schema_name = 'demo_ofs', if_exists = 'replace')\n",
    "\n",
    "print('5. Rescaled:')\n",
    "ipydisplay(tdf_rescaled_sentiment.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-coverage",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>1.4 - Create Final Data Set</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Join features into a single analytic set:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Join Gender info from Customer Table </li>\n",
    "    <li>Join Sentiment Polarity DataFrame</li>\n",
    "    <li>Remove NULLs</li>\n",
    "    <li>Train/Test Split</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_joined = tdf_path_encoded.join(tdf_customer_info_BFS[['CUSTOMER_ID','GENDER']], on=['customer_id'], lsuffix='l', rsuffix='cust', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the Gender category from Delta Lake\n",
    "tdf_joined = tdf_path_encoded.join(tdf_customer_info_BFS[['CUSTOMER_ID','GENDER']], on=['customer_id'], lsuffix='l', rsuffix='cust', how='inner')\n",
    "tdf_joined = tdf_joined.assign(b_gender = tdf_joined['GENDER'].str.contains('M'), \n",
    "                               customer_id = tdf_joined['customer_id_cust']).drop(['GENDER', 'CUSTOMER_ID_l', 'customer_id_cust'], axis = 1)\n",
    "print('1. Gender Flag Joined to Events:')\n",
    "ipydisplay(tdf_joined.head(5))\n",
    "\n",
    "# Join the Sentiment Polarity\n",
    "# All customers didn't leave comments, so many nulls need to be filled\n",
    "\n",
    "tdf_analytic_set = tdf_joined.join(tdf_rescaled_sentiment, on = ['customer_id'], lsuffix = 'l', rsuffix = 'r')\n",
    "tdf_analytic_set = tdf_analytic_set.assign(customer_id = tdf_analytic_set['customer_id_l']).drop(['customer_id_l', 'customer_id_r'], axis = 1)\n",
    "\n",
    "fillna_fit = tdtf.FillNa(style = 'literal', value=0, columns=['sum_polarity_POS', 'sum_polarity_NEG', 'sum_polarity_NEU'])\n",
    "rt = rt = Retain(columns = [x for x in tdf_analytic_set.columns if x not in ['sum_polarity_POS', 'sum_polarity_NEG', 'sum_polarity_NEU', 'customer_id']])\n",
    "\n",
    "tdf_analytic_set = valib.Transform(data = tdf_analytic_set,\n",
    "                                   fillna = fillna_fit,\n",
    "                                   key_columns = 'customer_id', \n",
    "                                   index_columns = 'customer_id',\n",
    "                                   retain = [rt]).result\n",
    "\n",
    "print('2. Polarity Added, NULLs filled:')\n",
    "ipydisplay(tdf_analytic_set.head(5))\n",
    "\n",
    "print('Check Distribution of churn vs. non-churn:')\n",
    "ipydisplay(tdf_analytic_set.groupby('b_cancel').count().to_pandas()[['b_cancel','count_customer_id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-crown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Test/Train Split</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Extraordinarily fast \"Sample\" function can split the data into multiple data sets in seconds.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_samples = tdf_analytic_set.sample(frac = [0.2, 0.8])\n",
    "copy_to_sql(tdf_samples[tdf_samples['sampleid'] == 2], table_name = 'churn_train', schema_name = 'demo', if_exists = 'replace')\n",
    "copy_to_sql(tdf_samples[tdf_samples['sampleid'] == 1], table_name = 'churn_test', schema_name = 'demo', if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-stadium",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Train the Model</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use open-source XGBoost Classifier to train the model using the \"training\" data split above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame\n",
    "df_train = DataFrame('\"demo\".\"churn_train\"').to_pandas(all_rows = True)\n",
    "\n",
    "# define the input columns and target variable:\n",
    "X_train = df_train[df_train.columns.drop(['session_id', 'customer_id', 'b_cancel', 'sampleid'])]\n",
    "y_train = df_train[['b_cancel']]\n",
    "\n",
    "# Fit the Model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-westminster",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Test the Model</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>It is common practice to measure the efficacy of a model.  For this demonstration, a Confusion Matrix is generated that shows the quantity of true vs. false positives and negatives for the model.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-million",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Return a Pandas DataFrame from the split data above\n",
    "\n",
    "df_test = DataFrame('\"demo\".\"churn_test\"').to_pandas(all_rows = True)\n",
    "\n",
    "# Define the input columns and target\n",
    "X_test = df_test[df_test.columns.drop(['session_id', 'customer_id', 'b_cancel', 'sampleid'])]\n",
    "y_test = df_test[['b_cancel']]\n",
    "\n",
    "\n",
    "# Predict the class and the probability of Fraud\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# Generate the Confusion Matrix\n",
    "df_test[['prob_0', 'prob_1']] = y_prob\n",
    "df_test['prediction'] = y_pred\n",
    "\n",
    "cm = confusion_matrix(df_test['b_cancel'], df_test['prediction'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ['0', '1'])\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Get AUC score - anything over .75 is decent\n",
    "AUC = roc_auc_score(df_test['b_cancel'], df_test['prediction'])\n",
    "print(f'AUC: {AUC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-coalition",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Save the Model</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Save the model file in native xgboost format AND in PMML format to use in BYOM.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('xgb_churn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-palmer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Serialize PMML for BYOM\n",
    "model.save_model('model.json')\n",
    "\n",
    "# Writing features map to .fmap file\n",
    "\n",
    "# Create an fmap file using the training data column types\n",
    "i = 0\n",
    "with open('model.fmap', 'w') as fmap_file:\n",
    "    for key, value in X_train.dtypes.items():\n",
    "        \n",
    "        value = str(value)\n",
    "        if 'int' in value:\n",
    "            value = 'int'\n",
    "        else:\n",
    "            value = 'q'\n",
    "        \n",
    "        fmap_file.write('%d\\t%s\\t%s\\n'%(i, key, value))\n",
    "        i = i + 1\n",
    "\n",
    "if not os.path.isfile('model.pmml'):\n",
    "    os.system(str(jdk4py.JAVA) + ' -jar jpmml-xgboost-executable-1.5.5.jar --model-input model.json --fmap-input model.fmap --pmml-output model.pmml --target-name mm_fraud')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-certificate",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Demo 1 Summary</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>The preceding demonstration has illustrated a machine learning model development and testing pipeline that leverages both native and open source techniques to develop a unique \"Churn\" model by:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Connecting disparate data sets in native storage and open formats</b></li>\n",
    "    <li><b>Executing powerful, unique, and scalable behavioral and sentiment anaysis functions</b></li>\n",
    "    <li><b>Cleansing and combining these insights into a feature-rich training set by using familiar techniques, expressed to run at the source of the data and at scale</b></li>\n",
    "    <li><b>Leveraging the innovation of Open-Source tools and techniques for model building and analysis</b></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-summer",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Demo 2a - Deploy to Native Scoring Function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>VantageCloud Lake <b>Analytic Clusters</b> combine the power and scale of native <b>ClearScape Analytics</b> Functions to prepare data that can be scored with a model using commmon serialization formats such as PMML, ONNX, or MOJO.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Enterprise Class customers report the ability to reduce data prep and model scoring times from several hours per run to seconds; effectively allowing model scoring in near-real-time.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This demonstration will illustrate these key concepts:</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '40%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>Load the PMML model to the Vantage system - capture model metadata and accuracy scores</li>\n",
    "                <br>\n",
    "                <li>Execute the Prediction against the prepared data.  <b>Note this runs on the Primary cluster today</b></li>\n",
    "                <br>\n",
    "                <li>Analyze the results of the process to determine ongoing model accuracty and efficacy</li>\n",
    "            </ol>\n",
    "        </td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-municipality",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Load the model to the Analytic Cluster</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Users can load model files, and add additional metadata if desired.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-allah",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_name = 'byom_models'\n",
    "schema_name = 'demo'\n",
    "model_id = 'xgb_churn_1'\n",
    "\n",
    "try:\n",
    "    delete_byom(model_id, table_name = table_name, schema_name = schema_name)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('Failed to delete the model') >= 1:\n",
    "        pass\n",
    "    elif str(e.args).find('not found') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "        \n",
    "model_metadata = {'Description': 'XGBoost Churn model',\n",
    "                  'AUC' : float(AUC),\n",
    "                  'ModelSavedDate': dt.date.today(),\n",
    "                  'ModelSavedTime': dt.datetime.now().time()}\n",
    "\n",
    "model_datatypes = {'Description':VARCHAR(100),\n",
    "                   'AUC':FLOAT,\n",
    "                   'ModelSavedDate':DATE(),\n",
    "                   'ModelSavedTime':TIME()}\n",
    "\n",
    "res = save_byom(model_id = model_id, \n",
    "                model_file = 'model.pmml', \n",
    "                schema_name = 'demo',\n",
    "                table_name = table_name,\n",
    "                additional_columns = model_metadata, \n",
    "                additional_columns_types = model_datatypes)\n",
    "\n",
    "list_byom(schema_name = schema_name, table_name = table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-makeup",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Execute the Scoring function</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The model scoring is executed via the <b>PMMLPredict</b> method, where we pass;</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>The data set to be scored.  This a \"Virtual\" Dataframe, and represents the state of the data <b>In Vantage</b>.  In the case below, we pass the transformed data.  This could also be a set of methods or SQL queries above to prep and transform in-line</li>\n",
    "    <li>The version of the model we wish to use</li>\n",
    "    <li>Function parameters such as additional columns to return, and the model output fields</li>\n",
    "    </ul>\n",
    "    \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Finally, the scoring is only executed when needed - in this case to satisfy the head() method call.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-lafayette",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the PMMLPredict function in Vantage\n",
    "\n",
    "from teradataml import PMMLPredict\n",
    "\n",
    "configure.byom_install_location = 'TD_MLDB'\n",
    "tdf_predict = PMMLPredict(\n",
    "            modeldata = retrieve_byom(model_id, table_name = table_name, schema_name = schema_name),\n",
    "            model_output_fields = ['probability(1)', 'probability(0)'],\n",
    "            newdata = DataFrame('\"demo\".\"churn_test\"'),\n",
    "            accumulate = ['b_cancel','customer_id', 'session_id']\n",
    "            ).result\n",
    "\n",
    "tdf_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-stocks",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Analyze the Results</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>It is common practice to measure the efficacy of a model.  Since the number of records in this data set is small, it can be copied to the client for visualization.</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Analyzing results at scale</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Under real-world conditions, it may be that the number of records that are being scored is too large to copy to the client - either due to network or client-side resource limitations.  To address these challenges, Teradata provides several model evaluation functions.  For Classification tasks, the <a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Analytics-Database-Analytic-Functions/Model-Evaluation-Functions/TD_ClassificationEvaluator'>TD_ClassificationEvaluator</a> function will create a confusion matrix in-database, and can be executed against data at any scale.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-tunnel",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the predictions to the client\n",
    "# to generate the simple Confusion Matrix\n",
    "# and print the AUC (Area Under Curve)\n",
    "\n",
    "df_test = tdf_predict.to_pandas(all_rows = True)\n",
    "df_test['prediction'] = df_test['probability(1)'].round(0).astype(int)\n",
    "cm = confusion_matrix(df_test['b_cancel'].astype(int), df_test['prediction'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ['0', '1'])\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Get AUC score - anything over .75 is decent\n",
    "AUC = roc_auc_score(df_test['b_cancel'].astype(int), df_test['prediction'].astype(int))\n",
    "print(f'AUC: {AUC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-patient",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Demo 2b - Deploy to Custom Container</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>VantageCloud Lake Edition <b>Analytic Clusters</b> combine the power and scale of native <b>ClearScape Analytics</b> Functions with the open and flexible runtime environments; offering users the flexibility to balance built-in data prep, transformation and feature engineering functions with custom code and models at massive scale.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Enterprise Class customers report the ability to reduce data prep and model scoring times from several hours per run to seconds; effectively allowing model scoring in near-real-time.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This demonstration will illustrate these key concepts:</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '40%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>Load the model and custom code to the Analytic Cluster Python Runtime</li>\n",
    "                <br>\n",
    "                <li>Execute the combined native query and the python scoring functions together, in parallel</li>\n",
    "                <br>\n",
    "                <li>Analyze the results of the process to determine ongoing model accuracty and efficacy</li>\n",
    "            </ol>\n",
    "        </td>\n",
    "        <td><img src = 'images/OAF_Scoring.png' width = '600'></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-cambodia",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Connect to the Environment Service</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To better support integration with Cloud Services and common automation tools; the <b > User Environment Service</b> is accessed via RESTful APIs.  These APIs can be called directly or in the examples shown below that leverage the Python Package for Teradata (teradataml) methods.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure base URL to the specific account service\n",
    "\n",
    "try:\n",
    "    ues_url\n",
    "except NameError as e:\n",
    "    ues_url = input('Please enter UES URL from Console: ')\n",
    "\n",
    "# Configure base URL to the specific account service\n",
    "\n",
    "# This URL comes from the environment panel in console; provided here in the environment\n",
    "# object in vars.json\n",
    "ues_url = session_vars['environment']['UES_URI']\n",
    "\n",
    "# This python snippet parses the url to place values into appropriate spots for pftoken to obtain JWT\n",
    "parsed_ues_url = urlparse(ues_url)\n",
    "client_id = parsed_ues_url.netloc.split('.')[0]\n",
    "\n",
    "if set_auth_token(ues_url = ues_url, username = username, pat_token = 'EXAMPLE', pem_file = 'path/to/pem.pem'):\n",
    "    print('UES Authentication successful')\n",
    "else:\n",
    "    print('UES Authentication failed, check URL and account info')\n",
    "\n",
    "# List available Base Python environments\n",
    "print('Available Base Environments:')\n",
    "ipydisplay(list_base_envs())\n",
    "\n",
    "# List any custom environments\n",
    "# Code here will catch any errors if there are no\n",
    "# existing custom environments\n",
    "\n",
    "print('Available User Environments:')\n",
    "try:\n",
    "    ipydisplay(list_user_envs())\n",
    "except Exception as e:\n",
    "    if str(e).find('No user environments found') > 0:\n",
    "        print('No user environments found')\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new environment, or connect to an existing one\n",
    "# This demo code will create a fixed environment called \"My_Scoring_Env\"\n",
    "# using a base Python 3.7 environment\n",
    "\n",
    "try:\n",
    "    demo_env = create_env(env_name = 'My_Scoring_Env',\n",
    "                          desc = 'Demonstration dedicated python environment')\n",
    "except Exception as e:\n",
    "    if str(e).find('same name already exists') > 0:\n",
    "        print('Environment already exists, obtaining a reference to it')\n",
    "        demo_env = get_env('My_Scoring_Env')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "try:\n",
    "    ipydisplay(list_user_envs())\n",
    "except Exception as e:\n",
    "    if str(e).find('No user environments found') > 0:\n",
    "        print('No user environments found')\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install any Python add-ons needed by the script in the user environment\n",
    "# Using option asynchronous=True for an asychronous execution of the statement.\n",
    "# Note: Avoid asynchronous installation when batch-executing all notebook statements,\n",
    "#       as execution will continue even without installation being complete.\n",
    "#\n",
    "claim_id = demo_env.install_lib(['numpy','pandas','scikit-learn', 'xgboost'], asynchronous=True)\n",
    "\n",
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "\n",
    "ipydisplay(demo_env.status(claim_id))\n",
    "stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "while stage == 'Started':\n",
    "    stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "    clear_output()\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    sleep(5)\n",
    "    \n",
    "# Verify the Python libraries have been installed correctly.\n",
    "ipydisplay(demo_env.libs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-speed",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Install User Files in the Cluster Container</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Users can load any asset to the environment using the install_file method.  This ensures that only authenticated users can install specific files into a dedicated filesystem, and helps prevent malicious code injection.  Users pass the file name, and whether to replace an existing file.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install xgboost model file.\n",
    "#\n",
    "demo_env.install_file('xgb_churn_model', replace = True)\n",
    "\n",
    "# Install the desired Python script into the environment.\n",
    "demo_env.install_file('XGB_Churn_Scoring.py', replace = True)\n",
    "\n",
    "# Verify the files have been installed correctly.\n",
    "demo_env.files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-reconstruction",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Execute the Scoring function</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The script is executed via the <b>Apply</b> method, where we pass;</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>The data set to be scored.  This a \"Virtual\" Dataframe, and represents the state of the data <b>In Vantage</b>.  In the case below, we pass the transformed data.  This could also be a set of methods or SQL queries above to prep and transform in-line</li>\n",
    "    <li>The command to run - in this case, calling the python runtime</li>\n",
    "    <li>The format of the data being returned from the functions</li>\n",
    "    <li>The custom container to execute the queries and code</li>\n",
    "    </ul>\n",
    "    \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Finally, the script is executed by calling the \"execute_script\" method; this \"lazy\" evaluation allows for more modular and performant architecture.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "apply_obj = Apply(data = DataFrame('\"demo\".\"churn_test\"'),\n",
    "                  apply_command = 'python3 XGB_Churn_Scoring.py',\n",
    "                  returns = {'customer_id': VARCHAR(20), 'session_id': VARCHAR(20),\n",
    "                             'Prob_0': VARCHAR(30), 'Prob_1': VARCHAR(30), \n",
    "                             'Prediction':VARCHAR(2),'Actual': VARCHAR(2)},\n",
    "                  env_name = demo_env,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the Python script inside the remote user environment.\n",
    "# The result is a teradataml DataFrame. \n",
    "#\n",
    "scored_data = apply_obj.execute_script()\n",
    "\n",
    "# Only return five rows - minimize network overhead\n",
    "scored_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-mission",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Analyze the Results</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>It is common practice to measure the efficacy of a model.  For this demonstration, a \"Confusion Matrix\" is generated that shows the quantity of true vs. false positives and negatives for the model.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the predictions to the client\n",
    "# to generate the simple Confusion Matrix\n",
    "# and print the AUC (Area Under Curve)\n",
    "\n",
    "df_test = scored_data.to_pandas(all_rows = True)\n",
    "cm = confusion_matrix(df_test['Actual'].astype(int), df_test['Prediction'].astype(int))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ['0', '1'])\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Get AUC score - anything over .75 is decent\n",
    "AUC = roc_auc_score(df_test['Actual'].astype(int), df_test['Prediction'].astype(int))\n",
    "print(f'AUC: {AUC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-coordinate",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Demo 2 Summary</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>The preceding demonstration has shown one method for executing open-source models in a uniquely-scalable manner by leveraging the VantageCloud Lake Open Analytics Framework to:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Create a secure, isolated, and custom runtime container</b></li>\n",
    "    <li><b>Deploy analytic artifacts including user code and models</b></li>\n",
    "    <li><b>Execute the Operational pipeline including data preparation and data cleansing in-line with model execution and in parallel</b></li>\n",
    "    <li><b>Expose the products of Machine Learning to the broadest possible audience</b></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-arizona",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Clean up</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uninstall the libraries from the environment first before removing it\n",
    "demo_env.uninstall_lib(libs = demo_env.libs['name'].to_list())\n",
    "remove_env('My_Scoring_Env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-jungle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
