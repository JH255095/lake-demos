{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Create scalable in-database Semantic Search capabilities powered by open-source models and native ClearScape Analytics functions\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"images/TeradataLogo.png\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<hr>\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#00233C'>Demonstrations Overview</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstrations illustrate the end-to-end process of how organizations can utilize VantageCloud Lake <b>GPU-enabled Analytic Cluster</b> architecture to run open-source large language models at massive parallelism and scale, and then leverage these next-generation capabilities in ad-hoc analytics, development, and operational processing.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This notebook contains several high-level demonstrations that can be run together or individually, and are designed to illustrate;</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Container Management</b>.  Administrators can create and manage <b>secure, custom</b> runtime containers that will host any number of models and model artifacts to unlock GPU-augmented analytics</li>\n",
    "    <li><b>Data Prep with Sentiment Extraction</b>. Developers will use the Hugging Face cardiffnlp/twitter-roberta-base-sentiment-latest model to extract user sentiment from Call Center transcripts</li>\n",
    "    <li><b>Operationalization</b>. Combine the data prep and transformation steps with powerful native <b>ClearScape Analytics</b> functions against the data sets to create a scalable, on-demand Sentiment extraction function</li>\n",
    "    </ol>\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#00233C'>End-to-End workflow</b>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The high level process is as follows:</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;font-family:Arial;color:#00233C'>\n",
    "    <tr><td style = 'vertical-align:top' width = '40%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>The Data Scientist conducts analytics activities using his or her own python tools and packages of choice, then connects to VantageCloud Lake through teradataml client library and teradatasql python driver.</li>\n",
    "                <br>      \n",
    "                <li>Teradataml provides APIs to create and manage custom runtime environments; including custom libraries, dependencies, model artifacts, and scoring scripts.  The user can leverage these APIs to create one or many custom, dedicated environments to host their code.</li>\n",
    "                <br>\n",
    "                <li>The Data Scientist will then execute their pipeline that will;\n",
    "                    <ul style = 'width:100%;table-layout:fixed;font-family:Arial;color:#00233C'><li>Call ClearScape Analytics functions on Compute Clusters (data prep, transformation, etc.)</li>\n",
    "                        <li>Prepared data is passed to the python container running in parallel on cluster nodes.</li>\n",
    "                        <li>Results (inference/predictions) are returned as \"virtual\" dataframes; where the data resides <b>in Vantage</b></li>\n",
    "                    </ul></li>\n",
    "                <br>\n",
    "                <li>Worfklow can be operationalized using SQL, and results can be returned to common BI tools, persisted as part of an ETL process, or embedded in application code</li>\n",
    "            </ol>\n",
    "        </td><td><img src = 'images/BYOLLM_Overview.png' width = '600'></td></tr>\n",
    "</table>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Installation</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If necessary, install required client packages for the demonstrations.  User may need to restart the Jupyter kernel after installation.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Imports</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Standard practice to import required packages and libraries; execute this cell to import packages for Teradata automation as well as machine learning, analytics, utility, and data management packages.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from teradataml import *\n",
    "from oaf_utils import *\n",
    "from teradatasqlalchemy.types import *\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import csv, sys, os, warnings\n",
    "#from os.path import expanduser\n",
    "from collections import OrderedDict\n",
    "\n",
    "from IPython.display import clear_output , display as ipydisplay\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "\n",
    "# load vars json\n",
    "with open('vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "# Database login information\n",
    "host = session_vars['environment']['host']\n",
    "username = session_vars['hierarchy']['users']['business_users'][1]['username']\n",
    "password = session_vars['hierarchy']['users']['business_users'][1]['password']\n",
    "\n",
    "# UES Authentication information\n",
    "ues_url = session_vars['environment']['UES_URI']\n",
    "configure.ues_url = ues_url\n",
    "pat_token = session_vars['hierarchy']['users']['business_users'][1]['pat_token']\n",
    "pem_file = session_vars['hierarchy']['users']['business_users'][1]['key_file']\n",
    "\n",
    "\n",
    "compute_group = session_vars['hierarchy']['users']['business_users'][1]['compute_group']\n",
    "\n",
    "\n",
    "# get the current python version to match deploy a custom container\n",
    "python_version = str(sys.version_info[0]) + '.' + str(sys.version_info[1])\n",
    "print(f'Using Python version {python_version} for user environment')\n",
    "\n",
    "\n",
    "# Hugging Face model for the demo\n",
    "model_name = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "\n",
    "# a list of required packages to install in the custom OAF container\n",
    "# modify this if using different models or design patterns\n",
    "pkgs = ['transformers',\n",
    "        'torch',\n",
    "        'sentencepiece',\n",
    "        'pandas',\n",
    "        'sentence-transformers',\n",
    "        'dill']\n",
    "\n",
    "# container name - set here for easier notebook navigation\n",
    "### User will also be asked to change it ###\n",
    "oaf_name = 'oaf_sentiment_demo'\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Connect to the database</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>After connecting, check cluster status. Start it if necessary - note the cluster only needs to be running to execute the APPLY sections of the demo.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for existing connection\n",
    "eng = check_and_connect(host=host, username=username, password=password, compute_group = compute_group)\n",
    "print(eng)\n",
    "\n",
    "# check cluster status\n",
    "res = check_cluster_start(compute_group = compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Demo 1 - Container Management\n",
    "  <br>\n",
    "    </p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Teradata Vantage Python Client Library provides simple, powerful methods for the creation and maintenance of custom Python runtime environments <b>in the VantageCloud environment</b> .  This allows practitioners complete control over the behavior and quality of their model performance and analytic accuracy running on the Analytic Cluster.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Custom environments are persistent.</b> Users only need to create these once and then can be saved, updated, or modified only as needed.</p>\n",
    "\n",
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Container Management Process</b></p>\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '40%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>Create a unique User Environment based on available base images</li>\n",
    "                <br>\n",
    "                <li>Install libraries</li>\n",
    "                <br>\n",
    "                <li>Install models and additional user artifacts</li>\n",
    "            </ol>\n",
    "        </td>\n",
    "        <td><img src = 'images/OAF_Env.png' width = '600'></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.  Connect to the Environment Service</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To better support integration with Cloud Services and commong automation tools; the <b > User Environment Service</b> is accessed via RESTful APIs.  These APIs can be called directly or in the examples shown below that leverage the Python Package for Teradata (teradataml) methods.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check to see if there is a valid UES auth\n",
    "# if not, authenticate\n",
    "try:\n",
    "    demo_env = get_env(oaf_name)\n",
    "    print('Existing valid UES token')\n",
    "\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'value''' or '''Failed to execute get_env''' in str(e):\n",
    "        if set_auth_token(ues_url = ues_url, username = username, pat_token = pat_token, pem_file = pem_file):\n",
    "            print('UES Authentication successful')\n",
    "        else:\n",
    "            print('UES Authentication failed, check URL and account info')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.  Create a Custom Container in Vantage</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If desired, the user can create a <b>new</b> custom environment by starting with a \"base\" image and customizing it.  The steps are:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>List the available \"base\" images the system supports</li>\n",
    "    <li>List any existing \"custom\" environments the user has created</li>\n",
    "    <li>If there are no custom environments, then create a new one from a base image</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new environment, or connect to an existing one\n",
    "\n",
    "\n",
    "try:\n",
    "    ipydisplay(list_user_envs())\n",
    "except Exception as e:\n",
    "    if str(e).find('No user environments found') > 0:\n",
    "        print('No user environments found')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "print('Use an existing environment, or create a new one:')\n",
    "print(f'OAF Environment is set to {oaf_name}.')\n",
    "print('Enter to accept, or input a new value.')\n",
    "print('If the environment is not in the list, a new one will be created')\n",
    "i = input()\n",
    "if len(i) != 0:\n",
    "    oaf_name = i\n",
    "    print(f'OAF Environment is now {oaf_name}')\n",
    "\n",
    "try:\n",
    "    demo_env = create_env(env_name = oaf_name,\n",
    "                      base_env = f'python_{python_version}',\n",
    "                      desc = 'OAF Demo env for LLM')\n",
    "except Exception as e:\n",
    "    if str(e).find('same name already exists') > 0:\n",
    "        print('Environment already exists, obtaining a reference to it')\n",
    "        demo_env = get_env(oaf_name)\n",
    "        pass\n",
    "    elif 'Invalid value for base environment name' in str(e):\n",
    "        print('Unsupported base environment version, using defaults')\n",
    "        demo_env = create_env(env_name = oaf_name,\n",
    "                      desc = 'OAF Demo env for LLM')\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Note create_env seems to be asynchronous - sleep a bit for it to register\n",
    "sleep(5)\n",
    "\n",
    "try:\n",
    "    ipydisplay(list_user_envs())\n",
    "except Exception as e:\n",
    "    if str(e).find('No user environments found') > 0:\n",
    "        print('No user environments found')\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>3.  Install Dependencies</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The second step in the customization process is to install Python package dependencies. This demonstration uses the Hugging Face <a href = 'https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest'>twitter-roberta-base-sentiment</a> Sentiment Extractor.  Since VantageCloud Lake Analytic Clusters are secured by default against unauthorized access to the outside network, the user can load the required libraries and model using teradataml methods:\n",
    "</p> \n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>List the currently installed models and python libraries</li>\n",
    "    <li><b>If necessary</b>, install any required packages</li>\n",
    "    <li><b>If necessary</b>, install the pre-trained model.  This process takes several steps;\n",
    "        <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li>Import and download the model</li>\n",
    "            <li>Create a zip archive of the model artifacts</li>\n",
    "            <li>Call the install_model() method to load the model to the container</li>\n",
    "        </ol></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipydisplay(demo_env.models)\n",
    "\n",
    "# just showing a sample here - remove .head(5) to see them all\n",
    "ipydisplay(demo_env.libs.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>A note on package versions</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Some demonstrations make use of the DataFrame apply() method, which automatically passes the python code to the Analytic Cluster.  As such, one needs to ensue the python package versions match.  dill and pandas are required, as is any additional libraries for the use case.\n",
    "</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note</b> while not required for many OAF use cases, for this demo the required packages for the model execution should be installed in the local environment first.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install any Python add-ons needed by the script in the user environment\n",
    "# Using option asynchronous=True for an asychronous execution of the statement.\n",
    "# Note: Avoid asynchronous installation when batch-executing all notebook statements,\n",
    "#       as execution will continue even without installation being complete.\n",
    "#\n",
    "# Can install by passing a list of packages/versions\n",
    "#   Or \n",
    "# install using a requirements.txt file.\n",
    "\n",
    "# For this demo, \n",
    "# this code block will collect the current user's package versions\n",
    "# for installation into the container\n",
    "# when using dataframe.apply(), it pandas and dill are required\n",
    "# to reduce issues, match the version between client and container\n",
    "\n",
    "# import these functions inside of a function namespace\n",
    "def get_versions(pkgs):\n",
    "    local_v_pkgs = []\n",
    "    for p in pkgs:\n",
    "\n",
    "        #fix up any hyphened package names\n",
    "        p_fixed = p.replace('-', '_')\n",
    "\n",
    "        #import the packages and append the strings to the list\n",
    "        exec(f'''import {p_fixed}; local_v_pkgs.append('{p}==' + str({p_fixed}.__version__))''')\n",
    "    return local_v_pkgs\n",
    "\n",
    "v_pkgs = get_versions(pkgs)\n",
    "\n",
    "\n",
    "\n",
    "# check to see if these packages need to be installed\n",
    "# by comparing the len of the intersection of the list of required packages with the installed ones\n",
    "if not len(set([x.split('==')[0] for x in pkgs]).intersection(demo_env.libs['name'].to_list())) == len(pkgs):\n",
    "    \n",
    "    # pass the list of packages - split off any extra info from the version property e.g., plus sign\n",
    "    claim_id = demo_env.install_lib([x.split('+')[0] for x in v_pkgs], asynchronous=True)\n",
    "else:\n",
    "    print(f'All required packages are installed in the {oaf_name} environment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Monitor library installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optionally - users can monitor the library installation status using the cell below:\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try: \n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "    while stage == 'Started':\n",
    "        stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print('No installations to monitor')\n",
    "\n",
    "    \n",
    "# Verify the Python libraries have been installed correctly.\n",
    "ipydisplay(demo_env.libs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Download and install model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Open Analytics Framework containers do not have open access to the external network, which contributes to a very secure runtime environment.  As such, users will load pre-trained models using the below APIs.  For illustration purposes, the following code will check to see if the model archive exists locally and if it doesn't, will import and download it by creating a model object.  The archive will then be created and installed into the remote environment.\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check to see if the model needs to be downloaded/archived\n",
    "\n",
    "# construct the file name for the model:\n",
    "model_base = model_name.split('/')[1]\n",
    "model_path = './' + model_base\n",
    "\n",
    "\n",
    "if not os.path.isfile(f'{model_base}.zip'):\n",
    "\n",
    "    from transformers import pipeline, AutoModelForSequenceClassification, TFAutoModelForSequenceClassification\n",
    "    from transformers import AutoTokenizer, AutoConfig\n",
    "    import torch\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    sentiment_task = pipeline(\"sentiment-analysis\", model = model , tokenizer = tokenizer, device = device)\n",
    "    \n",
    "    # Save model to the local directory - could also pick it up out of huggingface cache dir\n",
    "    tokenizer.save_pretrained(model_path)\n",
    "    model.save_pretrained(model_path)\n",
    "\n",
    "    import shutil\n",
    "    print('Creating Model Archive...')\n",
    "\n",
    "    sentiment_task = pipeline(\"sentiment-analysis\", model = model_name , tokenizer = model_name)\n",
    "    shutil.make_archive(model_base, \n",
    "                        format = 'zip', \n",
    "                        root_dir = model_path)\n",
    "else:\n",
    "    print('Local model archive exists.')\n",
    "\n",
    "# check to see if the model is already installed\n",
    "try:\n",
    "    if demo_env.models.empty: # no models installed at all\n",
    "        print('Installing Model...')\n",
    "        claim_id = demo_env.install_model(model_path = f'{model_base}.zip', asynchronous = True)\n",
    "    elif not any(model_base in x for x in demo_env.models['Model']): #see if model is there\n",
    "        print('Installing Model...')\n",
    "        claim_id = demo_env.install_model(model_path = f'{model_base}.zip', asynchronous = True)\n",
    "    else:\n",
    "        print('Model already installed')\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'empty''' in str(e):\n",
    "        print('Installing Model...')\n",
    "        claim_id = demo_env.install_model(model_path = f'{model_base}.zip', asynchronous = True)\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Monitor model installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optionally - users can monitor the model installation status using the cell below:\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try: \n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "    while stage != 'File Installed':\n",
    "        stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print('No installations to monitor')\n",
    "\n",
    "    \n",
    "# Verify the model has been installed correctly.\n",
    "demo_env.refresh()\n",
    "ipydisplay(demo_env.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Conclusion - Environment Management</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The preceding demo showed how users can perform a <b>one-time</b> configuration task to prepare a custom environment for analytic processing at scale.  Once this configuration is complete, these containers can be re-used in ad-hoc development tasks, or used for operationalizing analytics in production.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Sentiment Analysis using the Analytic Cluster\n",
    "  <br>\n",
    "    </p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration will utilize the custom container environment built in the prior demonstration.  A user function to analyze customer sentiment will be passed to the Analytic GPU Cluster for execution at scale.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Compute Clusters are <b>elastic and ephemeral</b>; they offer automated scale up and down based on demand, and can be turned on or off on a schedule or programmatically.  This allows for greater cost and resource efficiency, where users can turn the GPU-enable cluster on for the duration of the transformation job, then shut it down when the processing is complete.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Data Preparation Workflow</b></p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '30%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>Write a <b>local</b> function that leverages a pre-trained Language Model to analyze sentiment</li>\n",
    "                <br>\n",
    "                <li>Push this processing to the <b>GPU Analytic Cluster</b> for processing at scale</li>\n",
    "                <br>\n",
    "                <li><b>Optimize</b> the analysis function to run at scale to maximize GPU throughput</li>\n",
    "                <br>\n",
    "                <li><b>Execute batch sentiment sxtraction</b> to store the results for further analytic processing</li>\n",
    "            </ol>\n",
    "        </td>\n",
    "        <td style = 'vertical-align:top'>\n",
    "            <img src = 'images/local_remote_functions.png'>\n",
    "        <br>\n",
    "        <img src = 'images/optimize.png'></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Check connection</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Check database and UES connection</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for existing connection\n",
    "eng = check_and_connect(host=host, username=username, password=password, compute_group = compute_group)\n",
    "print(eng)\n",
    "    \n",
    "\n",
    "# check to see if there is a valid UES auth\n",
    "# if not, authenticate\n",
    "try:\n",
    "    demo_env = get_env(oaf_name)\n",
    "\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'value''' or '''Failed to execute get_env''' in str(e): #UES auth expired/required\n",
    "        if set_auth_token(ues_url = ues_url, username = username, pat_token = pat_token, pem_file = pem_file):\n",
    "            print('UES Authentication successful')\n",
    "            try:\n",
    "                demo_env = get_env(oaf_name)\n",
    "                pass\n",
    "            except Exception as l:\n",
    "                if f'''User environment '{oaf_name}' not found''' in str(l):\n",
    "                    print('User environment not found')\n",
    "                    pass\n",
    "                else:\n",
    "                    raise\n",
    "        else:\n",
    "            print('UES Authentication failed, check URL and account info')\n",
    "        pass\n",
    "    elif f'''User environment '{oaf_name}' not found''' in str(e):\n",
    "        print('User environment not found')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "# check cluster status\n",
    "check_cluster_start(compute_group = compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.1.  Create a client-side embedding function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The goal of this exercise is to create a client-side function which can be \"pushed\" to the analytic cluster for processing at scale.  There are a few minor enhancements here to improve performance and usability in this remote environment:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Imports</b>.  By default, the teradataml python client will package the code, objects, and dependencies and serialize it to the analytic cluster.  Users can make this more efficient by staging these objects before hand (done in the first demo of this notebook).  <b>Important</b> - place the larger libraries (sentence_transformers and torch) inside the function so they won't be registered as new dependencies that need to be installed.</li>\n",
    "    <li><b>GPU Drivers</b>.  Since this function will run both on the client (CPU) and cluster (GPU), place a conditional to check</li>\n",
    "    </ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sentiment(row):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    from transformers import pipeline, AutoModelForSequenceClassification, TFAutoModelForSequenceClassification\n",
    "    from transformers import AutoTokenizer, AutoConfig\n",
    "    import torch\n",
    "    from transformers.utils import logging\n",
    "    logging.set_verbosity_error() \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model_name = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "    if os.environ.get('OPENAF_MODELS_DIR'):\n",
    "        model_path = os.environ.get('OPENAF_MODELS_DIR') + '/' + model_name.split('/')[1]\n",
    "    else:\n",
    "        model_path = './' + model_name.split('/')[1]\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    sentiment_task = pipeline(\"sentiment-analysis\", model = model , tokenizer = tokenizer, device = device)\n",
    "\n",
    "    s = pd.Series(sentiment_task(row['text'])[0])\n",
    "\n",
    "    # concat them together\n",
    "    row = pd.concat([row[['id']], s], axis = 0)\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.2.  Test the function on local data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Python pandas provides an apply() method to execute the function across all rows in the DataFrame</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':[1,2], 'text':['very nice!', 'very bad!']})\n",
    "\n",
    "df.apply(get_sentiment, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Step 2. Push this function to the analytic cluster</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Similar to pandas, the teradataml package provides an apply() method which is called in a similar manner, except it runs <b>in parallel on</b> the cluster, leveraging the GPU infrastructure and the MPP processing capabilities of Vantage.</p>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.1 - Inspect the Data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Simple DataFrame methods to show the data.  A teradataml DataFrame behaves like a normal pandas DataFrame, with one significant difference in that it is a reference to data on the analytic database.  This allows developers to perform familiar data mangement operations on extremely large data sets as if the data is local.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf_calls = DataFrame('\"demo_ofs\".\"cust_calls\"')\n",
    "\n",
    "ipydisplay(tdf_calls.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.2 - Prepare to execute the apply method</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>When using the teradataml apply method,there are some differences in how data is passed in and out of the multiple runtime containers on the distributed nodes.  This offers a great deal of processing power, but also requires some additional considerations when calling the method:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Optional Return Types</b>.  If the data being returned by the function has different columns/data types than the input DataFrame, the user passes these as dictionary value to the keyword argument</li>\n",
    "    <li><b>Data Preparation</b>.  Of course, data preparation and cleansing can be performed inside the function. However, the unique architecture of the <b>Teradata Vantage</b> analytic database, is that users can execute powerful native data preparation functions that will operate at extreme scale and performance</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "types_dict = OrderedDict({})\n",
    "types_dict['id'] = BIGINT()\n",
    "types_dict['label'] = VARCHAR(20)\n",
    "types_dict['score'] = FLOAT()\n",
    "\n",
    "tdf = DataFrame.from_query('''SELECT TOP 10 id,\n",
    "    CASE \n",
    "        WHEN text IS NULL THEN ' '\n",
    "        ELSE regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(text , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END text\n",
    "    FROM demo_ofs.cust_calls;''')\n",
    "\n",
    "tdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.3 - Execute the function on the nodes</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Call the apply method on the teradataml DataFrame.  This will push the function to the analytic nodes for processing in parallel.  Data is returned as another teradataml DataFrame, which represents the entire result set of the operation.  For this example, additional method arguments include:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Function</b>.  The name of the function to pass - this is the original client-side function written above</li>\n",
    "    <li><b>Environment</b>.  The custom runtime environment with the models and dependencies loaded</li>\n",
    "    <li><b>Return types</b>. OrderedDict that represents the column names and data types</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# create a new dataframe representing the embeddings\n",
    "tdf_sentiment = tdf.apply(lambda row: get_sentiment(row),\n",
    "                    env_name = demo_env, \n",
    "                    returns = types_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Check the data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now - users can create a table with these embeddings, use it in additional analytics, or operationalize this as part of a pipeline.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipydisplay(tdf_sentiment.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Conclusion - executing custom code against GPU-enabled analytic clusters</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The preceding demo showed how users can use simple, familiar patters to execute powerful AI models <b>at scale</b> for development and operational processing.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Stop the Cluster</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Hibernate the environment if desired</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_cluster_stop(compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Demo 3 - Operationalizing AI-powered analytics\n",
    "  <br>\n",
    "    </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration will illustrate how developers can take the next step in the process to <b>operationalize</b> this processing, enabling the entire organization to leverage AI across the data lifecycle, including</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '30%'>\n",
    "           <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "               <li><b>Prepare the environment</b>.  Package the scoring function into a more robust program, and stage it on the remote environment</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Python Pipeline</b>.  Execute the function using Python methods, and commit the resulting transformations to database tables.  Test the native ClearScape Analytics Functions</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Operationalize</b>.  Simplify the analytic pipeline to support ongoing operational transformations, on-demand analytics, and third-party applications</li>\n",
    "        </ol>\n",
    "        </td>\n",
    "        <td width = '20%'></td>\n",
    "        <td style = 'vertical-align:top'><img src = 'images/OAF_Ops.png' width = 350 ></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Check connection</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Reconnect to the database, UES, and start cluster if necessary<get_context()/p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing connection\n",
    "eng = check_and_connect(host=host, username=username, password=password, compute_group = compute_group)\n",
    "print(eng)\n",
    "    \n",
    "\n",
    "# check to see if there is a valid UES auth\n",
    "# if not, authenticate\n",
    "try:\n",
    "    demo_env = get_env(oaf_name)\n",
    "\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'value''' in str(e): #UES auth expired/required\n",
    "        if set_auth_token(ues_url = ues_url, username = username, pat_token = pat_token, pem_file = pem_file):\n",
    "            print('UES Authentication successful')\n",
    "            try:\n",
    "                demo_env = get_env(oaf_name)\n",
    "                pass\n",
    "            except Exception as l:\n",
    "                if f'''User environment '{oaf_name}' not found''' in str(l):\n",
    "                    print('User environment not found')\n",
    "                    pass\n",
    "                else:\n",
    "                    raise\n",
    "        else:\n",
    "            print('UES Authentication failed, check URL and account info')\n",
    "        pass\n",
    "    elif f'''User environment '{oaf_name}' not found''' in str(e):\n",
    "        print('User environment not found')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "# check cluster status\n",
    "check_cluster_start(compute_group = compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>3.1  Create a server-side embedding function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The goal of this exercise is to create a <b>server-side</b> function which can be staged on the analytic cluster.  This offers many improvements over the method used above;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Performance</b>.  Staging the code and dependencies in the container environment reduces the amount of I/O, since the function doesn't need to get serialized to the cluster when called</li>\n",
    "    <li><b>Operationalization</b>.  The execution pipeline can be encapsulated into a SQL statement, which allows for seamless use in ETL pipelines, dashboards, or applications that need access</li>\n",
    "    <li><b>Flexibility</b>. Developers can express much greater flexibility in how the code works to optimize for performance, stability, data cleanliness or flow logic</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>These benefits do come with some amount of additional work.  Developers need to account how data is passed in and out of the code runtime, and how to pass it back to the SQL engine to assemble and return the final resultset.  Code is executed when the user expresses an <a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>APPLY SQL function</a>;</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Input Query</b>.  The APPLY function takes a SQL query as input.  This query can be as complex as needed and include data preparation, cleansing, and/or any other set-based logic necessary to create the desired input data set.  This complexity can also be abstracted into a database view.  When using the teradata client connectors for Python or R, thise query is represented as a DataFrame or tibble.</li>\n",
    "    <li><b>Pre-processing</b>.  Based on the query plan, data is retrieved from storage (cache, block storage, or object storage) and the input query is executed.</li>\n",
    "    <li><b>Distribution</b>.  Input data can be partitioned and/or ordered to be processed on a specific container or collection of them.  For example, the user may want to process all data for a single post code in one partition, and run thousands of these in parallel.  Data can also be distributed evenly across all units of parallelism in the system</li>\n",
    "    <li><b>Input</b>.  The data for each container is passed to the runtime using tandard input (stdin)</li>\n",
    "    <li><b>Processing</b>.  The user's code executes, parsing stdin for the input data</li>\n",
    "    <li><b>Output</b>.  Data is sent out of the code block using standard output (stdout)</li>\n",
    "    <li><b>Resultset</b>.  Resultset is assembled by the analytic database, and the SQL query returns</li>\n",
    "    </ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Example server-side code block</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This is the python script used in the demonstration.  It is saved to the filesystem as \"embedding.py\".  Note here there have been multiple optimizations to improve performance at scale; specifically using batching as compared to dataframe.apply() which is much slower.</p> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import sys, csv, os\n",
    "import warnings\n",
    "import torch \n",
    "import pandas as pd\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers.utils import logging\n",
    "warnings.simplefilter('ignore')\n",
    "logging.set_verbosity_error() \n",
    "\n",
    "# model_name = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "model_path = os.environ.get('OPENAF_MODELS_DIR') + '/twitter-roberta-base-sentiment-latest'\n",
    "\n",
    "# 1. use the csv reader to parse comma-separated input\n",
    "# 2. construct the Dataframe from the resulting dictionary\n",
    "\n",
    "colNames = ['id', 'text']\n",
    "d = csv.DictReader(sys.stdin.readlines(), fieldnames = colNames)\n",
    "df = pd.DataFrame(d, columns = colNames)\n",
    "\n",
    "# Use try...except to produce an error if something goes wrong in the try block\n",
    "try:\n",
    "    # Exit gracefully if DataFrame is empty\n",
    "    # It is possible some partitions won't get any data\n",
    "    if df.empty:\n",
    "        sys.exit()\n",
    "        \n",
    "    \n",
    "    #################################\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    sentiment_task = pipeline(\"sentiment-analysis\", model = model , tokenizer = tokenizer, device = device)\n",
    "    #################################\n",
    "\n",
    "    def get_sentiment(row):\n",
    "        #sentiments = sentiment_task(texts, batch_size = 10)\n",
    "        return pd.Series(sentiment_task(row['text'])[0])\n",
    "        #return sentiments\n",
    "\n",
    "   # texts = df['text'].tolist()\n",
    "   # sentiments = get_sentiment(texts)\n",
    "    \n",
    "    # sentiment_df = pd.DataFrame(sentiments, columns=['result'])\n",
    "    \n",
    "    s_df = df.apply(get_sentiment, axis = 1)\n",
    "    df = pd.concat([df[['id']], s_df], axis=1)\n",
    "    # Egress results to the Database through standard output.\n",
    "    df.to_csv(sys.stdout, index=False, header=False)\n",
    "        \n",
    "# raise any errors back to the SQL engine\n",
    "except (SystemExit):\n",
    "    # Skip exception if system exit requested in try block\n",
    "    pass\n",
    "except:    # Specify in standard error any other error encountered\n",
    "    print(\"Script Failure :\", sys.exc_info()[0], file=sys.stderr)\n",
    "    raise\n",
    "    sys.exit()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Step 3.  Install the file and any additional artifacts</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use the install_file() method to install this python file to the container.  As a reminder, this container is persistent, so these steps need only be done infrequently.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_env.install_file('Sentiment_Extractor_twitter_roberta_base.py', replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Step 4.  Call the APPLY function </b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This function can be executed in two ways;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/teradataml-Apply-Class-for-APPLY-Table-Operator'>Python</a></b> by calling the Apply() module function</li>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>SQL</a></b> which allows for broad adoption across the enterprise</li>\n",
    "    </ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>APPLY using Python</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The process is as follows</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Construct a dictionary that will define the return columns and data types</li>\n",
    "    <li>Construct a teradataml DataFrame representing the data to be processed - note this is a \"virtual\" object representing data and logic <b>in-database</b></li>\n",
    "    <li>Execute the module function.  This constructs the function call in the database, but does not execute anything.  Note the Apply function takes several arguments - the input data, environment name, and the command to run</li>\n",
    "    <li>In order to execute the function, an \"execute_script()\" method must be called.  This method returns the server-side DataFrame representing the complete operation.  This DataFrame can be used in further processing, stored as a table, etc.</li>\n",
    "    </ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "types_dict = OrderedDict({})\n",
    "types_dict['id'] = BIGINT()\n",
    "types_dict['label'] = VARCHAR(100)\n",
    "types_dict['score'] = FLOAT()\n",
    "\n",
    "view_query = '''REPLACE VIEW Cleaned_Text_V AS\n",
    "                SELECT id,\n",
    "                    CASE \n",
    "                        WHEN text IS NULL THEN ' '\n",
    "                        ELSE regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(text , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "                    END text\n",
    "                FROM demo_ofs.cust_calls;'''\n",
    "execute_sql(view_query)\n",
    "\n",
    "tdf = DataFrame('Cleaned_Text_V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "apply_obj = Apply(data = tdf,\n",
    "                  apply_command = 'python Sentiment_Extractor_twitter_roberta_base.py',\n",
    "                  returns = types_dict,\n",
    "                  env_name = oaf_name,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Execute the function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>call execute_script(), and return a single record to the client to check the data.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# all records\n",
    "ipydisplay(apply_obj.execute_script().sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Step 5. Persist the resultset</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Simple methods for saving the results to a table for reuse.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "copy_to_sql(Apply(data = tdf,\n",
    "                  apply_command = 'python Sentiment_Extractor_twitter_roberta_base.py',\n",
    "                  returns = types_dict,\n",
    "                  env_name = oaf_name\n",
    "                 ).execute_script(), table_name = 'customer_sentiment', temporary = False, if_exists = 'replace')\n",
    "execute_sql('SELECT COUNT(*) FROM customer_sentiment;').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf_sentiment = DataFrame('customer_sentiment')\n",
    "tdf_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>APPLY using SQL</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The process is much the same, except the benefit is that this SQL can be used by a wide range of tools, applications, and dashboards; as well as automated processes.  Construct the statement using the following values:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>\n",
    "        <b>ON</b> Clause<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "        <li>Input table or query</li>\n",
    "        <li>Hash or Partition column(s)</li>\n",
    "        <li>Order by and/pr local order by directives</li>\n",
    "        <li>Return columns and data types</li></ul></li>\n",
    "    <li>Any partition column(s)</li>\n",
    "    <li>The shell command to run</li>\n",
    "    <li>Additional functional arguments</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Simplify the SQL using Views</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Create a view that represents the data preparation steps.  In this example, the preparation tasks include removing NULLs and any special characters.  Note the same SQL used to contstruct the teradataml DataFrame is used here.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qry = '''\n",
    "    REPLACE VIEW prepared_data_V AS\n",
    "    \n",
    "SELECT id,\n",
    "    CASE \n",
    "        WHEN text IS NULL THEN ' '\n",
    "        ELSE regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(text , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END text\n",
    "    FROM demo_ofs.cust_calls;\n",
    "    \n",
    "    '''\n",
    "\n",
    "# execute the sql against the database\n",
    "execute_sql(qry)\n",
    "\n",
    "# check the data\n",
    "execute_sql('SELECT TOP 1 * FROM prepared_data_V;').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Construct the APPLY Query</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use the view as input data, provide \"returns\" payload and required parameters.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qry = f'''\n",
    "SELECT * FROM Apply(\n",
    "    ON prepared_data_V\n",
    "    PARTITION BY ANY\n",
    "    \n",
    "    returns(id BIGINT, label VARCHAR(100), score FLOAT) \n",
    "    USING\n",
    "    \n",
    "    APPLY_COMMAND('python Sentiment_Extractor_twitter_roberta_base.py')\n",
    "    ENVIRONMENT('{oaf_name}')\n",
    "    STYLE('csv')\n",
    "    delimiter(',') \n",
    ") as d;'''\n",
    "\n",
    "\n",
    "# execute the query on the server, and return the first record\n",
    "execute_sql(qry).fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Simplify the APPLY using a view</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Construct a database view using the query above.  Now this simple query can be embedded in operational processing, ETL functions, or the like.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view_qry = f'''REPLACE VIEW simplified_sentiment_V AS {qry}\n",
    "'''\n",
    "\n",
    "execute_sql(view_qry);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT TOP 10 * FROM simplified_sentiment_V', eng)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Conclusion - Operationalizing AI-powered analytics</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The preceding demo showed two methods for operationalizing the model execution; using python syntax, or embedding it as a simplified SQL view.  The former allows for developers and data scientists to easily embed this processing in their existing or new applications and workflows.  The latter allows for broad, democratized adoption across the data lifecycle and enterprise - enabling this analytic processing in ETL for data prep and transformation tasks, and in production to power dashboards and/or BI tools.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Cleanup</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Stop the cluster, remove the environment (if desired), and drop views created in the demonstrations.  Finally, disconnect from the database.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = check_cluster_stop(compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Optional - remove environment and artifacts</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uninstall the libraries from the environment first before removing it\n",
    "demo_env.uninstall_lib(libs = demo_env.libs['name'].to_list())\n",
    "remove_env(oaf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql('DROP VIEW simplified_sentiment_V;');\n",
    "execute_sql('DROP VIEW prepared_data_V;');\n",
    "execute_sql('DROP VIEW Cleaned_Text_V;');\n",
    "execute_sql('DROP TABLE customer_sentiment;');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
