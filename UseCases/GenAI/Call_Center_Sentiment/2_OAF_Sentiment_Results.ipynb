{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prostate-driving",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Sentiment Analysis Using Vantage and Open Analytics Framework Analytic GPU Clusters\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:28px;font-family:Arial;color:#00233C'><b>Demonstration Overview</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration illustrates an operationalized end-to-end process of utilizing VantageCloud Lake <b>GPU-enabled Analytic Cluster</b> architecture to run open-source large language models at massive parallelism and scale.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This notebook illustrates the final step of a GPU-augmented analytic pipeline.  In the previous demonstration, we reviewed;</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Container Management</b>.  Administrators can create and manage <b>secure, custom</b> runtime containers that will host any number of models and model artifacts to unlock GPU-augmented analytics</li>\n",
    "    <li><b>Data Prep with Sentiment Extraction</b>. Developers will use the Hugging Face cardiffnlp/twitter-roberta-base-sentiment-latest model to extract user sentiment from Call Center transcripts</li>\n",
    "    <li><b>Operationalization</b>. Combine the data prep and transformation steps with powerful native <b>ClearScape Analytics</b> functions against the data sets to create a scalable, on-demand Sentiment extraction function</li>\n",
    "    </ol>\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:28px;font-family:Arial;color:#00233C'><b>Understanding Customer Sentiment</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this final demonstraion, we will illustrate various methods for visualizing the customer sentiment.</p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e0798-9db7-4504-9823-dfa731f86d0c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Installation</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If necessary, install required client packages for the demonstrations.  User may need to restart the Jupyter kernel after installation.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f35b2-c07a-4827-8658-3ffae89b15b1",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Imports</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Standard practice to import required packages and libraries; execute this cell to import packages for Teradata automation as well as machine learning, analytics, utility, and data management packages.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-greek",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.subplots as subplots\n",
    "\n",
    "from teradataml import *\n",
    "from oaf_utils import *\n",
    "from teradatasqlalchemy.types import *\n",
    "from time import sleep\n",
    "import csv, sys, os, warnings\n",
    "from collections import OrderedDict\n",
    "\n",
    "from IPython.display import clear_output , display as ipydisplay\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "display.max_rows = 5\n",
    "display.suppress_vantage_runtime_warnings = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-drinking",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load vars json\n",
    "with open('vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "# Database login information\n",
    "host = session_vars['environment']['host']\n",
    "username = session_vars['hierarchy']['users']['business_users'][1]['username']\n",
    "password = session_vars['hierarchy']['users']['business_users'][1]['password']\n",
    "\n",
    "# UES Authentication information\n",
    "ues_url = session_vars['environment']['UES_URI']\n",
    "configure.ues_url = ues_url\n",
    "pat_token = session_vars['hierarchy']['users']['business_users'][1]['pat_token']\n",
    "pem_file = session_vars['hierarchy']['users']['business_users'][1]['key_file']\n",
    "\n",
    "\n",
    "compute_group = session_vars['hierarchy']['users']['business_users'][1]['compute_group']\n",
    "\n",
    "# container name - set here for easier notebook navigation\n",
    "### User will also be asked to change it ###\n",
    "oaf_name = 'oaf_sentiment_demo'\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f94933-ab14-4760-8637-52bb02eb1dca",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Demo 1 - Inspect the original data and extract sentiment\n",
    "  <br>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d737e1e3-f85c-40bc-8f7f-76d31935948f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Connect to the database</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>After connecting, check cluster status. Start it if necessary - note the cluster only needs to be running to execute the APPLY sections of the demo.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f67d63-3b3b-455f-9046-be7f3a7cc297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for existing connection\n",
    "eng = check_and_connect(host=host, username=username, password=password, compute_group = compute_group)\n",
    "print(eng)\n",
    "\n",
    "# check cluster status\n",
    "res = check_cluster_start(compute_group = compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50252b8d-83df-4132-8594-1056f77f669a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.1 - Inspect the Data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Simple DataFrame methods to show the data.  A teradataml DataFrame behaves like a normal pandas DataFrame, with one significant difference in that it is a reference to data on the analytic database.  This allows developers to perform familiar data mangement operations on extremely large data sets as if the data is local.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-memorabilia",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf_cust_calls = DataFrame('\"demo_ofs\".\"cust_calls\"')\n",
    "tdf_cust_calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba8ebf8-0a1d-463c-ba4a-ae1c5eb41afc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.2 - Extract Sentiment using the Hugging Face Model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the prior demonstration notebook, we created two database <b>views</b> that simplified the end-to-end process to extract sentiment using an <b>Analytic GPU Cluster</b> hosting the Hugging Face <a href = 'https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest'>twitter-roberta-base-sentiment</a> Sentiment Extractor.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The steps performed in that demonstration include:</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '30%'>\n",
    "           <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "               <li><b>Prepare the environment</b>.  Package the scoring function into a more robust program, and stage it on the remote environment</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Python Pipeline</b>.  Execute the function using Python methods, and commit the resulting transformations to database tables.  Test the native ClearScape Analytics Functions</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Operationalize</b>.  Simplify the analytic pipeline to support ongoing operational transformations, on-demand analytics, and third-party applications</li>\n",
    "        </ol>\n",
    "        </td>\n",
    "        <td width = '20%'></td>\n",
    "        <td style = 'vertical-align:top'><img src = 'images/OAF_Ops.png' width = 350 ></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>First, the query that will clean and prepare data:</p>\n",
    "\n",
    "```sql\n",
    "REPLACE VIEW prepared_data_V AS\n",
    "    SELECT id,\n",
    "    CASE \n",
    "            WHEN text IS NULL THEN ' '\n",
    "            ELSE regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(text , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END text\n",
    "    FROM demo_ofs.cust_calls;\n",
    "```\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next, the query that will execute the sentiment extraction functions in the cluster:</p>\n",
    "\n",
    "```sql\n",
    "REPLACE VIEW simplified_sentiment_V AS\n",
    "    SELECT * FROM Apply(\n",
    "        ON prepared_data_V\n",
    "        PARTITION BY ANY\n",
    "\n",
    "        returns(id BIGINT, label VARCHAR(100), score FLOAT) \n",
    "        USING\n",
    "\n",
    "        APPLY_COMMAND('python Sentiment_Extractor_twitter_roberta_base.py')\n",
    "        ENVIRONMENT('environment_name')\n",
    "        STYLE('csv')\n",
    "        delimiter(',') \n",
    "    ) as d;\n",
    "```\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-collins",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Rerun the queries to create the view:</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c453a-7715-46dd-bee4-caf5f32ae519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qry = '''\n",
    "REPLACE VIEW prepared_data_V AS\n",
    "    SELECT id,\n",
    "    CASE \n",
    "            WHEN text IS NULL THEN ' '\n",
    "            ELSE regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(text , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END text\n",
    "    FROM demo_ofs.cust_calls;\n",
    "'''\n",
    "execute_sql(qry)\n",
    "\n",
    "qry = f'''\n",
    "REPLACE VIEW simplified_sentiment_V AS\n",
    "    SELECT * FROM Apply(\n",
    "        ON prepared_data_V\n",
    "        PARTITION BY ANY\n",
    "\n",
    "        returns(id BIGINT, label VARCHAR(100), score FLOAT) \n",
    "        USING\n",
    "\n",
    "        APPLY_COMMAND('python Sentiment_Extractor_twitter_roberta_base.py')\n",
    "        ENVIRONMENT('{oaf_name}')\n",
    "        STYLE('csv')\n",
    "        delimiter(',') \n",
    "    ) as d;\n",
    "'''\n",
    "execute_sql(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdaf241-71b3-4d3f-b3c8-1e4ff00b6f8b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Use the view to inspect sentiment</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Note this is executing the python function and model, so it may take a few seconds</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae6bb3-f1d6-4ee8-8d5e-b641d10db6b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DataFrame('simplified_sentiment_V')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9dcabd-0d3b-4adb-93c1-ce57ac9a8df3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.3 - Persist the data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Teradata Python Package has simple methods for persisting the data - this is helpful to extract the sentiment once, then perform normal analytic processing moving forward.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca88cf3b-7824-439a-b983-cdd7752da1a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "copy_to_sql(DataFrame('simplified_sentiment_V'), table_name = 'customer_sentiment', temporary = True, if_exists = 'replace')\n",
    "tdf_sentiment = DataFrame('customer_sentiment')\n",
    "tdf_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0e5113-8221-4d14-80ca-a25ce7aeb7b4",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Demo 2 - Analyze customer sentiment\n",
    "  <br>\n",
    "    </p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Teradata Vantage <b>ClearScape Analytics Functions</b> offer powerful in-database capabilities for analyzing data at scale.  This sentiment data can be combined with other analytics, or used as an additional feature for churn prediction, next-best action, or any other analytic outcome.  Here we will perform some simple exploration and visualizations.  Note some visualizations return data to the client machine.  Depending on the number of records in the database, it may be more efficient to use additional in-database analytic functions.</p>\n",
    "\n",
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.1 - Sentiment Distribution</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use simple methods on the Teradata DataFrame to groupby and count records in the database.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2fe396-1193-419c-8cfa-434554e903cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf_sentiment.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a06a9bc-6944-47eb-9c95-4338553cdfce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create bar graph using Plotly Express\n",
    "df_gb = tdf_sentiment.groupby('label').count().to_pandas()\n",
    "fig = px.bar(df_gb, x='label', y='count_id', color='label',\n",
    "             labels={'count_id': 'Number of Occurrences', 'label': 'label'})\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed6f8e-0956-4639-bb05-e6eab479d455",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.2 - Word Clouds</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use client-side visualization tools to see the common terms for each negative, neutral, and positive calls.  First, join the original call transcripts to the sentiment, and use this as a filter.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09c7cb-fe97-43ff-89ee-05071b572109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf_cust_calls = DataFrame('\"demo_ofs\".\"cust_calls\"')\n",
    "tdf_joined = tdf_sentiment.join(tdf_cust_calls, on = 'id', lprefix = 'l').drop(labels = 'l_id', axis = 1)\n",
    "tdf_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-messenger",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neg = tdf_joined[tdf_joined['label'] == 'negative'].to_pandas()\n",
    "neg_text = ' '.join(neg['text'])\n",
    "\n",
    "# Replace 'X' with blank space\n",
    "modified_string = neg_text.replace('X', '')\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(modified_string)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-india",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neu = tdf_joined[tdf_joined['label'] == 'neutral'].to_pandas()\n",
    "neu_text = ' '.join(neu['text'])\n",
    "\n",
    "# Replace 'X' with blank space\n",
    "modified_string = neu_text.replace('X', '')\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(modified_string)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-diploma",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos = tdf_joined[tdf_joined['label'] == 'positive'].to_pandas()\n",
    "pos_text = ' '.join(pos['text'])\n",
    "\n",
    "# Replace 'X' with blank space\n",
    "modified_string = pos_text.replace('X', '')\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(modified_string)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ffebf3-1b5e-41fe-bfc0-d6123c8edb12",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.3 - Sentiment Strength - in-database analysis</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use the native <b>TD_Histogram</b> to analyze the distribution of strength scores for each negative, neutral sentiment.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f1bcca-3fb0-42e7-9ab1-71da7c543a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = Histogram(data = tdf_joined[tdf_joined['label'] == 'negative'], target_columns = 'score', method_type = 'STURGES').result\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a7053-5b91-4b19-9fc2-6d9c3e116656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create bar graph using Plotly Express\n",
    "neg_hist = res.to_pandas()\n",
    "fig = px.bar(neg_hist, x='MinValue', y='CountOfValues',\n",
    "             labels={'CountOfValues': 'Number of Occurrences', 'MinValue': 'score'},\n",
    "             title = 'Negative Sentiment Score Distribution',\n",
    "             color_discrete_sequence = ['red'])\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be03e7-6b82-4098-9b55-c94ca653c961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = Histogram(data = tdf_joined[tdf_joined['label'] == 'neutral'], target_columns = 'score', method_type = 'STURGES').result\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5973f28-11fe-42fd-9a02-71241acc0204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create bar graph using Plotly Express\n",
    "neu_hist = res.to_pandas()\n",
    "fig = px.bar(neu_hist, x='MinValue', y='CountOfValues',\n",
    "             labels={'CountOfValues': 'Number of Occurrences', 'MinValue': 'score'},\n",
    "             title = 'Neutral Sentiment Score Distribution',\n",
    "             color_discrete_sequence = ['yellow'])\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb1c2b-17a4-4525-a211-1a10d867417c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = Histogram(data = tdf_joined[tdf_joined['label'] == 'positive'], target_columns = 'score', method_type = 'STURGES').result\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03abe5d7-90f3-4a5a-b663-7d8d3138810b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create bar graph using Plotly Express\n",
    "pos_hist = res.to_pandas()\n",
    "fig = px.bar(neg_hist, x='MinValue', y='CountOfValues',\n",
    "             labels={'CountOfValues': 'Number of Occurrences', 'MinValue': 'score'},\n",
    "             title = 'Positive Sentiment Score Distribution',\n",
    "             color_discrete_sequence = ['green'])\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-subscriber",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-catch",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-monkey",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execute_sql('DROP VIEW prepared_data_V;');\n",
    "execute_sql('DROP VIEW simplified_sentiment_V;');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-swiss",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83959ea-12a1-4be4-b128-3c8a2cbc5343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
