{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Regulatory compliance and customer complaint analytics powered by ClearScape Analytics In-db functions, BYO-LLM, and GPU compute\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"images/TeradataLogo.png\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:28px;font-family:Arial;color:#00233C'><b>Use case</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>For financial institutions, failure to comply with regulations can have severe financial implications and reputation damage.   Monitoring employee-client communications helps to prevent irresponsible behavior. In addition, it is also required to manage customer complaints efficiently\n",
    "In this demo you will see how use power of ClearScape Analytics In-db functions, BYO-LLM and GPU compute to analyze text related to irresponsible behavior and semantic search on customer complaints.</p>\n",
    "\n",
    "<p style = 'font-size:28px;font-family:Arial;color:#00233C'><b>Demonstrations Overview</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstrations illustrate the end-to-end process of how organizations can utilize VantageCloud Lake <b>GPU-enabled Analytic Cluster</b> architecture to run open-source large language models at massive parallelism and scale, and then leverage these next-generation capabilities in ad-hoc analytics, development, and operational processing.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This notebook contains several high-level demonstrations that can be run together or individually, and are designed to illustrate;</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Container Management</b>.  Administrators can create and manage <b>secure, custom</b> runtime containers that will host any number of models and model artifacts to unlock GPU-augmented analytics</li>\n",
    "    <li><b>Data Prep with Vector Embeddings</b>. Developers will use the Hugging Face BAAI/bge-small-en-v1.5 model to generate vector embeddings for two data sets:<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "        <li><b>Consumer Complaints</b>. A subset of the Consumer Financial Protection Board Complaints <a href = 'https://catalog.data.gov/dataset/consumer-complaint-database'>database</a> data has been loaded into the VantageCloud Lake database for this demonstration</li><li><b>Semantic Search Terms</b>.  A user-defined list of natural language topics to use to perform a Semantic Search</li></ul></li>\n",
    "    <li><b>Operationalization with interactive search</b>. Combine the data prep and transformation steps with powerful native <b>ClearScape Analytics</b> functions against the data sets to derive insights at scale.  These similarity functions can rapidly identify the semantic relationship between user input and a large corpus of complaints data</li>\n",
    "    </ol>\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#00233C'>End-to-End workflow</b>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The high level process is as follows:</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;font-family:Arial;color:#00233C'>\n",
    "    <tr><td style = 'vertical-align:top' width = '40%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>The Data Scientist conducts analytics activities using his or her own python tools and packages of choice, then connects to VantageCloud Lake through teradataml client library and teradatasql python driver.</li>\n",
    "                <br>      \n",
    "                <li>Teradataml provides APIs to create and manage custom runtime environments; including custom libraries, dependencies, model artifacts, and scoring scripts.  The user can leverage these APIs to create one or many custom, dedicated environments to host their code.</li>\n",
    "                <br>\n",
    "                <li>The Data Scientist will then execute their pipeline that will;\n",
    "                    <ul style = 'width:100%;table-layout:fixed;font-family:Arial;color:#00233C'><li>Call ClearScape Analytics functions on Compute Clusters (data prep, transformation, etc.)</li>\n",
    "                        <li>Prepared data is passed to the python container running in parallel on cluster nodes.</li>\n",
    "                        <li>Results (inference/predictions) are returned as \"virtual\" dataframes; where the data resides <b>in Vantage</b></li>\n",
    "                    </ul></li>\n",
    "                <br>\n",
    "                <li>Worfklow can be operationalized using SQL, and results can be returned to common BI tools, persisted as part of an ETL process, or embedded in application code</li>\n",
    "            </ol>\n",
    "        </td><td><img src = 'images/BYOLLM_Overview.png' width = '600'></td></tr>\n",
    "</table>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Installation</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If necessary, install required client packages for the demonstrations.  User may need to restart the Jupyter kernel after installation.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Imports</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Standard practice to import required packages and libraries; execute this cell to import packages for Teradata automation as well as machine learning, analytics, utility, and data management packages.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import *\n",
    "from oaf_utils import *\n",
    "from teradatasqlalchemy.types import *\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import csv, sys, os, warnings\n",
    "from os.path import expanduser\n",
    "from collections import OrderedDict\n",
    "import ipywidgets as widgets\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from IPython.display import clear_output , display as ipydisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from itables import init_notebook_mode\n",
    "import itables.options as opt\n",
    "\n",
    "# Set display options for dataframes, plots, and warnings\n",
    "\n",
    "opt.style=\"table-layout:auto;width:auto;float:left\"\n",
    "opt.columnDefs = [{\"className\": \"dt-left\", \"targets\": \"_all\"}]\n",
    "init_notebook_mode(all_interactive=True)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "\n",
    "# load vars json\n",
    "with open('vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "# Database login information\n",
    "host = session_vars['environment']['host']\n",
    "username = session_vars['hierarchy']['users']['business_users'][1]['username']\n",
    "password = session_vars['hierarchy']['users']['business_users'][1]['password']\n",
    "\n",
    "# UES Authentication information\n",
    "ues_url = session_vars['environment']['UES_URI']\n",
    "configure.ues_url = ues_url\n",
    "pat_token = session_vars['hierarchy']['users']['business_users'][1]['pat_token']\n",
    "pem_file = session_vars['hierarchy']['users']['business_users'][1]['key_file']\n",
    "\n",
    "\n",
    "compute_group = session_vars['hierarchy']['users']['business_users'][1]['compute_group']\n",
    "\n",
    "\n",
    "# get the current python version to match deploy a custom container\n",
    "python_version = str(sys.version_info[0]) + '.' + str(sys.version_info[1])\n",
    "print(f'Using Python version {python_version} for user environment')\n",
    "\n",
    "\n",
    "# Hugging Face model for the demo\n",
    "model_name = 'BAAI/bge-small-en-v1.5'\n",
    "\n",
    "# a list of required packages to install in the custom OAF container\n",
    "# modify this if using different models or design patterns\n",
    "pkgs = ['transformers',\n",
    "        'torch',\n",
    "        'sentencepiece',\n",
    "        'pandas',\n",
    "        'numpy'\n",
    "        'sentence-transformers',\n",
    "        'dill']\n",
    "\n",
    "# container name - set here for easier notebook navigation\n",
    "### User will also be asked to change it ###\n",
    "oaf_name = 'embeddings_env_demo'\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Connect to the database</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>After connecting, check cluster status. Start it if necessary - note the cluster only needs to be running to execute the APPLY sections of the demo.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing connection\n",
    "eng = check_and_connect(host=host, username=username, password=password, compute_group = compute_group)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cluster status\n",
    "res = check_cluster_start(compute_group = compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "      Container Management\n",
    "  <br>\n",
    "    </p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Teradata Vantage Python Client Library provides simple, powerful methods for the creation and maintenance of custom Python runtime environments <b>in the VantageCloud environment</b> .  This allows practitioners complete control over the behavior and quality of their model performance and analytic accuracy running on the Analytic Cluster.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Custom environments are persistent.</b> Users only need to create these once and then can be saved, updated, or modified only as needed.</p>\n",
    "\n",
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Container Management Process</b></p>\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '40%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>Create a unique User Environment based on available base images</li>\n",
    "                <br>\n",
    "                <li>Install libraries</li>\n",
    "                <br>\n",
    "                <li>Install models and additional user artifacts</li>\n",
    "            </ol>\n",
    "        </td>\n",
    "        <td><img src = 'images/OAF_Env.png' width = '600'></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Connect to the Environment Service</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To better support integration with Cloud Services and commong automation tools; the <b > User Environment Service</b> is accessed via RESTful APIs.  These APIs can be called directly or in the examples shown below that leverage the Python Package for Teradata (teradataml) methods.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if there is a valid UES auth\n",
    "# if not, authenticate\n",
    "try:\n",
    "    demo_env = get_env(oaf_name)\n",
    "    print('Existing valid UES token')\n",
    "\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'value''' in str(e) or '''Failed to execute get_env''' in str(e):\n",
    "        if set_auth_token(ues_url = ues_url, username = username, pat_token = pat_token, pem_file = pem_file):\n",
    "            print('UES Authentication successful')\n",
    "        else:\n",
    "            print('UES Authentication failed, check URL and account info')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.  Create a Custom Container in Vantage</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If desired, the user can create a <b>new</b> custom environment by starting with a \"base\" image and customizing it.  The steps are:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>List the available \"base\" images the system supports</li>\n",
    "    <li>List any existing \"custom\" environments the user has created</li>\n",
    "    <li>If there are no custom environments, then create a new one from a base image</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new environment, or connect to an existing one\n",
    "\n",
    "\n",
    "try:\n",
    "    ipydisplay(list_user_envs())\n",
    "except Exception as e:\n",
    "    \n",
    "    if str(e).find('No user environments found') > 0:\n",
    "        print('No user environments found')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "print('Use an existing environment, or create a new one:')\n",
    "print(f'OAF Environment is set to {oaf_name}.')\n",
    "print('Enter to accept, or input a new value.')\n",
    "print('If the environment is not in the list, a new one will be created')\n",
    "i = input()\n",
    "if len(i) != 0:\n",
    "    oaf_name = i\n",
    "    print(f'OAF Environment is now {oaf_name}')\n",
    "\n",
    "try:\n",
    "    demo_env = create_env(env_name = oaf_name,\n",
    "                      base_env = f'python_{python_version}',\n",
    "                      desc = 'OAF Demo env for LLM')\n",
    "except Exception as e:\n",
    "    if str(e).find('same name already exists') > 0:\n",
    "        print('Environment already exists, obtaining a reference to it')\n",
    "        demo_env = get_env(oaf_name)\n",
    "        pass\n",
    "    elif 'Invalid value for base environment name' in str(e):\n",
    "        print('Unsupported base environment version, using defaults')\n",
    "        demo_env = create_env(env_name = oaf_name,\n",
    "                      desc = 'OAF Demo env for LLM')\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Note create_env seems to be asynchronous - sleep a bit for it to register\n",
    "sleep(5)\n",
    "\n",
    "try:\n",
    "    ipydisplay(list_user_envs())\n",
    "except Exception as e:\n",
    "    if str(e).find('No user environments found') > 0:\n",
    "        print('No user environments found')\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.  Install Dependencies</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The second step in the customization process is to install Python package dependencies. This demonstration uses the Hugging Face <a href = 'https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2'>all-MiniLM-L6-v2</a> Sentence Transformer.  Since VantageCloud Lake Analytic Clusters are secured by default against unauthorized access to the outside network, the user can load the required libraries and model using teradataml methods:\n",
    "</p> \n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>List the currently installed models and python libraries</li>\n",
    "    <li><b>If necessary</b>, install any required packages</li>\n",
    "    <li><b>If necessary</b>, install the pre-trained model.  This process takes several steps;\n",
    "        <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li>Import and download the model</li>\n",
    "            <li>Create a zip archive of the model artifacts</li>\n",
    "            <li>Call the install_model() method to load the model to the container</li>\n",
    "        </ol></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipydisplay(demo_env.models)\n",
    "\n",
    "# just showing a sample here - remove .head(5) to see them all\n",
    "ipydisplay(demo_env.libs.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>A note on package versions</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The next demonstration makes use of the DataFrame apply() method, which automatically passes the python code to the Analytic Cluster.  As such, one needs to ensue the python package versions match.  dill and pandas are required, as is any additional libraries for the use case.\n",
    "</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note</b> while not required for many OAF use cases, for this demo the required packages for the model execution must be installed in the local environment first.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install any Python add-ons needed by the script in the user environment\n",
    "# Using option asynchronous=True for an asychronous execution of the statement.\n",
    "# Note: Avoid asynchronous installation when batch-executing all notebook statements,\n",
    "#       as execution will continue even without installation being complete.\n",
    "#\n",
    "# Can install by passing a list of packages/versions\n",
    "#   Or \n",
    "# install using a requirements.txt file.\n",
    "\n",
    "# For this demo, \n",
    "# this code block will collect the current user's package versions\n",
    "# for installation into the container\n",
    "# when using dataframe.apply(), it pandas and dill are required\n",
    "# to reduce issues, match the version between client and container\n",
    "\n",
    "# import these functions inside of a function namespace\n",
    "def get_versions(pkgs):\n",
    "    local_v_pkgs = []\n",
    "    for p in pkgs:\n",
    "\n",
    "        #fix up any hyphened package names\n",
    "        p_fixed = p.replace('-', '_')\n",
    "\n",
    "        #import the packages and append the strings to the list\n",
    "        exec(f'''import {p_fixed}; local_v_pkgs.append('{p}==' + str({p_fixed}.__version__))''')\n",
    "    return local_v_pkgs\n",
    "\n",
    "v_pkgs = get_versions(pkgs)\n",
    "\n",
    "\n",
    "\n",
    "# check to see if these packages need to be installed\n",
    "# by comparing the len of the intersection of the list of required packages with the installed ones\n",
    "if not len(set([x.split('==')[0] for x in pkgs]).intersection(demo_env.libs['name'].to_list())) == len(pkgs):\n",
    "    \n",
    "    # pass the list of packages - split off any extra info from the version property e.g., plus sign\n",
    "    claim_id = demo_env.install_lib([x.split('+')[0] for x in v_pkgs], asynchronous=True)\n",
    "else:\n",
    "    print(f'All required packages are installed in the {oaf_name} environment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Monitor library installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optionally - users can monitor the library installation status using the cell below:\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try: \n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "    while stage == 'Started':\n",
    "        stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print('No installations to monitor')\n",
    "\n",
    "    \n",
    "# Verify the Python libraries have been installed correctly.\n",
    "ipydisplay(demo_env.libs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>3.  Download and install pretrained model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Open Analytics Framework containers do not have open access to the external network, which contributes to a very secure runtime environment.  As such, users will load pre-trained models using the below APIs.  For illustration purposes, the following code will check to see if the model archive exists locally and if it doesn't, will import and download it by creating a model object.  The archive will then be created and installed into the remote environment.\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if the model needs to be downloaded/archived\n",
    "\n",
    "# construct the file name for the model:\n",
    "model_fname = 'models--' + model_name.replace('/', '--')\n",
    "\n",
    "if not os.path.isfile(f'{model_fname}.zip'):\n",
    "\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import shutil\n",
    "    print('Creating Model Archive...')\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "    shutil.make_archive(model_fname, \n",
    "                        format='zip', \n",
    "                        root_dir=f'{expanduser(\"~\")}/.cache/huggingface/hub/{model_fname}/')\n",
    "else:\n",
    "    print('Local model archive exists.')\n",
    "\n",
    "# check to see if the model is already installed\n",
    "try:\n",
    "    if demo_env.models.empty: # no models installed at all\n",
    "        print('Installing Model...')\n",
    "        claim_id = demo_env.install_model(model_path = f'{model_fname}.zip', asynchronous = True)\n",
    "    elif not any(model_fname in x for x in demo_env.models['Model']): #see if model is there\n",
    "        print('Installing Model...')\n",
    "        claim_id = demo_env.install_model(model_path = f'{model_fname}.zip', asynchronous = True)\n",
    "    else:\n",
    "        print('Model already installed')\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'empty''' in str(e):\n",
    "        print('Installing Model...')\n",
    "        claim_id = demo_env.install_model(model_path = f'{model_fname}.zip', asynchronous = True)\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Monitor model installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optionally - users can monitor the model installation status using the cell below:\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try: \n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "    while stage != 'File Installed':\n",
    "        stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print('No installations to monitor')\n",
    "\n",
    "    \n",
    "# Verify the model has been installed correctly.\n",
    "demo_env.refresh()\n",
    "ipydisplay(demo_env.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Conclusion - Environment Management</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The preceding demo showed how users can perform a <b>one-time</b> configuration task to prepare a custom environment for analytic processing at scale.  Once this configuration is complete, these containers can be re-used in ad-hoc development tasks, or used for operationalizing analytics in production.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Data Prep with Vector Embeddings\n",
    "  <br>\n",
    "    </p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration will utilize the custom container environment built in the prior demonstration that uses the <a href = 'https://huggingface.co/BAAI/bge-small-en-v1.5'> Hugging Face bge-small-en-v1.5</a> pre-trained model to create vector embeddings for the two data sets:</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Consumer Complaints</b></li>\n",
    "    <li><b>Search Topics</b></li>\n",
    "    </ol>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Once complete, these embeddings will be stored in the database, which will allow for broad analysis of this data at scale using native <b>ClearScape Analytics</b> functions, and integration with operational processing</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Compute Clusters are <b>elastic and ephemeral</b>; they offer automated scale up and down based on demand, and can be turned on or off on a schedule or programmatically.  This allows for greater cost and resource efficiency, where users can turn the GPU-enable cluster on for the duration of the transformation job, then shut it down when the processing is complete.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Data Preparation Workflow</b></p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '30%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>Write a <b>local</b> function that leverages a pre-trained Language Model to create vector embeddings</li>\n",
    "                <br>\n",
    "                <li>Push this processing to the <b>GPU Analytic Cluster</b> for processing at scale</li>\n",
    "                <br>\n",
    "                <li><b>Optimize</b> the embedding function to run at scale to maximize GPU throughput</li>\n",
    "                <br>\n",
    "                <li><b>Execute batch embedding</b> to store a vector representation of all consumer complaints</li>\n",
    "            </ol>\n",
    "        </td>\n",
    "        <td style = 'vertical-align:top'>\n",
    "            <img src = 'images/local_remote_functions.png'>\n",
    "        <br>\n",
    "        <img src = 'images/optimize.png'></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Check connection</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Check database and UES connection</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing connection\n",
    "eng = check_and_connect(host=host, username=username, password=password, compute_group = compute_group)\n",
    "print(eng)\n",
    "    \n",
    "\n",
    "# check to see if there is a valid UES auth\n",
    "# if not, authenticate\n",
    "try:\n",
    "    demo_env = get_env(oaf_name)\n",
    "\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'value''' in str(e) or '''Failed to execute get_env''' in str(e): #UES auth expired/required\n",
    "        if set_auth_token(ues_url = ues_url, username = username, pat_token = pat_token, pem_file = pem_file):\n",
    "            print('UES Authentication successful')\n",
    "            try:\n",
    "                demo_env = get_env(oaf_name)\n",
    "                pass\n",
    "            except Exception as l:\n",
    "                if f'''User environment '{oaf_name}' not found''' in str(l):\n",
    "                    print('User environment not found')\n",
    "                    pass\n",
    "                else:\n",
    "                    raise\n",
    "        else:\n",
    "            print('UES Authentication failed, check URL and account info')\n",
    "        pass\n",
    "    elif f'''User environment '{oaf_name}' not found''' in str(e):\n",
    "        print('User environment not found')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "# check cluster status\n",
    "check_cluster_start(compute_group = compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.  Create a client-side embedding function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The goal of this exercise is to create a client-side function which can be \"pushed\" to the analytic cluster for processing at scale.  There are a few minor enhancements here to improve performance and usability in this remote environment:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Imports</b>.  By default, the teradataml python client will package the code, objects, and dependencies and serialize it to the analytic cluster.  Users can make this more efficient by staging these objects before hand (done in the first demo of this notebook).  <b>Important</b> - place the larger libraries (sentence_transformers and torch) inside the function so they won't be registered as new dependencies that need to be installed.</li>\n",
    "    <li><b>GPU Drivers</b>.  Since this function will run both on the client (CPU) and cluster (GPU), place a conditional to check</li>\n",
    "    </ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(row):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import torch\n",
    "    \n",
    "    model = SentenceTransformer('BAAI/bge-small-en-v1.5') #'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    \n",
    "    # check for NVIDIA drivers\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # create series from the embeddings list that is returned\n",
    "    # m_out = model.encode(row['InputText'], normalize_embeddings=True, device = 'cuda')\n",
    "    # print(m_out)\n",
    "    embeddings = model.encode(row['InputText'], device = device, convert_to_tensor=True) #normalize_embeddings=True,\n",
    "    # print(s)\n",
    "    #concat them together\n",
    "    row = pd.concat([row, pd.Series(embeddings.cpu().numpy())], axis = 0)\n",
    "    \n",
    "    # return row\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Test the function on local data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Python pandas provides an apply() method to execute the function across all rows in the DataFrame</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':[1,2], 'InputText':['hello world', 'hello back']})\n",
    "\n",
    "\n",
    "df.apply(create_embeddings, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2. Push this function to the analytic cluster</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Similar to pandas, the teradataml package provides an apply() method which is called in a similar manner, except it runs <b>in parallel on</b> the cluster, leveraging the GPU infrastructure and the MPP processing capabilities of Vantage.</p>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Inspect the Data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Simple DataFrame methods to show the data.  A <b>teradataml DataFrame</b> behaves like a normal pandas DataFrame, with one significant difference in that it is a reference to data on the analytic database.  This allows developers to perform familiar data mangement operations on extremely large data sets as if the data is local.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comments = DataFrame('\"demo_ofs\".\"CFPB_Complaints\"')\n",
    "\n",
    "ipydisplay(tdf_comments.to_pandas(num_rows = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Prepare to execute the apply method</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>When using the teradataml apply method,there are some differences in how data is passed in and out of the multiple runtime containers on the distributed nodes.  This offers a great deal of processing power, but also requires some additional considerations when calling the method:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Optional Return Types</b>.  If the data being returned by the function has different columns/data types than the input DataFrame, the user passes these as dictionary value to the keyword argument</li>\n",
    "    <li><b>Data Preparation</b>.  Of course, data preparation and cleansing can be performed inside the embeddings function using python. However, the unique architecture of the <b>Teradata Vantage</b> analytic database, is that users can execute powerful native data preparation functions that will operate at extreme scale and performance</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "types_dict = OrderedDict({})\n",
    "types_dict['id'] = BIGINT()\n",
    "types_dict['InputText'] = VARCHAR(1024)\n",
    "\n",
    "for i in range(384):\n",
    "    key = '\"' + str(i) + '\"'\n",
    "    types_dict[key] = FLOAT()\n",
    "\n",
    "tdf = DataFrame.from_query('''SELECT TOP 10 id,\n",
    "    CASE \n",
    "        WHEN txt IS NULL THEN ' '\n",
    "        ELSE regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(txt , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END InputText\n",
    "    FROM demo_ofs.CFPB_Complaints;''')\n",
    "\n",
    "tdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Execute the function on the nodes</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Call the apply method on the teradataml DataFrame.  This will push the function to the analytic nodes for processing in parallel.  Data is returned as another teradataml DataFrame, which represents the entire result set of the operation.  For this example, additional method arguments include:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Function</b>.  The name of the function to pass - this is the original client-side function written above</li>\n",
    "    <li><b>Environment</b>.  The custom runtime environment with the models and dependencies loaded</li>\n",
    "    <li><b>Return types</b>. OrderedDict that represents the column names and data types</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe representing the embeddings\n",
    "tdf_embedded = tdf.apply(lambda row: create_embeddings(row),\n",
    "                    env_name = demo_env, \n",
    "                    returns = types_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Check the data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now - users can create a table with these embeddings, use it in additional analytics, or operationalize this as part of a pipeline.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipydisplay(tdf_embedded.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>3.  Create a server-side embedding function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The goal of this exercise is to create a <b>server-side</b> function which can be staged on the analytic cluster.  This offers many improvements over the method used above;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Performance</b>.  Staging the code and dependencies in the container environment reduces the amount of I/O, since the function doesn't need to get serialized to the cluster when called</li>\n",
    "    <li><b>Operationalization</b>.  The execution pipeline can be encapsulated into a SQL statement, which allows for seamless use in ETL pipelines, dashboards, or applications that need access</li>\n",
    "    <li><b>Flexibility</b>. Developers can express much greater flexibility in how the code works to optimize for performance, stability, data cleanliness or flow logic</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>These benefits do come with some amount of additional work.  Developers need to account how data is passed in and out of the code runtime, and how to pass it back to the SQL engine to assemble and return the final resultset.  Code is executed when the user expresses an <a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>APPLY SQL function</a>;</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Input Query</b>.  The APPLY function takes a SQL query as input.  This query can be as complex as needed and include data preparation, cleansing, and/or any other set-based logic necessary to create the desired input data set.  This complexity can also be abstracted into a database view.  When using the teradata client connectors for Python or R, thise query is represented as a DataFrame or tibble.</li>\n",
    "    <li><b>Pre-processing</b>.  Based on the query plan, data is retrieved from storage (cache, block storage, or object storage) and the input query is executed.</li>\n",
    "    <li><b>Distribution</b>.  Input data can be partitioned and/or ordered to be processed on a specific container or collection of them.  For example, the user may want to process all data for a single post code in one partition, and run thousands of these in parallel.  Data can also be distributed evenly across all units of parallelism in the system</li>\n",
    "    <li><b>Input</b>.  The data for each container is passed to the runtime using tandard input (stdin)</li>\n",
    "    <li><b>Processing</b>.  The user's code executes, parsing stdin for the input data</li>\n",
    "    <li><b>Output</b>.  Data is sent out of the code block using standard output (stdout)</li>\n",
    "    <li><b>Resultset</b>.  Resultset is assembled by the analytic database, and the SQL query returns</li>\n",
    "    </ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Example server-side code block</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This is the python script used in the demonstration.  It is saved to the filesystem as \"embedding.py\".  Note here there have been multiple optimizations to improve performance at scale; specifically using batching as compared to dataframe.apply() which is much slower.</p> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import sys, csv\n",
    "import warnings\n",
    "import torch \n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "# 1. use the csv reader to parse comma-separated input\n",
    "# 2. construct the Dataframe from the resulting dictionary\n",
    "\n",
    "colNames = ['id', 'text']\n",
    "d = csv.DictReader(sys.stdin.readlines(), fieldnames = colNames)\n",
    "df = pd.DataFrame(d, columns = colNames)\n",
    "\n",
    "# Use try...except to produce an error if something goes wrong in the try block\n",
    "try:\n",
    "    # Exit gracefully if DataFrame is empty\n",
    "    # It is possible some partitions won't get any data\n",
    "    if df.empty:\n",
    "        sys.exit()\n",
    "        \n",
    "    \n",
    "    model = SentenceTransformer('BAAI/bge-small-en-v1.5')\n",
    "    #################################\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device) #<-- let's load the model once in the gpu (when gpu available)\n",
    "    # I fear that in the previous code, the model was loaded for each rows\n",
    "    #################################\n",
    "\n",
    "\n",
    "\n",
    "# Read data from stdin, and construct a Pandas DataFrame #\n",
    "# Data can also be read/processed directly from stdin i\n",
    "    def create_embeddings(texts):\n",
    "        # Encode texts using the model in batches\n",
    "        with torch.no_grad(): # just to be sure, I am not sure if gradient computations are turned off by SentenceTransformer\n",
    "            embeddings = model.encode(texts, device=device, batch_size=2048, convert_to_tensor=True)\n",
    "        return embeddings.cpu().numpy() # here we go back to cpu\n",
    "    ####################################################\n",
    "\n",
    "\n",
    "    ########################################################\n",
    "    # There is no need to use a apply and do row by row\n",
    "    texts = df['text'].tolist()\n",
    "    embeddings = create_embeddings(texts)\n",
    "    # Now the embeddings are calculated, we concatenate them in the dataframe:\n",
    "    embedding_cols = [f'V{i}' for i in range(embeddings.shape[1])]\n",
    "    embedding_df = pd.DataFrame(embeddings, columns=embedding_cols)\n",
    "    df = pd.concat([df[['id']], embedding_df], axis=1)\n",
    "    \n",
    "\n",
    "    # Egress results to the Database through standard output.\n",
    "    # iterrrows generates a Series, iterate through the series to construct\n",
    "    # a comma-separated output string\n",
    "    for index, value in df.iterrows():\n",
    "        my_str = ''\n",
    "        for val in value.index:\n",
    "            my_str = my_str + str(value[val]) + ','\n",
    "        print(my_str[:-1])\n",
    "        \n",
    "# raise any errors back to the SQL engine\n",
    "except (SystemExit):\n",
    "    # Skip exception if system exit requested in try block\n",
    "    pass\n",
    "except:    # Specify in standard error any other error encountered\n",
    "    print(\"Script Failure :\", sys.exc_info()[0], file=sys.stderr)\n",
    "    raise\n",
    "    sys.exit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Install the file and any additional artifacts</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use the install_file() method to install this python file to the container.  As a reminder, this container is persistent, so these steps need only be done infrequently.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_env.install_file('embedding_bge_small_en.py', replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Call the APPLY function </b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This function can be executed in two ways;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/teradataml-Apply-Class-for-APPLY-Table-Operator'>Python</a></b> by calling the Apply() module function</li>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>SQL</a></b> which allows for broad adoption across the enterprise</li>\n",
    "    </ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>APPLY using Python</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The process is as follows</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Construct a dictionary that will define the return columns and data types</li>\n",
    "    <li>Construct a teradataml DataFrame representing the data to be processed - note this is a \"virtual\" object representing data and logic <b>in-database</b></li>\n",
    "    <li>Execute the module function.  This constructs the function call in the database, but does not execute anything.  Note the Apply function takes several arguments - the input data, environment name, and the command to run</li>\n",
    "    <li>In order to execute the function, an \"execute_script()\" method must be called.  This method returns the server-side DataFrame representing the complete operation.  This DataFrame can be used in further processing, stored as a table, etc.</li>\n",
    "    </ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_dict = OrderedDict({})\n",
    "types_dict['id'] = BIGINT()\n",
    "\n",
    "for i in range(384):\n",
    "    key = '\"' + str(i) + '\"'\n",
    "    types_dict[key] = FLOAT()\n",
    "    \n",
    "\n",
    "\n",
    "view_query = '''REPLACE VIEW Cleaned_Text_V AS\n",
    "                SELECT id,\n",
    "                    CASE \n",
    "                        WHEN txt IS NULL THEN ' '\n",
    "                        ELSE regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(txt , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "                    END text\n",
    "                FROM demo_ofs.CFPB_Complaints;'''\n",
    "execute_sql(view_query)\n",
    "\n",
    "tdf = DataFrame('Cleaned_Text_V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_obj = Apply(data = tdf.iloc[:1000],\n",
    "                  apply_command = 'python embedding_bge_small_en.py',\n",
    "                  returns = types_dict,\n",
    "                  env_name = oaf_name,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Execute the function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Call execute_script(), and return a single record to the client to check the data.  Note there is some amount of startup time, since the container must start up and receive data.  These use cases get much more effective as the volume of the data being processed increases</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ipydisplay(apply_obj.execute_script().sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>4. Persist the resultset</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Simple methods for saving the results to a table for reuse.  The copy_to_sql() function will persist the contents of the DataFrame to a table in the database.  The performance optimizations used in the cluster-side embedding function will process records rapidly at scale.</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>On a single-node GPU cluster, this will take approximately 2 minutes to process all records</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "copy_to_sql(Apply(data = tdf,\n",
    "                  apply_command = 'python embedding_bge_small_en.py',\n",
    "                  returns = types_dict,\n",
    "                  env_name = oaf_name\n",
    "                 ).execute_script(), table_name = 'CFPB_embeddings', schema_name = 'demo_ofs', if_exists = 'replace')\n",
    "execute_sql('SELECT COUNT(1) FROM demo_ofs.CFPB_embeddings;').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Construct a \"topics\" table</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Create a small table of search topics, write it to the database.  Next, create an embeddings table out of those topics.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id': [1,2,3,4,5,6],\n",
    "      'txt': ['Fradulent activity with Debit Cards at Wells Fargo',\n",
    "              'Identity theft issues at Citibank',\n",
    "              'Multiple account openings without authorization',\n",
    "              'Irresponsible behavior by customer support',\n",
    "              'App issues when transacting with bank',\n",
    "              'Cant get money out of ATM',\n",
    "              ]})\n",
    "print('Writing topics table to the database')\n",
    "copy_to_sql(df,table_name='topics_of_interest', schema_name = 'demo_ofs', \n",
    "            if_exists='replace', index=False, types = OrderedDict({'id':BIGINT()}))\n",
    "\n",
    "print('Creating embeddings table')\n",
    "apply_obj = Apply(data = DataFrame('\"demo_ofs\".\"topics_of_interest\"'),\n",
    "                  apply_command = 'python embedding_bge_small_en.py',\n",
    "                  returns = types_dict,\n",
    "                  env_name = oaf_name\n",
    "                 )\n",
    "\n",
    "copy_to_sql(apply_obj.execute_script(), table_name = 'topics_embeddings', schema_name = 'demo_ofs', if_exists = 'replace')\n",
    "\n",
    "print('Embedding complete')\n",
    "print('Sample of the data:')\n",
    "ipydisplay(execute_sql('SELECT TOP 1 id, \"0\", \"1\" FROM demo_ofs.topics_embeddings;').fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Conclusion - executing custom code against GPU-enabled analytic clusters</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The preceding demo showed how users can use simple, familiar patters to execute powerful AI models <b>at scale</b> for development and operational processing.  This processing can be used in batch data preparation tasks, or operationalized as the below example will show.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Operationalizing interactive AI-powered analytics\n",
    "  <br>\n",
    "    </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration will illustrate how developers can take the next step in the process to <b>operationalize</b> this processing, enabling the entire organization to leverage AI across the data lifecycle, including</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '30%'>\n",
    "           <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "               <li><b>Calculate Semantic Similarity</b>.  Execute native vector distance functions to check similarity between the search topics and complaints embeddings</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Examine Results</b>.  Generate a data table and word cloud to check for other contextual patterns</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Create an interactive exerience</b>.  Create an operational pipeline to take interactive semantic search terms</li>\n",
    "        </ol>\n",
    "        </td>\n",
    "        <td width = '20%'></td>\n",
    "        <td style = 'vertical-align:top'><img src = 'images/cos_similarity.jpeg' width = 350 ></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Check connection</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Reconnect to the database, UES, and start cluster if necessary<get_context()/p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing connection\n",
    "eng = check_and_connect(host=host, username=username, password=password, compute_group = compute_group)\n",
    "print(eng)\n",
    "    \n",
    "\n",
    "# check to see if there is a valid UES auth\n",
    "# if not, authenticate\n",
    "try:\n",
    "    demo_env = get_env(oaf_name)\n",
    "\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'value''' in str(e) or '''Failed to execute get_env''' in str(e): #UES auth expired/required\n",
    "        if set_auth_token(ues_url = ues_url, username = username, pat_token = pat_token, pem_file = pem_file):\n",
    "            print('UES Authentication successful')\n",
    "            try:\n",
    "                demo_env = get_env(oaf_name)\n",
    "                pass\n",
    "            except Exception as l:\n",
    "                if f'''User environment '{oaf_name}' not found''' in str(l):\n",
    "                    print('User environment not found')\n",
    "                    pass\n",
    "                else:\n",
    "                    raise\n",
    "        else:\n",
    "            print('UES Authentication failed, check URL and account info')\n",
    "        pass\n",
    "    elif f'''User environment '{oaf_name}' not found''' in str(e):\n",
    "        print('User environment not found')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "# check cluster status\n",
    "check_cluster_start(compute_group = compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>1.  Calculate semantic similarity</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>First, create a reference to the prepared data sets.  Next, execute the native <b>ClearScape Analytics</b> VectorDistance function.</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Database-Analytic-Functions/Model-Training-Functions/TD_VectorDistance'>TD_VectorDistance</a> function accepts a table of target vectors and a table of reference vectors and returns a table that contains the distance between target-reference pairs. The function computes the distance between the target pair and the reference pair from the same table if you provide only one table as the input.  This function can be called using the terdataml python package, or native SQL.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Complaints embeddings:')\n",
    "tdf_target = DataFrame('\"demo_ofs\".\"CFPB_embeddings\"')\n",
    "ipydisplay(tdf_target.sample(1))\n",
    "print('Topics embeddings:')\n",
    "tdf_reference = DataFrame('\"demo_ofs\".\"topics_embeddings\"')\n",
    "ipydisplay(tdf_reference.sample(1))\n",
    "\n",
    "print('Calculating vector distance')\n",
    "feature_list = ['\"' + str(i) + '\"' for i in range(384)]\n",
    "res_tdf = VectorDistance(target_data = tdf_target, \n",
    "                   reference_data = tdf_reference, \n",
    "                   target_id_column = 'id',\n",
    "                   target_feature_columns = feature_list,\n",
    "                   ref_id_column = 'id',\n",
    "                   ref_feature_columns = feature_list,\n",
    "                   distance_measure = 'cosine',\n",
    "                   topk = 1\n",
    "                  ).result\n",
    "print('Analysis complete, raw output: ')\n",
    "res_tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2.  Create user-friendly results</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>First, use various teradataml methods to join the original comments data to the distance calculations.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame references to the original data sets\n",
    "tdf_topics = DataFrame('\"demo_ofs\".\"topics_of_interest\"')\n",
    "tdf_full = DataFrame.from_query('''SELECT id,\n",
    "    CASE \n",
    "        WHEN txt IS NULL THEN ' '\n",
    "        ELSE regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(txt , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END text\n",
    "    FROM demo_ofs.CFPB_Complaints;''')\n",
    "\n",
    "print('Joining topics text to distance calculations')\n",
    "tdf_final = res_tdf.join(tdf_topics, on = 'reference_id = id')\n",
    "print('Joining comments text to distance calculations')\n",
    "tdf_final = tdf_final.join(tdf_full, on = 'target_id = id', lsuffix = 'l')\n",
    "tdf_final = tdf_final.assign(similarity = 1 - tdf_final['distance'])\n",
    "tdf_final = tdf_final.assign(topic = tdf_final['txt'])\n",
    "tdf_final = tdf_final.assign(comment = tdf_final['text'])\n",
    "tdf_final = tdf_final.assign(topic_id = tdf_final['reference_id'])\n",
    "tdf_final = tdf_final.drop(['target_id', 'reference_id', 'id_l', 'txt', 'text'], axis = 1)\n",
    "\n",
    "print('Writing final results to a table')\n",
    "copy_to_sql(tdf_final, table_name = 'similarity_results', if_exists = 'replace')\n",
    "ipydisplay(DataFrame('similarity_results').head(2).to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Visualize results</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use client-side widgets to provide an interactive experience.  Return ten rows of selected results <b>only</b>.  Then, generate a Word Cloud to represent frequent terms.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_results = DataFrame('similarity_results')\n",
    "topics_list = DataFrame('\"demo_ofs\".\"topics_of_interest\"').to_pandas()['txt'].to_list()\n",
    "\n",
    "d = widgets.Dropdown(options=topics_list)\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        with output:\n",
    "            clear_output()\n",
    "            local_df = tdf_results[tdf_results['topic'] == change['new']].set_index('distance').iloc[:10].to_pandas().drop('topic', axis = 1)\n",
    "            ipydisplay(local_df)\n",
    "            text = \" \".join(comment for comment in local_df['comment'])\n",
    "            stopwords = set(STOPWORDS)\n",
    "            wordcloud = WordCloud(stopwords = stopwords, width = 800, height=400, \n",
    "                                  max_words=100, min_word_length=1, \n",
    "                                  collocations = True, background_color = 'white').generate(text)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.imshow(wordcloud, interpolation='gaussian')\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Word Cloud for Search Topic')\n",
    "            plt.show()\n",
    "            \n",
    "d.observe(on_change)\n",
    "\n",
    "print('Select Topic to Search:')\n",
    "ipydisplay(d, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>3.  Interactive Semantic Search</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration will illustrate an example of how to <b>operationalize</b> the combined Hugging Face embeddings, and native analytics performed in the steps above.  In this section, the python methods are replaced with SQL, which allows for broad adoption and re-use by many tools and applications.  Steps are as follow:</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Construct the SQL pipeline</b>.  This query will combine all the analytic steps above into a single expression:<ol style = 'font-size:16px;font-family:Arial;color:#00233C'><li>Embedding incoming search term using the Hugging Face model</li>\n",
    "        <li>Passing the vector values to the TD_VectorDistance function</li>\n",
    "        <li>Joining the distance measurements to the original comments</li>\n",
    "        <li>Returning search results back to the user</li></ol></li>\n",
    "    <li><b>User</b> Submits search term to the query</li>\n",
    "    <li><b>Responses</b> are sent back to the client</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Embed incoming data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Note that each of these examples below executes this APPLY function.  There is a certain amount of overhead in launching the container and performing the inference.  It may be recommended that users embed the incoming data before passing it to SQL, which may improve interactive performance.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>APPLY using SQL</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The process is much the same as above when python was used, except the benefit is that this SQL can be used by a wide range of tools, applications, and dashboards; as well as automated processes.  Construct the statement using the following values:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>\n",
    "        <b>ON</b> Clause<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "        <li>Input table or query</li>\n",
    "        <li>Return columns and data types</li></ul></li>\n",
    "    <li>Any partition column(s)</li>\n",
    "    <li>The shell command to run</li>\n",
    "    <li>Additional functional arguments</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_topic = input('Please Enter Search Term: ')\n",
    "apply_qry = f'''\n",
    "SELECT * FROM Apply(\n",
    "    ON (SELECT 1 as id, '{search_topic}' as txt)\n",
    "    PARTITION BY ANY\n",
    "    \n",
    "    returns(id BIGINT, \"0\" FLOAT, \"1\" FLOAT, \"2\" FLOAT, \"3\" FLOAT, \"4\" FLOAT, \"5\" FLOAT, \"6\" FLOAT, \"7\" FLOAT, \"8\" FLOAT, \"9\" FLOAT, \"10\" FLOAT, \"11\" FLOAT, \"12\" FLOAT, \"13\" FLOAT, \"14\" FLOAT, \"15\" FLOAT, \"16\" FLOAT, \"17\" FLOAT, \"18\" FLOAT, \"19\" FLOAT, \"20\" FLOAT, \"21\" FLOAT, \"22\" FLOAT, \"23\" FLOAT, \"24\" FLOAT, \"25\" FLOAT, \"26\" FLOAT, \"27\" FLOAT, \"28\" FLOAT, \"29\" FLOAT, \"30\" FLOAT, \"31\" FLOAT, \"32\" FLOAT, \"33\" FLOAT, \"34\" FLOAT, \"35\" FLOAT, \"36\" FLOAT, \"37\" FLOAT, \"38\" FLOAT, \"39\" FLOAT, \"40\" FLOAT, \"41\" FLOAT, \"42\" FLOAT, \"43\" FLOAT, \"44\" FLOAT, \"45\" FLOAT, \"46\" FLOAT, \"47\" FLOAT, \"48\" FLOAT, \"49\" FLOAT, \"50\" FLOAT, \"51\" FLOAT, \"52\" FLOAT, \"53\" FLOAT, \"54\" FLOAT, \"55\" FLOAT, \"56\" FLOAT, \"57\" FLOAT, \"58\" FLOAT, \"59\" FLOAT, \"60\" FLOAT, \"61\" FLOAT, \"62\" FLOAT, \"63\" FLOAT, \"64\" FLOAT, \"65\" FLOAT, \"66\" FLOAT, \"67\" FLOAT, \"68\" FLOAT, \"69\" FLOAT, \"70\" FLOAT, \"71\" FLOAT, \"72\" FLOAT, \"73\" FLOAT, \"74\" FLOAT, \"75\" FLOAT, \"76\" FLOAT, \"77\" FLOAT, \"78\" FLOAT, \"79\" FLOAT, \"80\" FLOAT, \"81\" FLOAT, \"82\" FLOAT, \"83\" FLOAT, \"84\" FLOAT, \"85\" FLOAT, \"86\" FLOAT, \"87\" FLOAT, \"88\" FLOAT, \"89\" FLOAT, \"90\" FLOAT, \"91\" FLOAT, \"92\" FLOAT, \"93\" FLOAT, \"94\" FLOAT, \"95\" FLOAT, \"96\" FLOAT, \"97\" FLOAT, \"98\" FLOAT, \"99\" FLOAT, \"100\" FLOAT, \"101\" FLOAT, \"102\" FLOAT, \"103\" FLOAT, \"104\" FLOAT, \"105\" FLOAT, \"106\" FLOAT, \"107\" FLOAT, \"108\" FLOAT, \"109\" FLOAT, \"110\" FLOAT, \"111\" FLOAT, \"112\" FLOAT, \"113\" FLOAT, \"114\" FLOAT, \"115\" FLOAT, \"116\" FLOAT, \"117\" FLOAT, \"118\" FLOAT, \"119\" FLOAT, \"120\" FLOAT, \"121\" FLOAT, \"122\" FLOAT, \"123\" FLOAT, \"124\" FLOAT, \"125\" FLOAT, \"126\" FLOAT, \"127\" FLOAT, \"128\" FLOAT, \"129\" FLOAT, \"130\" FLOAT, \"131\" FLOAT, \"132\" FLOAT, \"133\" FLOAT, \"134\" FLOAT, \"135\" FLOAT, \"136\" FLOAT, \"137\" FLOAT, \"138\" FLOAT, \"139\" FLOAT, \"140\" FLOAT, \"141\" FLOAT, \"142\" FLOAT, \"143\" FLOAT, \"144\" FLOAT, \"145\" FLOAT, \"146\" FLOAT, \"147\" FLOAT, \"148\" FLOAT, \"149\" FLOAT, \"150\" FLOAT, \"151\" FLOAT, \"152\" FLOAT, \"153\" FLOAT, \"154\" FLOAT, \"155\" FLOAT, \"156\" FLOAT, \"157\" FLOAT, \"158\" FLOAT, \"159\" FLOAT, \"160\" FLOAT, \"161\" FLOAT, \"162\" FLOAT, \"163\" FLOAT, \"164\" FLOAT, \"165\" FLOAT, \"166\" FLOAT, \"167\" FLOAT, \"168\" FLOAT, \"169\" FLOAT, \"170\" FLOAT, \"171\" FLOAT, \"172\" FLOAT, \"173\" FLOAT, \"174\" FLOAT, \"175\" FLOAT, \"176\" FLOAT, \"177\" FLOAT, \"178\" FLOAT, \"179\" FLOAT, \"180\" FLOAT, \"181\" FLOAT, \"182\" FLOAT, \"183\" FLOAT, \"184\" FLOAT, \"185\" FLOAT, \"186\" FLOAT, \"187\" FLOAT, \"188\" FLOAT, \"189\" FLOAT, \"190\" FLOAT, \"191\" FLOAT, \"192\" FLOAT, \"193\" FLOAT, \"194\" FLOAT, \"195\" FLOAT, \"196\" FLOAT, \"197\" FLOAT, \"198\" FLOAT, \"199\" FLOAT, \"200\" FLOAT, \"201\" FLOAT, \"202\" FLOAT, \"203\" FLOAT, \"204\" FLOAT, \"205\" FLOAT, \"206\" FLOAT, \"207\" FLOAT, \"208\" FLOAT, \"209\" FLOAT, \"210\" FLOAT, \"211\" FLOAT, \"212\" FLOAT, \"213\" FLOAT, \"214\" FLOAT, \"215\" FLOAT, \"216\" FLOAT, \"217\" FLOAT, \"218\" FLOAT, \"219\" FLOAT, \"220\" FLOAT, \"221\" FLOAT, \"222\" FLOAT, \"223\" FLOAT, \"224\" FLOAT, \"225\" FLOAT, \"226\" FLOAT, \"227\" FLOAT, \"228\" FLOAT, \"229\" FLOAT, \"230\" FLOAT, \"231\" FLOAT, \"232\" FLOAT, \"233\" FLOAT, \"234\" FLOAT, \"235\" FLOAT, \"236\" FLOAT, \"237\" FLOAT, \"238\" FLOAT, \"239\" FLOAT, \"240\" FLOAT, \"241\" FLOAT, \"242\" FLOAT, \"243\" FLOAT, \"244\" FLOAT, \"245\" FLOAT, \"246\" FLOAT, \"247\" FLOAT, \"248\" FLOAT, \"249\" FLOAT, \"250\" FLOAT, \"251\" FLOAT, \"252\" FLOAT, \"253\" FLOAT, \"254\" FLOAT, \"255\" FLOAT, \"256\" FLOAT, \"257\" FLOAT, \"258\" FLOAT, \"259\" FLOAT, \"260\" FLOAT, \"261\" FLOAT, \"262\" FLOAT, \"263\" FLOAT, \"264\" FLOAT, \"265\" FLOAT, \"266\" FLOAT, \"267\" FLOAT, \"268\" FLOAT, \"269\" FLOAT, \"270\" FLOAT, \"271\" FLOAT, \"272\" FLOAT, \"273\" FLOAT, \"274\" FLOAT, \"275\" FLOAT, \"276\" FLOAT, \"277\" FLOAT, \"278\" FLOAT, \"279\" FLOAT, \"280\" FLOAT, \"281\" FLOAT, \"282\" FLOAT, \"283\" FLOAT, \"284\" FLOAT, \"285\" FLOAT, \"286\" FLOAT, \"287\" FLOAT, \"288\" FLOAT, \"289\" FLOAT, \"290\" FLOAT, \"291\" FLOAT, \"292\" FLOAT, \"293\" FLOAT, \"294\" FLOAT, \"295\" FLOAT, \"296\" FLOAT, \"297\" FLOAT, \"298\" FLOAT, \"299\" FLOAT, \"300\" FLOAT, \"301\" FLOAT, \"302\" FLOAT, \"303\" FLOAT, \"304\" FLOAT, \"305\" FLOAT, \"306\" FLOAT, \"307\" FLOAT, \"308\" FLOAT, \"309\" FLOAT, \"310\" FLOAT, \"311\" FLOAT, \"312\" FLOAT, \"313\" FLOAT, \"314\" FLOAT, \"315\" FLOAT, \"316\" FLOAT, \"317\" FLOAT, \"318\" FLOAT, \"319\" FLOAT, \"320\" FLOAT, \"321\" FLOAT, \"322\" FLOAT, \"323\" FLOAT, \"324\" FLOAT, \"325\" FLOAT, \"326\" FLOAT, \"327\" FLOAT, \"328\" FLOAT, \"329\" FLOAT, \"330\" FLOAT, \"331\" FLOAT, \"332\" FLOAT, \"333\" FLOAT, \"334\" FLOAT, \"335\" FLOAT, \"336\" FLOAT, \"337\" FLOAT, \"338\" FLOAT, \"339\" FLOAT, \"340\" FLOAT, \"341\" FLOAT, \"342\" FLOAT, \"343\" FLOAT, \"344\" FLOAT, \"345\" FLOAT, \"346\" FLOAT, \"347\" FLOAT, \"348\" FLOAT, \"349\" FLOAT, \"350\" FLOAT, \"351\" FLOAT, \"352\" FLOAT, \"353\" FLOAT, \"354\" FLOAT, \"355\" FLOAT, \"356\" FLOAT, \"357\" FLOAT, \"358\" FLOAT, \"359\" FLOAT, \"360\" FLOAT, \"361\" FLOAT, \"362\" FLOAT, \"363\" FLOAT, \"364\" FLOAT, \"365\" FLOAT, \"366\" FLOAT, \"367\" FLOAT, \"368\" FLOAT, \"369\" FLOAT, \"370\" FLOAT, \"371\" FLOAT, \"372\" FLOAT, \"373\" FLOAT, \"374\" FLOAT, \"375\" FLOAT, \"376\" FLOAT, \"377\" FLOAT, \"378\" FLOAT, \"379\" FLOAT, \"380\" FLOAT, \"381\" FLOAT, \"382\" FLOAT, \"383\" FLOAT)\n",
    "    USING\n",
    "    \n",
    "    APPLY_COMMAND('python embedding_bge_small_en.py')\n",
    "    ENVIRONMENT('{oaf_name}')\n",
    "    STYLE('csv')\n",
    "    delimiter(',') \n",
    ") as d;'''\n",
    "\n",
    "print(f'Vector Representation of the following statement:')\n",
    "print('-------------------------')\n",
    "print(search_topic)\n",
    "print('-------------------------')\n",
    "ipydisplay(execute_sql(apply_qry).fetchone()[0:4])\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Calculate vector distance in-line</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Pass the results of the APPLY up to the TD_VectorDistance function.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_qry = f'''\n",
    "SELECT TOP 10 Target_ID, Distance, 1-Distance AS Similarity FROM TD_VectorDistance(\n",
    "    ON demo_ofs.CFPB_embeddings AS TargetTable\n",
    "    PARTITION BY ANY \n",
    "    ON ({apply_qry[:-1]}) AS ReferenceTable\n",
    "    DIMENSION\n",
    "    USING\n",
    "    TargetIDColumn('id')\n",
    "    TargetFeatureColumns('[1:384]')\n",
    "    RefIDColumn('id')\n",
    "    RefFeatureColumns('[1:384]')\n",
    "    DistanceMeasure('cosine')\n",
    "    TopK(1)\n",
    ") as dst\n",
    "ORDER BY Similarity DESC;'''\n",
    "\n",
    "print(f'Top 10 Cosine Similarity Results for \"{search_topic}\":')\n",
    "execute_sql(distance_qry).fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Join original text data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Add projections and a JOIN clause to return readable results.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_qry = f'''\n",
    "\n",
    "SELECT dt.Target_ID, cpl.txt, dt.Similarity\n",
    "FROM demo_ofs.CFPB_Complaints cpl\n",
    " INNER JOIN ({distance_qry[:-1]}) dt\n",
    "     ON dt.Target_ID = cpl.id;'''\n",
    "\n",
    "print(f'Top semantic match for \"{search_topic}\": ')\n",
    "execute_sql(join_qry).fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Expand the SQL</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Show the full query.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_to_end = f'''\n",
    "WITH aq AS (SELECT * FROM Apply(\n",
    "    ON (SELECT 1 as id, '{search_topic}' as txt)\n",
    "    PARTITION BY ANY\n",
    "    \n",
    "    returns(id BIGINT, \"0\" FLOAT, \"1\" FLOAT, \"2\" FLOAT, \"3\" FLOAT, \"4\" FLOAT, \"5\" FLOAT, \"6\" FLOAT, \"7\" FLOAT, \"8\" FLOAT, \"9\" FLOAT, \"10\" FLOAT, \"11\" FLOAT, \"12\" FLOAT, \"13\" FLOAT, \"14\" FLOAT, \"15\" FLOAT, \"16\" FLOAT, \"17\" FLOAT, \"18\" FLOAT, \"19\" FLOAT, \"20\" FLOAT, \"21\" FLOAT, \"22\" FLOAT, \"23\" FLOAT, \"24\" FLOAT, \"25\" FLOAT, \"26\" FLOAT, \"27\" FLOAT, \"28\" FLOAT, \"29\" FLOAT, \"30\" FLOAT, \"31\" FLOAT, \"32\" FLOAT, \"33\" FLOAT, \"34\" FLOAT, \"35\" FLOAT, \"36\" FLOAT, \"37\" FLOAT, \"38\" FLOAT, \"39\" FLOAT, \"40\" FLOAT, \"41\" FLOAT, \"42\" FLOAT, \"43\" FLOAT, \"44\" FLOAT, \"45\" FLOAT, \"46\" FLOAT, \"47\" FLOAT, \"48\" FLOAT, \"49\" FLOAT, \"50\" FLOAT, \"51\" FLOAT, \"52\" FLOAT, \"53\" FLOAT, \"54\" FLOAT, \"55\" FLOAT, \"56\" FLOAT, \"57\" FLOAT, \"58\" FLOAT, \"59\" FLOAT, \"60\" FLOAT, \"61\" FLOAT, \"62\" FLOAT, \"63\" FLOAT, \"64\" FLOAT, \"65\" FLOAT, \"66\" FLOAT, \"67\" FLOAT, \"68\" FLOAT, \"69\" FLOAT, \"70\" FLOAT, \"71\" FLOAT, \"72\" FLOAT, \"73\" FLOAT, \"74\" FLOAT, \"75\" FLOAT, \"76\" FLOAT, \"77\" FLOAT, \"78\" FLOAT, \"79\" FLOAT, \"80\" FLOAT, \"81\" FLOAT, \"82\" FLOAT, \"83\" FLOAT, \"84\" FLOAT, \"85\" FLOAT, \"86\" FLOAT, \"87\" FLOAT, \"88\" FLOAT, \"89\" FLOAT, \"90\" FLOAT, \"91\" FLOAT, \"92\" FLOAT, \"93\" FLOAT, \"94\" FLOAT, \"95\" FLOAT, \"96\" FLOAT, \"97\" FLOAT, \"98\" FLOAT, \"99\" FLOAT, \"100\" FLOAT, \"101\" FLOAT, \"102\" FLOAT, \"103\" FLOAT, \"104\" FLOAT, \"105\" FLOAT, \"106\" FLOAT, \"107\" FLOAT, \"108\" FLOAT, \"109\" FLOAT, \"110\" FLOAT, \"111\" FLOAT, \"112\" FLOAT, \"113\" FLOAT, \"114\" FLOAT, \"115\" FLOAT, \"116\" FLOAT, \"117\" FLOAT, \"118\" FLOAT, \"119\" FLOAT, \"120\" FLOAT, \"121\" FLOAT, \"122\" FLOAT, \"123\" FLOAT, \"124\" FLOAT, \"125\" FLOAT, \"126\" FLOAT, \"127\" FLOAT, \"128\" FLOAT, \"129\" FLOAT, \"130\" FLOAT, \"131\" FLOAT, \"132\" FLOAT, \"133\" FLOAT, \"134\" FLOAT, \"135\" FLOAT, \"136\" FLOAT, \"137\" FLOAT, \"138\" FLOAT, \"139\" FLOAT, \"140\" FLOAT, \"141\" FLOAT, \"142\" FLOAT, \"143\" FLOAT, \"144\" FLOAT, \"145\" FLOAT, \"146\" FLOAT, \"147\" FLOAT, \"148\" FLOAT, \"149\" FLOAT, \"150\" FLOAT, \"151\" FLOAT, \"152\" FLOAT, \"153\" FLOAT, \"154\" FLOAT, \"155\" FLOAT, \"156\" FLOAT, \"157\" FLOAT, \"158\" FLOAT, \"159\" FLOAT, \"160\" FLOAT, \"161\" FLOAT, \"162\" FLOAT, \"163\" FLOAT, \"164\" FLOAT, \"165\" FLOAT, \"166\" FLOAT, \"167\" FLOAT, \"168\" FLOAT, \"169\" FLOAT, \"170\" FLOAT, \"171\" FLOAT, \"172\" FLOAT, \"173\" FLOAT, \"174\" FLOAT, \"175\" FLOAT, \"176\" FLOAT, \"177\" FLOAT, \"178\" FLOAT, \"179\" FLOAT, \"180\" FLOAT, \"181\" FLOAT, \"182\" FLOAT, \"183\" FLOAT, \"184\" FLOAT, \"185\" FLOAT, \"186\" FLOAT, \"187\" FLOAT, \"188\" FLOAT, \"189\" FLOAT, \"190\" FLOAT, \"191\" FLOAT, \"192\" FLOAT, \"193\" FLOAT, \"194\" FLOAT, \"195\" FLOAT, \"196\" FLOAT, \"197\" FLOAT, \"198\" FLOAT, \"199\" FLOAT, \"200\" FLOAT, \"201\" FLOAT, \"202\" FLOAT, \"203\" FLOAT, \"204\" FLOAT, \"205\" FLOAT, \"206\" FLOAT, \"207\" FLOAT, \"208\" FLOAT, \"209\" FLOAT, \"210\" FLOAT, \"211\" FLOAT, \"212\" FLOAT, \"213\" FLOAT, \"214\" FLOAT, \"215\" FLOAT, \"216\" FLOAT, \"217\" FLOAT, \"218\" FLOAT, \"219\" FLOAT, \"220\" FLOAT, \"221\" FLOAT, \"222\" FLOAT, \"223\" FLOAT, \"224\" FLOAT, \"225\" FLOAT, \"226\" FLOAT, \"227\" FLOAT, \"228\" FLOAT, \"229\" FLOAT, \"230\" FLOAT, \"231\" FLOAT, \"232\" FLOAT, \"233\" FLOAT, \"234\" FLOAT, \"235\" FLOAT, \"236\" FLOAT, \"237\" FLOAT, \"238\" FLOAT, \"239\" FLOAT, \"240\" FLOAT, \"241\" FLOAT, \"242\" FLOAT, \"243\" FLOAT, \"244\" FLOAT, \"245\" FLOAT, \"246\" FLOAT, \"247\" FLOAT, \"248\" FLOAT, \"249\" FLOAT, \"250\" FLOAT, \"251\" FLOAT, \"252\" FLOAT, \"253\" FLOAT, \"254\" FLOAT, \"255\" FLOAT, \"256\" FLOAT, \"257\" FLOAT, \"258\" FLOAT, \"259\" FLOAT, \"260\" FLOAT, \"261\" FLOAT, \"262\" FLOAT, \"263\" FLOAT, \"264\" FLOAT, \"265\" FLOAT, \"266\" FLOAT, \"267\" FLOAT, \"268\" FLOAT, \"269\" FLOAT, \"270\" FLOAT, \"271\" FLOAT, \"272\" FLOAT, \"273\" FLOAT, \"274\" FLOAT, \"275\" FLOAT, \"276\" FLOAT, \"277\" FLOAT, \"278\" FLOAT, \"279\" FLOAT, \"280\" FLOAT, \"281\" FLOAT, \"282\" FLOAT, \"283\" FLOAT, \"284\" FLOAT, \"285\" FLOAT, \"286\" FLOAT, \"287\" FLOAT, \"288\" FLOAT, \"289\" FLOAT, \"290\" FLOAT, \"291\" FLOAT, \"292\" FLOAT, \"293\" FLOAT, \"294\" FLOAT, \"295\" FLOAT, \"296\" FLOAT, \"297\" FLOAT, \"298\" FLOAT, \"299\" FLOAT, \"300\" FLOAT, \"301\" FLOAT, \"302\" FLOAT, \"303\" FLOAT, \"304\" FLOAT, \"305\" FLOAT, \"306\" FLOAT, \"307\" FLOAT, \"308\" FLOAT, \"309\" FLOAT, \"310\" FLOAT, \"311\" FLOAT, \"312\" FLOAT, \"313\" FLOAT, \"314\" FLOAT, \"315\" FLOAT, \"316\" FLOAT, \"317\" FLOAT, \"318\" FLOAT, \"319\" FLOAT, \"320\" FLOAT, \"321\" FLOAT, \"322\" FLOAT, \"323\" FLOAT, \"324\" FLOAT, \"325\" FLOAT, \"326\" FLOAT, \"327\" FLOAT, \"328\" FLOAT, \"329\" FLOAT, \"330\" FLOAT, \"331\" FLOAT, \"332\" FLOAT, \"333\" FLOAT, \"334\" FLOAT, \"335\" FLOAT, \"336\" FLOAT, \"337\" FLOAT, \"338\" FLOAT, \"339\" FLOAT, \"340\" FLOAT, \"341\" FLOAT, \"342\" FLOAT, \"343\" FLOAT, \"344\" FLOAT, \"345\" FLOAT, \"346\" FLOAT, \"347\" FLOAT, \"348\" FLOAT, \"349\" FLOAT, \"350\" FLOAT, \"351\" FLOAT, \"352\" FLOAT, \"353\" FLOAT, \"354\" FLOAT, \"355\" FLOAT, \"356\" FLOAT, \"357\" FLOAT, \"358\" FLOAT, \"359\" FLOAT, \"360\" FLOAT, \"361\" FLOAT, \"362\" FLOAT, \"363\" FLOAT, \"364\" FLOAT, \"365\" FLOAT, \"366\" FLOAT, \"367\" FLOAT, \"368\" FLOAT, \"369\" FLOAT, \"370\" FLOAT, \"371\" FLOAT, \"372\" FLOAT, \"373\" FLOAT, \"374\" FLOAT, \"375\" FLOAT, \"376\" FLOAT, \"377\" FLOAT, \"378\" FLOAT, \"379\" FLOAT, \"380\" FLOAT, \"381\" FLOAT, \"382\" FLOAT, \"383\" FLOAT)\n",
    "    USING\n",
    "    \n",
    "    APPLY_COMMAND('python embedding_bge_small_en.py')\n",
    "    ENVIRONMENT('{oaf_name}')\n",
    "    STYLE('csv')\n",
    "    delimiter(',') \n",
    ") as d),\n",
    "\n",
    "dt AS (SELECT TOP 10 Target_ID, Distance, 1-Distance AS Similarity FROM TD_VectorDistance(\n",
    "    ON demo_ofs.CFPB_embeddings AS TargetTable\n",
    "    PARTITION BY ANY \n",
    "    ON aq AS ReferenceTable\n",
    "    DIMENSION\n",
    "    USING\n",
    "    TargetIDColumn('id')\n",
    "    TargetFeatureColumns('[1:384]')\n",
    "    RefIDColumn('id')\n",
    "    RefFeatureColumns('[1:384]')\n",
    "    DistanceMeasure('cosine')\n",
    "    TopK(1)\n",
    ") as dst\n",
    "ORDER BY Similarity DESC)\n",
    "\n",
    "SELECT dt.Target_ID, cpl.txt, dt.Similarity\n",
    "FROM demo_ofs.CFPB_Complaints cpl\n",
    " INNER JOIN  dt\n",
    "     ON dt.Target_ID = cpl.id;\n",
    "'''\n",
    "print(f'Top semantic match for \"{search_topic}\": ')\n",
    "execute_sql(end_to_end).fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Create an interactive search experience</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use this query in a dynamic UI - this could be used in a BI tool or other application.</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This first cell defines functions we will use with the Jupyter Widgets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search(term, oaf_name):\n",
    "    return f'''\n",
    "WITH aq AS (SELECT * FROM Apply(\n",
    "    ON (SELECT 1 as id, '{term}' as txt)\n",
    "    PARTITION BY ANY\n",
    "    \n",
    "    returns(id BIGINT, \"0\" FLOAT, \"1\" FLOAT, \"2\" FLOAT, \"3\" FLOAT, \"4\" FLOAT, \"5\" FLOAT, \"6\" FLOAT, \"7\" FLOAT, \"8\" FLOAT, \"9\" FLOAT, \"10\" FLOAT, \"11\" FLOAT, \"12\" FLOAT, \"13\" FLOAT, \"14\" FLOAT, \"15\" FLOAT, \"16\" FLOAT, \"17\" FLOAT, \"18\" FLOAT, \"19\" FLOAT, \"20\" FLOAT, \"21\" FLOAT, \"22\" FLOAT, \"23\" FLOAT, \"24\" FLOAT, \"25\" FLOAT, \"26\" FLOAT, \"27\" FLOAT, \"28\" FLOAT, \"29\" FLOAT, \"30\" FLOAT, \"31\" FLOAT, \"32\" FLOAT, \"33\" FLOAT, \"34\" FLOAT, \"35\" FLOAT, \"36\" FLOAT, \"37\" FLOAT, \"38\" FLOAT, \"39\" FLOAT, \"40\" FLOAT, \"41\" FLOAT, \"42\" FLOAT, \"43\" FLOAT, \"44\" FLOAT, \"45\" FLOAT, \"46\" FLOAT, \"47\" FLOAT, \"48\" FLOAT, \"49\" FLOAT, \"50\" FLOAT, \"51\" FLOAT, \"52\" FLOAT, \"53\" FLOAT, \"54\" FLOAT, \"55\" FLOAT, \"56\" FLOAT, \"57\" FLOAT, \"58\" FLOAT, \"59\" FLOAT, \"60\" FLOAT, \"61\" FLOAT, \"62\" FLOAT, \"63\" FLOAT, \"64\" FLOAT, \"65\" FLOAT, \"66\" FLOAT, \"67\" FLOAT, \"68\" FLOAT, \"69\" FLOAT, \"70\" FLOAT, \"71\" FLOAT, \"72\" FLOAT, \"73\" FLOAT, \"74\" FLOAT, \"75\" FLOAT, \"76\" FLOAT, \"77\" FLOAT, \"78\" FLOAT, \"79\" FLOAT, \"80\" FLOAT, \"81\" FLOAT, \"82\" FLOAT, \"83\" FLOAT, \"84\" FLOAT, \"85\" FLOAT, \"86\" FLOAT, \"87\" FLOAT, \"88\" FLOAT, \"89\" FLOAT, \"90\" FLOAT, \"91\" FLOAT, \"92\" FLOAT, \"93\" FLOAT, \"94\" FLOAT, \"95\" FLOAT, \"96\" FLOAT, \"97\" FLOAT, \"98\" FLOAT, \"99\" FLOAT, \"100\" FLOAT, \"101\" FLOAT, \"102\" FLOAT, \"103\" FLOAT, \"104\" FLOAT, \"105\" FLOAT, \"106\" FLOAT, \"107\" FLOAT, \"108\" FLOAT, \"109\" FLOAT, \"110\" FLOAT, \"111\" FLOAT, \"112\" FLOAT, \"113\" FLOAT, \"114\" FLOAT, \"115\" FLOAT, \"116\" FLOAT, \"117\" FLOAT, \"118\" FLOAT, \"119\" FLOAT, \"120\" FLOAT, \"121\" FLOAT, \"122\" FLOAT, \"123\" FLOAT, \"124\" FLOAT, \"125\" FLOAT, \"126\" FLOAT, \"127\" FLOAT, \"128\" FLOAT, \"129\" FLOAT, \"130\" FLOAT, \"131\" FLOAT, \"132\" FLOAT, \"133\" FLOAT, \"134\" FLOAT, \"135\" FLOAT, \"136\" FLOAT, \"137\" FLOAT, \"138\" FLOAT, \"139\" FLOAT, \"140\" FLOAT, \"141\" FLOAT, \"142\" FLOAT, \"143\" FLOAT, \"144\" FLOAT, \"145\" FLOAT, \"146\" FLOAT, \"147\" FLOAT, \"148\" FLOAT, \"149\" FLOAT, \"150\" FLOAT, \"151\" FLOAT, \"152\" FLOAT, \"153\" FLOAT, \"154\" FLOAT, \"155\" FLOAT, \"156\" FLOAT, \"157\" FLOAT, \"158\" FLOAT, \"159\" FLOAT, \"160\" FLOAT, \"161\" FLOAT, \"162\" FLOAT, \"163\" FLOAT, \"164\" FLOAT, \"165\" FLOAT, \"166\" FLOAT, \"167\" FLOAT, \"168\" FLOAT, \"169\" FLOAT, \"170\" FLOAT, \"171\" FLOAT, \"172\" FLOAT, \"173\" FLOAT, \"174\" FLOAT, \"175\" FLOAT, \"176\" FLOAT, \"177\" FLOAT, \"178\" FLOAT, \"179\" FLOAT, \"180\" FLOAT, \"181\" FLOAT, \"182\" FLOAT, \"183\" FLOAT, \"184\" FLOAT, \"185\" FLOAT, \"186\" FLOAT, \"187\" FLOAT, \"188\" FLOAT, \"189\" FLOAT, \"190\" FLOAT, \"191\" FLOAT, \"192\" FLOAT, \"193\" FLOAT, \"194\" FLOAT, \"195\" FLOAT, \"196\" FLOAT, \"197\" FLOAT, \"198\" FLOAT, \"199\" FLOAT, \"200\" FLOAT, \"201\" FLOAT, \"202\" FLOAT, \"203\" FLOAT, \"204\" FLOAT, \"205\" FLOAT, \"206\" FLOAT, \"207\" FLOAT, \"208\" FLOAT, \"209\" FLOAT, \"210\" FLOAT, \"211\" FLOAT, \"212\" FLOAT, \"213\" FLOAT, \"214\" FLOAT, \"215\" FLOAT, \"216\" FLOAT, \"217\" FLOAT, \"218\" FLOAT, \"219\" FLOAT, \"220\" FLOAT, \"221\" FLOAT, \"222\" FLOAT, \"223\" FLOAT, \"224\" FLOAT, \"225\" FLOAT, \"226\" FLOAT, \"227\" FLOAT, \"228\" FLOAT, \"229\" FLOAT, \"230\" FLOAT, \"231\" FLOAT, \"232\" FLOAT, \"233\" FLOAT, \"234\" FLOAT, \"235\" FLOAT, \"236\" FLOAT, \"237\" FLOAT, \"238\" FLOAT, \"239\" FLOAT, \"240\" FLOAT, \"241\" FLOAT, \"242\" FLOAT, \"243\" FLOAT, \"244\" FLOAT, \"245\" FLOAT, \"246\" FLOAT, \"247\" FLOAT, \"248\" FLOAT, \"249\" FLOAT, \"250\" FLOAT, \"251\" FLOAT, \"252\" FLOAT, \"253\" FLOAT, \"254\" FLOAT, \"255\" FLOAT, \"256\" FLOAT, \"257\" FLOAT, \"258\" FLOAT, \"259\" FLOAT, \"260\" FLOAT, \"261\" FLOAT, \"262\" FLOAT, \"263\" FLOAT, \"264\" FLOAT, \"265\" FLOAT, \"266\" FLOAT, \"267\" FLOAT, \"268\" FLOAT, \"269\" FLOAT, \"270\" FLOAT, \"271\" FLOAT, \"272\" FLOAT, \"273\" FLOAT, \"274\" FLOAT, \"275\" FLOAT, \"276\" FLOAT, \"277\" FLOAT, \"278\" FLOAT, \"279\" FLOAT, \"280\" FLOAT, \"281\" FLOAT, \"282\" FLOAT, \"283\" FLOAT, \"284\" FLOAT, \"285\" FLOAT, \"286\" FLOAT, \"287\" FLOAT, \"288\" FLOAT, \"289\" FLOAT, \"290\" FLOAT, \"291\" FLOAT, \"292\" FLOAT, \"293\" FLOAT, \"294\" FLOAT, \"295\" FLOAT, \"296\" FLOAT, \"297\" FLOAT, \"298\" FLOAT, \"299\" FLOAT, \"300\" FLOAT, \"301\" FLOAT, \"302\" FLOAT, \"303\" FLOAT, \"304\" FLOAT, \"305\" FLOAT, \"306\" FLOAT, \"307\" FLOAT, \"308\" FLOAT, \"309\" FLOAT, \"310\" FLOAT, \"311\" FLOAT, \"312\" FLOAT, \"313\" FLOAT, \"314\" FLOAT, \"315\" FLOAT, \"316\" FLOAT, \"317\" FLOAT, \"318\" FLOAT, \"319\" FLOAT, \"320\" FLOAT, \"321\" FLOAT, \"322\" FLOAT, \"323\" FLOAT, \"324\" FLOAT, \"325\" FLOAT, \"326\" FLOAT, \"327\" FLOAT, \"328\" FLOAT, \"329\" FLOAT, \"330\" FLOAT, \"331\" FLOAT, \"332\" FLOAT, \"333\" FLOAT, \"334\" FLOAT, \"335\" FLOAT, \"336\" FLOAT, \"337\" FLOAT, \"338\" FLOAT, \"339\" FLOAT, \"340\" FLOAT, \"341\" FLOAT, \"342\" FLOAT, \"343\" FLOAT, \"344\" FLOAT, \"345\" FLOAT, \"346\" FLOAT, \"347\" FLOAT, \"348\" FLOAT, \"349\" FLOAT, \"350\" FLOAT, \"351\" FLOAT, \"352\" FLOAT, \"353\" FLOAT, \"354\" FLOAT, \"355\" FLOAT, \"356\" FLOAT, \"357\" FLOAT, \"358\" FLOAT, \"359\" FLOAT, \"360\" FLOAT, \"361\" FLOAT, \"362\" FLOAT, \"363\" FLOAT, \"364\" FLOAT, \"365\" FLOAT, \"366\" FLOAT, \"367\" FLOAT, \"368\" FLOAT, \"369\" FLOAT, \"370\" FLOAT, \"371\" FLOAT, \"372\" FLOAT, \"373\" FLOAT, \"374\" FLOAT, \"375\" FLOAT, \"376\" FLOAT, \"377\" FLOAT, \"378\" FLOAT, \"379\" FLOAT, \"380\" FLOAT, \"381\" FLOAT, \"382\" FLOAT, \"383\" FLOAT)\n",
    "    USING\n",
    "    \n",
    "    APPLY_COMMAND('python embedding_bge_small_en.py')\n",
    "    ENVIRONMENT('{oaf_name}')\n",
    "    STYLE('csv')\n",
    "    delimiter(',') \n",
    ") as d),\n",
    "\n",
    "dt AS (SELECT TOP 10 Target_ID, Distance, 1-Distance AS Similarity FROM TD_VectorDistance(\n",
    "    ON demo_ofs.CFPB_embeddings AS TargetTable\n",
    "    PARTITION BY ANY \n",
    "    ON aq AS ReferenceTable\n",
    "    DIMENSION\n",
    "    USING\n",
    "    TargetIDColumn('id')\n",
    "    TargetFeatureColumns('[1:384]')\n",
    "    RefIDColumn('id')\n",
    "    RefFeatureColumns('[1:384]')\n",
    "    DistanceMeasure('cosine')\n",
    "    TopK(1)\n",
    ") as dst\n",
    "ORDER BY Similarity DESC)\n",
    "\n",
    "SELECT dt.Target_ID, cpl.txt, dt.Similarity\n",
    "FROM demo_ofs.CFPB_Complaints cpl\n",
    " INNER JOIN  dt\n",
    "     ON dt.Target_ID = cpl.id\n",
    "ORDER BY dt.Similarity DESC;\n",
    "'''\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    if len(t.value) > 0:\n",
    "        with o:\n",
    "            clear_output()\n",
    "            print('Starting Search...')\n",
    "            end_to_end = build_search(t.value, oaf_name)\n",
    "            #print('Starting Search...')\n",
    "            local_df = pd.read_sql(end_to_end, eng)[['target_id', 'Similarity', 'txt']]\n",
    "            ipydisplay(local_df)\n",
    "            text = \" \".join(comment for comment in local_df['txt'])\n",
    "            stopwords = set(STOPWORDS)\n",
    "            wordcloud = WordCloud(stopwords = stopwords, width = 800, height=400, \n",
    "                                  max_words=100, min_word_length=1, \n",
    "                                  collocations = True, background_color = 'white').generate(text)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.imshow(wordcloud, interpolation='gaussian')\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Word Cloud for Search Topic')\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Launch the UI</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Enter a term and click \"Search\".  Try misspellings to illustrate this is semantic vs. literal search.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Enter Search Term: ')\n",
    "t = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type something')\n",
    "b  = widgets.Button(\n",
    "    description='Search',\n",
    "    tooltip='Search')\n",
    "o = widgets.Output()\n",
    "\n",
    "ipydisplay(t, b, o)\n",
    "b.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Conclusion - Operationalizing AI-powered analytics</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The preceding demo showed two methods for operationalizing the model execution; using python syntax, or embedding it as a simplified SQL view.  The former allows for developers and data scientists to easily embed this processing in their existing or new applications and workflows.  The latter allows for broad, democratized adoption across the data lifecycle and enterprise - enabling this analytic processing in ETL for data prep and transformation tasks, and in production to power dashboards and/or BI tools.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Cleanup</b></p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'><li>Stop the cluster</li>\n",
    "    <li><b>Not required</b>, but if desired remove the environment and drop tables created in the demonstrations</li>\n",
    "    <li>Disconnect from the database.</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = check_cluster_stop(compute_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uninstall the libraries from the environment first before removing it\n",
    "# demo_env.uninstall_lib(libs = demo_env.libs['name'].to_list())\n",
    "# remove_env(oaf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the tables created during this demo\n",
    "\n",
    "# db_drop_table('similarity_results');\n",
    "# db_drop_table('topics_of_interest', schema_name = 'demo_ofs');\n",
    "# db_drop_table('topics_embeddings', schema_name = 'demo_ofs');\n",
    "# db_drop_table('CFPB_embeddings', schema_name = 'demo_ofs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
