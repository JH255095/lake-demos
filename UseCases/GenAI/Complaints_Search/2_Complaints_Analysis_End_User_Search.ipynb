{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Regulatory compliance and customer complaint analytics powered by ClearScape Analytics In-db functions, BYO-LLM, and GPU compute\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"images/TeradataLogo.png\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<hr>\n",
    "<p style = 'font-size:28px;font-family:Arial;color:#00233C'><b>Use case</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>For financial institutions, failure to comply with regulations can have severe financial implications and reputation damage.   Monitoring employee-client communications helps to prevent irresponsible behavior. In addition, it is also required to manage customer complaints efficiently\n",
    "In this demo you will see how use power of ClearScape Analytics In-db functions, BYO-LLM and GPU compute to analyze text related to irresponsible behavior and semantic search on customer complaints.</p>\n",
    "\n",
    "<p style = 'font-size:28px;font-family:Arial;color:#00233C'><b>Demonstration Overview</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration illustrates an operationalized end-to-end process of utilizing VantageCloud Lake <b>GPU-enabled Analytic Cluster</b> architecture to run open-source large language models at massive parallelism and scale.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This notebook illustrates the final step of a GPU-augmented analytic pipeline.  In the previous demonstration, we reviewed;</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Container Management</b>.  Administrators can create and manage <b>secure, custom</b> runtime containers that will host any number of models and model artifacts to unlock GPU-augmented analytics</li>\n",
    "    <li><b>Data Prep with Vector Embeddings</b>. Developers will use the Hugging Face BAAI/bge-small-en-v1.5 model to generate vector embeddings for two data sets:<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "        <li><b>Consumer Complaints</b>. A subset of the Consumer Financial Protection Board Complaints <a href = 'https://catalog.data.gov/dataset/consumer-complaint-database'>database</a> data has been loaded into the VantageCloud Lake database for this demonstration</li><li><b>Semantic Search Terms</b>.  A user-defined list of natural language topics to use to perform a Semantic Search</li></ul></li>\n",
    "    </ol>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Operationalization with interactive search</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this final demonstraion, we will illustrate two interactive use-cases for the semantic embeddings generated above;</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Calculate Semantic Similarity</b> for all pre-staged search or compliance topics.  Generate an interactive UI to allow rapid browsing of top search results</li>\n",
    "    <li><b>Execute the pipeline on-demand</b>.  Create an interactive experience that performs the Hugging Face embeddings, vector distance, and data formatting all in a single call to the analytic engine</li>\n",
    "    </ol>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Installation</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If necessary, install required client packages for the demonstrations.  User may need to restart the Jupyter kernel after installation.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Imports</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Standard practice to import required packages and libraries; execute this cell to import packages for Teradata automation as well as machine learning, analytics, utility, and data management packages.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import *\n",
    "from oaf_utils import *\n",
    "from teradatasqlalchemy.types import *\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import csv, sys, os, warnings\n",
    "from os.path import expanduser\n",
    "from collections import OrderedDict\n",
    "import ipywidgets as widgets\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from IPython.display import clear_output , display as ipydisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from itables import init_notebook_mode\n",
    "import itables.options as opt\n",
    "\n",
    "# Set display options for dataframes, plots, and warnings\n",
    "\n",
    "opt.style=\"table-layout:auto;width:auto;float:left\"\n",
    "opt.columnDefs = [{\"className\": \"dt-left\", \"targets\": \"_all\"}]\n",
    "init_notebook_mode(all_interactive=True)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "\n",
    "# load vars json\n",
    "with open('vars_gpu_SEP_24.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "# Database login information\n",
    "host = session_vars['environment']['host']\n",
    "username = session_vars['hierarchy']['users']['business_users'][1]['username']\n",
    "password = session_vars['hierarchy']['users']['business_users'][1]['password']\n",
    "\n",
    "# UES Authentication information\n",
    "ues_url = session_vars['environment']['UES_URI']\n",
    "configure.ues_url = ues_url\n",
    "pat_token = session_vars['hierarchy']['users']['business_users'][1]['pat_token']\n",
    "pem_file = session_vars['hierarchy']['users']['business_users'][1]['key_file']\n",
    "\n",
    "\n",
    "compute_group = session_vars['hierarchy']['users']['business_users'][1]['compute_group']\n",
    "\n",
    "\n",
    "# container name - set here for easier notebook navigation\n",
    "### User will also be asked to change it ###\n",
    "oaf_name = 'embeddings_env_demo'\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Operationalizing interactive AI-powered analytics\n",
    "  <br>\n",
    "    </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration will illustrate how developers can <b>operationalize</b> end-to-end GPU-augmented processing, enabling the entire organization to leverage AI across the data lifecycle.  The following steps illustrate how to:</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '30%'>\n",
    "           <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "               <li><b>Calculate Semantic Similarity</b>.  Execute native vector distance functions to check similarity between the search topics and complaints embeddings</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Examine Results</b>.  Generate a data table and word cloud to check for other contextual patterns</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Create an interactive exerience</b>.  Create an operational pipeline to take interactive semantic search terms</li>\n",
    "        </ol>\n",
    "        </td>\n",
    "        <td width = '20%'></td>\n",
    "        <td style = 'vertical-align:top'><img src = 'images/cos_similarity.jpeg' width = 350 ></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Check connection</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Connect to the database, UES, and start cluster if necessary<get_context()/p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing connection\n",
    "eng = check_and_connect(host=host, username=username, password=password, compute_group = compute_group)\n",
    "print(eng)\n",
    "    \n",
    "\n",
    "# check to see if there is a valid UES auth\n",
    "# if not, authenticate\n",
    "try:\n",
    "    demo_env = get_env(oaf_name)\n",
    "\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'value''' in str(e): #UES auth expired/required\n",
    "        if set_auth_token(ues_url = ues_url, username = username, pat_token = pat_token, pem_file = pem_file):\n",
    "            print('UES Authentication successful')\n",
    "            try:\n",
    "                demo_env = get_env(oaf_name)\n",
    "                pass\n",
    "            except Exception as l:\n",
    "                if f'''User environment '{oaf_name}' not found''' in str(l):\n",
    "                    print('User environment not found')\n",
    "                    pass\n",
    "                else:\n",
    "                    raise\n",
    "        else:\n",
    "            print('UES Authentication failed, check URL and account info')\n",
    "        pass\n",
    "    elif f'''User environment '{oaf_name}' not found''' in str(e):\n",
    "        print('User environment not found')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "try:\n",
    "    ipydisplay(list_user_envs())\n",
    "except Exception as e:\n",
    "    if str(e).find('No user environments found') > 0:\n",
    "        print('No user environments found')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "print('Use an existing environment')\n",
    "print(f'OAF Environment is set to {oaf_name}.')\n",
    "print('Enter to accept, or input a new value.')\n",
    "i = input()\n",
    "if len(i) != 0:\n",
    "    oaf_name = i\n",
    "    demo_env = get_env(oaf_name)\n",
    "    print(f'OAF Environment is now {oaf_name}')\n",
    "    \n",
    "\n",
    "# check cluster status\n",
    "check_cluster_start(compute_group = compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>1.  Calculate semantic similarity</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>First, create a reference to the prepared data sets.  Next, execute the native <b>ClearScape Analytics</b> VectorDistance function.</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Database-Analytic-Functions/Model-Training-Functions/TD_VectorDistance'>TD_VectorDistance</a> function accepts a table of target vectors and a table of reference vectors and returns a table that contains the distance between target-reference pairs. The function computes the distance between the target pair and the reference pair from the same table if you provide only one table as the input.  This function can be called using the terdataml python package, or native SQL.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for the required tables\n",
    "# if any are missing, run the appropriate sections of the \n",
    "# first demo notebook\n",
    "\n",
    "# Required tables\n",
    "reqs = ['CFPB_embeddings', 'topics_embeddings', 'topics_of_interest', 'CFPB_Complaints']\n",
    "\n",
    "# tables in the database demo_ofs\n",
    "tbls = db_list_tables(schema_name = 'demo_ofs')['TableName'].to_list()\n",
    "\n",
    "if len(set(reqs).intersection(tbls)) == len(reqs):\n",
    "    print('Required tables exist')\n",
    "else:\n",
    "    print('The following tables are missing, Please run the previous notebook to generate them:')\n",
    "    ipydisplay(set(reqs) - set(tbls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Complaints embeddings:')\n",
    "tdf_target = DataFrame('\"demo_ofs\".\"CFPB_embeddings\"')\n",
    "ipydisplay(tdf_target.sample(1))\n",
    "print('Topics embeddings:')\n",
    "tdf_reference = DataFrame('\"demo_ofs\".\"topics_embeddings\"')\n",
    "ipydisplay(tdf_reference.sample(1))\n",
    "\n",
    "print('Calculating vector distance')\n",
    "feature_list = ['\"' + str(i) + '\"' for i in range(384)]\n",
    "res_tdf = VectorDistance(target_data = tdf_target, \n",
    "                   reference_data = tdf_reference, \n",
    "                   target_id_column = 'id',\n",
    "                   target_feature_columns = feature_list,\n",
    "                   ref_id_column = 'id',\n",
    "                   ref_feature_columns = feature_list,\n",
    "                   distance_measure = 'cosine',\n",
    "                   topk = 1\n",
    "                  ).result\n",
    "print('Analysis complete, raw output: ')\n",
    "res_tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2.  Create user-friendly results</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>First, use various teradataml methods to join the original comments data to the distance calculations.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame references to the original data sets\n",
    "tdf_topics = DataFrame('\"demo_ofs\".\"topics_of_interest\"')\n",
    "tdf_full = DataFrame.from_query('''SELECT id,\n",
    "    CASE \n",
    "        WHEN txt IS NULL THEN ' '\n",
    "        ELSE regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(txt , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END text\n",
    "    FROM demo_ofs.CFPB_Complaints;''')\n",
    "\n",
    "print('Joining topics text to distance calculations')\n",
    "tdf_final = res_tdf.join(tdf_topics, on = 'reference_id = id')\n",
    "print('Joining comments text to distance calculations')\n",
    "tdf_final = tdf_final.join(tdf_full, on = 'target_id = id', lsuffix = 'l')\n",
    "tdf_final = tdf_final.assign(similarity = 1 - tdf_final['distance'])\n",
    "tdf_final = tdf_final.assign(topic = tdf_final['txt'])\n",
    "tdf_final = tdf_final.assign(comment = tdf_final['text'])\n",
    "tdf_final = tdf_final.assign(topic_id = tdf_final['reference_id'])\n",
    "tdf_final = tdf_final.drop(['target_id', 'reference_id', 'id_l', 'txt', 'text'], axis = 1)\n",
    "\n",
    "print('Writing final results to a table')\n",
    "copy_to_sql(tdf_final, table_name = 'similarity_results', schema_name = 'demo_ofs', if_exists = 'replace')\n",
    "ipydisplay(DataFrame('\"demo_ofs\".\"similarity_results\"').head(2).to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Visualize results</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use client-side widgets to provide an interactive experience.  Return ten rows of selected results <b>only</b>.  Then, generate a Word Cloud to represent frequent terms.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_results = DataFrame('\"demo_ofs\".\"similarity_results\"')\n",
    "topics_list = DataFrame('\"demo_ofs\".\"topics_of_interest\"').to_pandas()['txt'].to_list()\n",
    "\n",
    "d = widgets.Dropdown(options=topics_list)\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        with output:\n",
    "            clear_output()\n",
    "            local_df = tdf_results[tdf_results['topic'] == change['new']].set_index('distance').iloc[:10].to_pandas().drop('topic', axis = 1)\n",
    "            ipydisplay(local_df)\n",
    "            text = \" \".join(comment for comment in local_df['comment'])\n",
    "            stopwords = set(STOPWORDS)\n",
    "            wordcloud = WordCloud(stopwords = stopwords, width = 800, height=400, \n",
    "                                  max_words=100, min_word_length=1, \n",
    "                                  collocations = True, background_color = 'white').generate(text)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.imshow(wordcloud, interpolation='gaussian')\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Word Cloud for Search Topic')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "d.observe(on_change)\n",
    "\n",
    "print('Select Topic to Search:')\n",
    "ipydisplay(d, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>3.  Interactive Semantic Search</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration will illustrate an example of how to <b>operationalize</b> the combined Hugging Face embeddings, and native analytics performed in the steps above.  In this section, the python methods are replaced with SQL, which allows for broad adoption and re-use by many tools and applications.  Steps are as follow:</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Construct the SQL pipeline</b>.  This query will combine all the analytic steps above into a single expression:<ol style = 'font-size:16px;font-family:Arial;color:#00233C'><li>Embedding incoming search term using the Hugging Face model</li>\n",
    "        <li>Passing the vector values to the TD_VectorDistance function</li>\n",
    "        <li>Joining the distance measurements to the original comments</li>\n",
    "        <li>Returning search results back to the user</li></ol></li>\n",
    "    <li><b>User</b> Submits search term to the query</li>\n",
    "    <li><b>Responses</b> are sent back to the client</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Create an interactive search experience</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use this query in a dynamic UI - this could be used in a BI tool or other application.</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This first cell defines functions we will use with the Jupyter Widgets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search(term, oaf_name):\n",
    "    return f'''\n",
    "WITH aq AS (SELECT * FROM Apply(\n",
    "    ON (SELECT 1 as id, '{term}' as txt)\n",
    "    PARTITION BY ANY\n",
    "    \n",
    "    returns(id BIGINT, \"0\" FLOAT, \"1\" FLOAT, \"2\" FLOAT, \"3\" FLOAT, \"4\" FLOAT, \"5\" FLOAT, \"6\" FLOAT, \"7\" FLOAT, \"8\" FLOAT, \"9\" FLOAT, \"10\" FLOAT, \"11\" FLOAT, \"12\" FLOAT, \"13\" FLOAT, \"14\" FLOAT, \"15\" FLOAT, \"16\" FLOAT, \"17\" FLOAT, \"18\" FLOAT, \"19\" FLOAT, \"20\" FLOAT, \"21\" FLOAT, \"22\" FLOAT, \"23\" FLOAT, \"24\" FLOAT, \"25\" FLOAT, \"26\" FLOAT, \"27\" FLOAT, \"28\" FLOAT, \"29\" FLOAT, \"30\" FLOAT, \"31\" FLOAT, \"32\" FLOAT, \"33\" FLOAT, \"34\" FLOAT, \"35\" FLOAT, \"36\" FLOAT, \"37\" FLOAT, \"38\" FLOAT, \"39\" FLOAT, \"40\" FLOAT, \"41\" FLOAT, \"42\" FLOAT, \"43\" FLOAT, \"44\" FLOAT, \"45\" FLOAT, \"46\" FLOAT, \"47\" FLOAT, \"48\" FLOAT, \"49\" FLOAT, \"50\" FLOAT, \"51\" FLOAT, \"52\" FLOAT, \"53\" FLOAT, \"54\" FLOAT, \"55\" FLOAT, \"56\" FLOAT, \"57\" FLOAT, \"58\" FLOAT, \"59\" FLOAT, \"60\" FLOAT, \"61\" FLOAT, \"62\" FLOAT, \"63\" FLOAT, \"64\" FLOAT, \"65\" FLOAT, \"66\" FLOAT, \"67\" FLOAT, \"68\" FLOAT, \"69\" FLOAT, \"70\" FLOAT, \"71\" FLOAT, \"72\" FLOAT, \"73\" FLOAT, \"74\" FLOAT, \"75\" FLOAT, \"76\" FLOAT, \"77\" FLOAT, \"78\" FLOAT, \"79\" FLOAT, \"80\" FLOAT, \"81\" FLOAT, \"82\" FLOAT, \"83\" FLOAT, \"84\" FLOAT, \"85\" FLOAT, \"86\" FLOAT, \"87\" FLOAT, \"88\" FLOAT, \"89\" FLOAT, \"90\" FLOAT, \"91\" FLOAT, \"92\" FLOAT, \"93\" FLOAT, \"94\" FLOAT, \"95\" FLOAT, \"96\" FLOAT, \"97\" FLOAT, \"98\" FLOAT, \"99\" FLOAT, \"100\" FLOAT, \"101\" FLOAT, \"102\" FLOAT, \"103\" FLOAT, \"104\" FLOAT, \"105\" FLOAT, \"106\" FLOAT, \"107\" FLOAT, \"108\" FLOAT, \"109\" FLOAT, \"110\" FLOAT, \"111\" FLOAT, \"112\" FLOAT, \"113\" FLOAT, \"114\" FLOAT, \"115\" FLOAT, \"116\" FLOAT, \"117\" FLOAT, \"118\" FLOAT, \"119\" FLOAT, \"120\" FLOAT, \"121\" FLOAT, \"122\" FLOAT, \"123\" FLOAT, \"124\" FLOAT, \"125\" FLOAT, \"126\" FLOAT, \"127\" FLOAT, \"128\" FLOAT, \"129\" FLOAT, \"130\" FLOAT, \"131\" FLOAT, \"132\" FLOAT, \"133\" FLOAT, \"134\" FLOAT, \"135\" FLOAT, \"136\" FLOAT, \"137\" FLOAT, \"138\" FLOAT, \"139\" FLOAT, \"140\" FLOAT, \"141\" FLOAT, \"142\" FLOAT, \"143\" FLOAT, \"144\" FLOAT, \"145\" FLOAT, \"146\" FLOAT, \"147\" FLOAT, \"148\" FLOAT, \"149\" FLOAT, \"150\" FLOAT, \"151\" FLOAT, \"152\" FLOAT, \"153\" FLOAT, \"154\" FLOAT, \"155\" FLOAT, \"156\" FLOAT, \"157\" FLOAT, \"158\" FLOAT, \"159\" FLOAT, \"160\" FLOAT, \"161\" FLOAT, \"162\" FLOAT, \"163\" FLOAT, \"164\" FLOAT, \"165\" FLOAT, \"166\" FLOAT, \"167\" FLOAT, \"168\" FLOAT, \"169\" FLOAT, \"170\" FLOAT, \"171\" FLOAT, \"172\" FLOAT, \"173\" FLOAT, \"174\" FLOAT, \"175\" FLOAT, \"176\" FLOAT, \"177\" FLOAT, \"178\" FLOAT, \"179\" FLOAT, \"180\" FLOAT, \"181\" FLOAT, \"182\" FLOAT, \"183\" FLOAT, \"184\" FLOAT, \"185\" FLOAT, \"186\" FLOAT, \"187\" FLOAT, \"188\" FLOAT, \"189\" FLOAT, \"190\" FLOAT, \"191\" FLOAT, \"192\" FLOAT, \"193\" FLOAT, \"194\" FLOAT, \"195\" FLOAT, \"196\" FLOAT, \"197\" FLOAT, \"198\" FLOAT, \"199\" FLOAT, \"200\" FLOAT, \"201\" FLOAT, \"202\" FLOAT, \"203\" FLOAT, \"204\" FLOAT, \"205\" FLOAT, \"206\" FLOAT, \"207\" FLOAT, \"208\" FLOAT, \"209\" FLOAT, \"210\" FLOAT, \"211\" FLOAT, \"212\" FLOAT, \"213\" FLOAT, \"214\" FLOAT, \"215\" FLOAT, \"216\" FLOAT, \"217\" FLOAT, \"218\" FLOAT, \"219\" FLOAT, \"220\" FLOAT, \"221\" FLOAT, \"222\" FLOAT, \"223\" FLOAT, \"224\" FLOAT, \"225\" FLOAT, \"226\" FLOAT, \"227\" FLOAT, \"228\" FLOAT, \"229\" FLOAT, \"230\" FLOAT, \"231\" FLOAT, \"232\" FLOAT, \"233\" FLOAT, \"234\" FLOAT, \"235\" FLOAT, \"236\" FLOAT, \"237\" FLOAT, \"238\" FLOAT, \"239\" FLOAT, \"240\" FLOAT, \"241\" FLOAT, \"242\" FLOAT, \"243\" FLOAT, \"244\" FLOAT, \"245\" FLOAT, \"246\" FLOAT, \"247\" FLOAT, \"248\" FLOAT, \"249\" FLOAT, \"250\" FLOAT, \"251\" FLOAT, \"252\" FLOAT, \"253\" FLOAT, \"254\" FLOAT, \"255\" FLOAT, \"256\" FLOAT, \"257\" FLOAT, \"258\" FLOAT, \"259\" FLOAT, \"260\" FLOAT, \"261\" FLOAT, \"262\" FLOAT, \"263\" FLOAT, \"264\" FLOAT, \"265\" FLOAT, \"266\" FLOAT, \"267\" FLOAT, \"268\" FLOAT, \"269\" FLOAT, \"270\" FLOAT, \"271\" FLOAT, \"272\" FLOAT, \"273\" FLOAT, \"274\" FLOAT, \"275\" FLOAT, \"276\" FLOAT, \"277\" FLOAT, \"278\" FLOAT, \"279\" FLOAT, \"280\" FLOAT, \"281\" FLOAT, \"282\" FLOAT, \"283\" FLOAT, \"284\" FLOAT, \"285\" FLOAT, \"286\" FLOAT, \"287\" FLOAT, \"288\" FLOAT, \"289\" FLOAT, \"290\" FLOAT, \"291\" FLOAT, \"292\" FLOAT, \"293\" FLOAT, \"294\" FLOAT, \"295\" FLOAT, \"296\" FLOAT, \"297\" FLOAT, \"298\" FLOAT, \"299\" FLOAT, \"300\" FLOAT, \"301\" FLOAT, \"302\" FLOAT, \"303\" FLOAT, \"304\" FLOAT, \"305\" FLOAT, \"306\" FLOAT, \"307\" FLOAT, \"308\" FLOAT, \"309\" FLOAT, \"310\" FLOAT, \"311\" FLOAT, \"312\" FLOAT, \"313\" FLOAT, \"314\" FLOAT, \"315\" FLOAT, \"316\" FLOAT, \"317\" FLOAT, \"318\" FLOAT, \"319\" FLOAT, \"320\" FLOAT, \"321\" FLOAT, \"322\" FLOAT, \"323\" FLOAT, \"324\" FLOAT, \"325\" FLOAT, \"326\" FLOAT, \"327\" FLOAT, \"328\" FLOAT, \"329\" FLOAT, \"330\" FLOAT, \"331\" FLOAT, \"332\" FLOAT, \"333\" FLOAT, \"334\" FLOAT, \"335\" FLOAT, \"336\" FLOAT, \"337\" FLOAT, \"338\" FLOAT, \"339\" FLOAT, \"340\" FLOAT, \"341\" FLOAT, \"342\" FLOAT, \"343\" FLOAT, \"344\" FLOAT, \"345\" FLOAT, \"346\" FLOAT, \"347\" FLOAT, \"348\" FLOAT, \"349\" FLOAT, \"350\" FLOAT, \"351\" FLOAT, \"352\" FLOAT, \"353\" FLOAT, \"354\" FLOAT, \"355\" FLOAT, \"356\" FLOAT, \"357\" FLOAT, \"358\" FLOAT, \"359\" FLOAT, \"360\" FLOAT, \"361\" FLOAT, \"362\" FLOAT, \"363\" FLOAT, \"364\" FLOAT, \"365\" FLOAT, \"366\" FLOAT, \"367\" FLOAT, \"368\" FLOAT, \"369\" FLOAT, \"370\" FLOAT, \"371\" FLOAT, \"372\" FLOAT, \"373\" FLOAT, \"374\" FLOAT, \"375\" FLOAT, \"376\" FLOAT, \"377\" FLOAT, \"378\" FLOAT, \"379\" FLOAT, \"380\" FLOAT, \"381\" FLOAT, \"382\" FLOAT, \"383\" FLOAT)\n",
    "    USING\n",
    "    \n",
    "    APPLY_COMMAND('python embedding_bge_small_en.py')\n",
    "    ENVIRONMENT('{oaf_name}')\n",
    "    STYLE('csv')\n",
    "    delimiter(',') \n",
    ") as d),\n",
    "\n",
    "dt AS (SELECT TOP 10 Target_ID, Distance, 1-Distance AS Similarity FROM TD_VectorDistance(\n",
    "    ON demo_ofs.CFPB_embeddings AS TargetTable\n",
    "    PARTITION BY ANY \n",
    "    ON aq AS ReferenceTable\n",
    "    DIMENSION\n",
    "    USING\n",
    "    TargetIDColumn('id')\n",
    "    TargetFeatureColumns('[1:384]')\n",
    "    RefIDColumn('id')\n",
    "    RefFeatureColumns('[1:384]')\n",
    "    DistanceMeasure('cosine')\n",
    "    TopK(1)\n",
    ") as dst\n",
    "ORDER BY Similarity DESC)\n",
    "\n",
    "SELECT dt.Target_ID, cpl.txt, dt.Similarity\n",
    "FROM demo_ofs.CFPB_Complaints cpl\n",
    " INNER JOIN  dt\n",
    "     ON dt.Target_ID = cpl.id\n",
    "ORDER BY dt.Similarity DESC;\n",
    "'''\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    if len(t.value) > 0:\n",
    "        with o:\n",
    "            clear_output()\n",
    "            print('Starting Search...')\n",
    "            end_to_end = build_search(t.value, oaf_name)\n",
    "            #print('Starting Search...')\n",
    "            local_df = pd.read_sql(end_to_end, eng)[['target_id', 'Similarity', 'txt']]\n",
    "            ipydisplay(local_df)\n",
    "            text = \" \".join(comment for comment in local_df['txt'])\n",
    "            stopwords = set(STOPWORDS)\n",
    "            wordcloud = WordCloud(stopwords = stopwords, width = 800, height=400, \n",
    "                                  max_words=100, min_word_length=1, \n",
    "                                  collocations = True, background_color = 'white').generate(text)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.imshow(wordcloud, interpolation='gaussian')\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Word Cloud for Search Topic')\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Launch the UI</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Enter a term and click \"Search\".  Try misspellings to illustrate this is semantic vs. literal search.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Enter Search Term: ')\n",
    "t = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type something')\n",
    "b  = widgets.Button(\n",
    "    description='Search',\n",
    "    tooltip='Search')\n",
    "o = widgets.Output()\n",
    "\n",
    "ipydisplay(t, b, o)\n",
    "b.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Conclusion - Operationalizing AI-powered analytics</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The preceding demo showed two methods for operationalizing the model execution; using python syntax, or embedding it as a simplified SQL view.  The former allows for developers and data scientists to easily embed this processing in their existing or new applications and workflows.  The latter allows for broad, democratized adoption across the data lifecycle and enterprise - enabling this analytic processing in ETL for data prep and transformation tasks, and in production to power dashboards and/or BI tools.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Cleanup</b></p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'><li>Stop the cluster</li>\n",
    "    <li><b>Not required</b>, but if desired remove the environment and drop tables created in the demonstrations</li>\n",
    "    <li>Disconnect from the database.</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = check_cluster_stop(compute_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uninstall the libraries from the environment first before removing it\n",
    "# demo_env.uninstall_lib(libs = demo_env.libs['name'].to_list())\n",
    "# remove_env(oaf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the tables created during this demo\n",
    "\n",
    "# db_drop_table('similarity_results');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
