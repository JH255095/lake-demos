{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "young-employment",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data for Demos ##\n",
    "\n",
    "### Note - first download csv files from s3://td-demos-data/CSV/ ###\n",
    "\n",
    "Run each cell to load data for Use Case demos:\n",
    "\n",
    "1. demo.Accounts_Mapping_BFS - Dimension table for Data Engineering demo\n",
    "2. demo.Customer_BFS - Dimenstion table for Data Engineering demo\n",
    "3. demo.Amazon_Fine_Foods_Reviews - Reviews for NBTC and Sentiment Analyzer\n",
    "    - demo.nltk_stopwords for textparser\n",
    "    - demo.bin_table for histogram function\n",
    "4. demo.housing_prices_full - housing prices data for Numeric Regression\n",
    "5. demo_ofs.Txn_History - copy of the txn history table for DS/OAF demos.\n",
    "6. demo_ofs.UK_Retail_Data - Online retail sales data for KMeans Clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-appraisal",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Data Loads for Data Engineering Demos ##\n",
    "\n",
    "- **demo.Accounts_Mapping_BFS**\n",
    "- **demo.Customer_BFS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /* -------------------------------------------------------- */\n",
    "# -- Perform this as SYSDBA.\n",
    "# -- Load demo.Accounts_Mapping_EBS from source file\n",
    "# /* -------------------------------------------------------- */\n",
    "\n",
    "import teradatasql, json\n",
    "\n",
    "# load vars json\n",
    "with open('../vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "name = session_vars['hierarchy']['SYSDBA']['username']\n",
    "pwd = session_vars['hierarchy']['SYSDBA']['password']\n",
    "\n",
    "with teradatasql.connect(host = session_vars['environment']['host'], \n",
    "                     user = name, \n",
    "                     password = pwd) as con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    try:\n",
    "        cur.execute('DROP TABLE Demo.Accounts_Mapping_BFS')\n",
    "    except Exception as e:\n",
    "        # Table already exists\n",
    "        if str(e.args).find(\"3807\") >= 1:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "    \n",
    "    qry = '''\n",
    "    CREATE MULTISET TABLE demo.Accounts_Mapping_BFS,\n",
    "    STORAGE = TD_NDSSTORAGE\n",
    "        (nameOrig VARCHAR(11),\n",
    "         customer_identifier VARCHAR(100))\n",
    "    PRIMARY INDEX(nameOrig) \n",
    "    '''\n",
    "    cur.execute(qry)\n",
    "    \n",
    "    qry = '''{fn teradata_read_csv(customer_mapping.csv)} insert into demo.Accounts_Mapping_BFS (?, ?)'''\n",
    "    cur.execute(qry)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spread-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /* -------------------------------------------------------- */\n",
    "# -- Perform this as SYSDBA.\n",
    "# -- Load demo.Customer_EBS from S3\n",
    "# /* -------------------------------------------------------- */\n",
    "\n",
    "import teradatasql, json\n",
    "\n",
    "# load vars json\n",
    "with open('../vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "name = session_vars['hierarchy']['SYSDBA']['username']\n",
    "pwd = session_vars['hierarchy']['SYSDBA']['password']\n",
    "\n",
    "with teradatasql.connect(host = session_vars['environment']['host'], \n",
    "                     user = name, \n",
    "                     password = pwd) as con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    try:\n",
    "        cur.execute('DROP TABLE Demo.Customers_BFS')\n",
    "    except Exception as e:\n",
    "        # Table already exists\n",
    "        if str(e.args).find(\"3807\") >= 1:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "    \n",
    "    qry = '''\n",
    "    CREATE TABLE demo.Customers_BFS,\n",
    "    STORAGE = TD_NDSSTORAGE\n",
    "         (\n",
    "         id BIGINT,\n",
    "         customer_identifier VARCHAR(26),\n",
    "         firstname VARCHAR(50),\n",
    "         lastname VARCHAR(90),\n",
    "         email VARCHAR(90),\n",
    "         phone VARCHAR(50),\n",
    "         birthday VARCHAR(10),\n",
    "         streetaddress VARCHAR(200),\n",
    "         city VARCHAR(90),\n",
    "         state VARCHAR(50),\n",
    "         zipcode VARCHAR(10),\n",
    "         latitude FLOAT,\n",
    "         longitude FLOAT,\n",
    "         num_accounts INTEGER)\n",
    "    PRIMARY INDEX(id);\n",
    "    '''\n",
    "    cur.execute(qry)\n",
    "    \n",
    "    qry = '''\n",
    "    INSERT INTO demo.Customers_BFS\n",
    "\n",
    "    SELECT\n",
    "         CAST(Col1 AS BIGINT) id,\n",
    "         CAST(Col2 AS VARCHAR(26)) customer_identifier,\n",
    "         CAST(Col3 AS VARCHAR(50)) firstname,\n",
    "         CAST(Col4 AS VARCHAR(90)) lastname,\n",
    "         CAST(Col5 AS VARCHAR(90)) email,\n",
    "         CAST(Col6 AS VARCHAR(50)) phone,\n",
    "         CAST(Col7 AS VARCHAR(10)) birthday,\n",
    "         CAST(Col8 AS VARCHAR(200)) streetaddress,\n",
    "         CAST(Col9 AS VARCHAR(90)) city,\n",
    "         CAST(Col10 AS VARCHAR(50)) state,\n",
    "         CAST(Col11 AS VARCHAR(10)) zipcode,\n",
    "         CAST(Col12 AS FLOAT) latitude,\n",
    "         CAST(Col13 AS FLOAT) longitude,\n",
    "         CAST(Col14 AS INTEGER) numaccounts\n",
    "    FROM\n",
    "    (\n",
    "         LOCATION = '/s3/s3.amazonaws.com/td-usecases-data-store/retail_sample_data/FSCustomerJourney/customers.csv'\n",
    "         ROWFORMAT = '{\"field_delimiter\":\",\",\"record_delimiter\":\"\\\\n\",\"character_set\":\"LATIN\"}'\n",
    "         STRIP_ENCLOSING_CHAR = '\"'\n",
    "        HEADER = 'FALSE'\n",
    "        AUTHORIZATION = retail_sample_data.DEMO_AUTH_NOS\n",
    "    ) as dt\n",
    "    '''\n",
    "    cur.execute(qry)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-sport",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Data Loads for Text Demos ##\n",
    "### NBTC and Sentiment Analyzer ###\n",
    "\n",
    "- **demo.Amazon_Fine_Foods_Reviews**\n",
    "- **demo.nltk_stopwords**\n",
    "- **demo.bin_table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "heated-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /* -------------------------------------------------------- */\n",
    "# -- Perform this as SYSDBA.\n",
    "# -- Load demo.Amazon_Fine_Foods_Reviews data\n",
    "# /* -------------------------------------------------------- */\n",
    "\n",
    "import teradatasql, json\n",
    "\n",
    "# load vars json\n",
    "with open('../vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "name = session_vars['hierarchy']['SYSDBA']['username']\n",
    "pwd = session_vars['hierarchy']['SYSDBA']['password']\n",
    "\n",
    "with teradatasql.connect(host = session_vars['environment']['host'], \n",
    "                     user = name, \n",
    "                     password = pwd) as con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    try:\n",
    "        cur.execute('DROP TABLE Demo.Amazon_Fine_Foods_Reviews')\n",
    "    except Exception as e:\n",
    "        # Table already exists\n",
    "        if str(e.args).find(\"3807\") >= 1:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "    \n",
    "    qry = '''\n",
    "        CREATE TABLE Demo.Amazon_Fine_Foods_Reviews, \n",
    "        STORAGE = TD_OFSSTORAGE\n",
    "        (\n",
    "        doc_id int, \n",
    "        rating int,\n",
    "        review varchar(21500) CHARACTER SET LATIN\n",
    "        \n",
    "        );\n",
    "    '''\n",
    "    cur.execute(qry)\n",
    "    \n",
    "    qry = '''{fn teradata_read_csv(amazon_reviews.csv)} insert into Demo.Amazon_Fine_Foods_Reviews (?, ?, ?)'''\n",
    "    cur.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "helpful-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /* -------------------------------------------------------- */\n",
    "# -- Perform this as SYSDBA.\n",
    "# -- Load demo.nltk_stopwords\n",
    "# /* -------------------------------------------------------- */\n",
    "\n",
    "import teradatasql, json\n",
    "\n",
    "# load vars json\n",
    "with open('../vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "name = session_vars['hierarchy']['SYSDBA']['username']\n",
    "pwd = session_vars['hierarchy']['SYSDBA']['password']\n",
    "\n",
    "with teradatasql.connect(host = session_vars['environment']['host'], \n",
    "                     user = name, \n",
    "                     password = pwd) as con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    try:\n",
    "        cur.execute('DROP TABLE demo.nltk_stopwords')\n",
    "    except Exception as e:\n",
    "        # Table already exists\n",
    "        if str(e.args).find(\"3807\") >= 1:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "    \n",
    "    qry = '''\n",
    "        CREATE TABLE demo.stop_words, \n",
    "        STORAGE = TD_NDSSTORAGE(\n",
    "         word varchar(100) CHARACTER SET LATIN\n",
    "        );\n",
    "    '''\n",
    "    cur.execute(qry)\n",
    "    \n",
    "    qry = '''{fn teradata_read_csv(nltk_stopwords.csv)} insert into Demo.stop_words (?)'''\n",
    "    cur.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "organized-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /* -------------------------------------------------------- */\n",
    "# -- Perform this as SYSDBA.\n",
    "# -- Load demo.bin_table\n",
    "# /* -------------------------------------------------------- */\n",
    "\n",
    "import teradatasql, json\n",
    "\n",
    "# load vars json\n",
    "with open('../vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "name = session_vars['hierarchy']['SYSDBA']['username']\n",
    "pwd = session_vars['hierarchy']['SYSDBA']['password']\n",
    "\n",
    "with teradatasql.connect(host = session_vars['environment']['host'], \n",
    "                     user = name, \n",
    "                     password = pwd) as con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    try:\n",
    "        cur.execute('DROP TABLE demo.bin_table')\n",
    "    except Exception as e:\n",
    "        # Table already exists\n",
    "        if str(e.args).find(\"3807\") >= 1:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "    \n",
    "    qry = '''\n",
    "        CREATE TABLE demo.bin_table, \n",
    "        STORAGE = TD_NDSSTORAGE(\n",
    "         ColumnName varchar(100) CHARACTER SET LATIN,\n",
    "         MinValue FLOAT,\n",
    "         MaxValue FLOAT,\n",
    "         Label VARCHAR(20)\n",
    "         \n",
    "        );\n",
    "    '''\n",
    "    cur.execute(qry)\n",
    "    \n",
    "    qry = '''{fn teradata_read_csv(bin_table.csv)} insert into Demo.bin_table (?,?,?,?)'''\n",
    "    cur.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-theme",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Data Loads for Numeric Regression ##\n",
    "- **demo.housing_prices_full**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "right-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /* -------------------------------------------------------- */\n",
    "# -- Perform this as SYSDBA.\n",
    "# -- Load demo.housing_prices_full\n",
    "# /* -------------------------------------------------------- */\n",
    "\n",
    "import teradatasql, json\n",
    "\n",
    "# load vars json\n",
    "with open('../vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "name = session_vars['hierarchy']['SYSDBA']['username']\n",
    "pwd = session_vars['hierarchy']['SYSDBA']['password']\n",
    "\n",
    "with teradatasql.connect(host = session_vars['environment']['host'], \n",
    "                     user = name, \n",
    "                     password = pwd) as con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    try:\n",
    "        cur.execute('DROP TABLE demo_ofs.housing_prices_full')\n",
    "    except Exception as e:\n",
    "        # Table already exists\n",
    "        if str(e.args).find(\"3807\") >= 1:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    qry = '''\n",
    "    CREATE TABLE demo_ofs.housing_prices_full,\n",
    "\n",
    "    STORAGE=TD_OFSSTORAGE\n",
    "\n",
    "         (\n",
    "          id BIGINT,\n",
    "          mssubclass BIGINT,\n",
    "          mszoning VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          lotfrontage FLOAT,\n",
    "          lotarea BIGINT,\n",
    "          street VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          alley VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          lotshape VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          landcontour VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          utilities VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          lotconfig VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          landslope VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          neighborhood VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          condition1 VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          condition2 VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          bldgtype VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          housestyle VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          overallqual BIGINT,\n",
    "          overallcond BIGINT,\n",
    "          yearbuilt BIGINT,\n",
    "          yearremodadd BIGINT,\n",
    "          roofstyle VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          roofmatl VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          exterior1st VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          exterior2nd VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          masvnrtype VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          masvnrarea FLOAT,\n",
    "          exterqual VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          extercond VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          foundation VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          bsmtqual VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          bsmtcond VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          bsmtexposure VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          bsmtfintype1 VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          bsmtfinsf1 BIGINT,\n",
    "          bsmtfintype2 VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          bsmtfinsf2 BIGINT,\n",
    "          bsmtunfsf BIGINT,\n",
    "          totalbsmtsf BIGINT,\n",
    "          heating VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          heatingqc VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          centralair VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          electrical VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          _1stflrsf BIGINT,\n",
    "          _2ndflrsf BIGINT,\n",
    "          lowqualfinsf BIGINT,\n",
    "          grlivarea BIGINT,\n",
    "          bsmtfullbath BIGINT,\n",
    "          bsmthalfbath BIGINT,\n",
    "          fullbath BIGINT,\n",
    "          halfbath BIGINT,\n",
    "          bedroomabvgr BIGINT,\n",
    "          kitchenabvgr BIGINT,\n",
    "          kitchenqual VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          totrmsabvgrd BIGINT,\n",
    "          functional VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          fireplaces BIGINT,\n",
    "          fireplacequ VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          garagetype VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          garageyrblt BIGINT,\n",
    "          garagefinish VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          garagecars BIGINT,\n",
    "          garagearea BIGINT,\n",
    "          garagequal VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          garagecond VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          paveddrive VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          wooddecksf BIGINT,\n",
    "          openporchsf BIGINT,\n",
    "          enclosedporch BIGINT,\n",
    "          _3ssnporch BIGINT,\n",
    "          screenporch BIGINT,\n",
    "          poolarea BIGINT,\n",
    "          poolqc VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          fence VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          miscfeature VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          miscval BIGINT,\n",
    "          mosold BIGINT,\n",
    "          yrsold BIGINT,\n",
    "          saletype VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          salecondition VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "          saleprice BIGINT,\n",
    "          part BIGINT)\n",
    "    ;\n",
    "    '''\n",
    "\n",
    "    cur.execute(qry)\n",
    "    \n",
    "    qry = '''{fn teradata_read_csv(housing_full_partition.csv)} insert into Demo_ofs.housing_prices_full (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)'''\n",
    "    cur.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-collaboration",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Data Loads for OAF/Data Science Demo ##\n",
    "\n",
    "- **demo_ofs.Txn_History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vocal-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /* -------------------------------------------------------- */\n",
    "# -- Perform this as SYSDBA.\n",
    "# -- Load demo_ofs.Txn_History\n",
    "# /* -------------------------------------------------------- */\n",
    "\n",
    "import teradatasql, json\n",
    "\n",
    "# load vars json\n",
    "with open('../vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "name = session_vars['hierarchy']['SYSDBA']['username']\n",
    "pwd = session_vars['hierarchy']['SYSDBA']['password']\n",
    "\n",
    "with teradatasql.connect(host = session_vars['environment']['host'], \n",
    "                     user = name, \n",
    "                     password = pwd) as con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    try:\n",
    "        cur.execute('DROP TABLE demo_ofs.Txn_History')\n",
    "    except Exception as e:\n",
    "        # Can't drop table due to BackupCount\n",
    "        if str(e.args).find(\"4880\") >= 1:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    qry = '''\n",
    "    /* Load the data into OFS directly from S3\n",
    "    */\n",
    "\n",
    "    --EXPLAIN\n",
    "    CREATE TABLE demo_ofs.Txn_History,\n",
    "\n",
    "        /*Note the use of STORAGE here to specify OFS\n",
    "        This can also be set to a user and database default */\n",
    "\n",
    "        STORAGE=TD_OFSSTORAGE\n",
    "\n",
    "        /* We can use a SELECT statement to populate the table\n",
    "        using WITH DATA */\n",
    "        AS (\n",
    "\n",
    "            /*Provide json path information to identify the proper fields */\n",
    "            SELECT Payload.txn_id txn_id,\n",
    "                Payload.step step,\n",
    "                Payload.\"type\" \"txn_type\",\n",
    "                CAST(Payload.amount AS FLOAT) amount,\n",
    "                Payload.nameOrig nameOrig,\n",
    "                CAST(Payload.oldbalanceOrig AS FLOAT) oldbalanceOrig,\n",
    "                CAST(Payload.newbalanceOrig AS FLOAT) newbalanceOrig,\n",
    "                Payload.nameDest nameDest,\n",
    "                CAST(Payload.oldbalanceDest AS FLOAT) oldbalanceDest,\n",
    "                CAST(Payload.newbalanceDest AS FLOAT) newbalanceDest,\n",
    "                CAST(Payload.isFraud AS INTEGER) isFraud,\n",
    "                CAST(Payload.isFlaggedFraud AS INTEGER) isFlaggedFraud\n",
    "\n",
    "            FROM (\n",
    "                LOCATION = '/s3/s3.amazonaws.com/trial-datasets/FraudReduction/'\n",
    "                AUTHORIZATION = Repositories.PubAuth\n",
    "    ) AS D\n",
    "    ) WITH DATA\n",
    "    '''\n",
    "    try:\n",
    "        cur.execute(qry)\n",
    "    except Exception as e:\n",
    "        # Table exists\n",
    "        if str(e.args).find(\"3803\") >= 1: \n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    qry = '''\n",
    "    /* Insert some additional rows into our OFS Table */\n",
    "    INSERT INTO demo_ofs.Txn_History\n",
    "\n",
    "            /*Provide json path information to identify the proper fields */\n",
    "            SELECT TOP 10000 Payload.txn_id txn_id,\n",
    "                Payload.step step,\n",
    "                Payload.\"type\" \"txn_type\",\n",
    "                CAST(Payload.amount AS FLOAT) amount,\n",
    "                Payload.nameOrig nameOrig,\n",
    "                CAST(Payload.oldbalanceOrig AS FLOAT) oldbalanceOrig,\n",
    "                CAST(Payload.newbalanceOrig AS FLOAT) newbalanceOrig,\n",
    "                Payload.nameDest nameDest,\n",
    "                CAST(Payload.oldbalanceDest AS FLOAT) oldbalanceDest,\n",
    "                CAST(Payload.newbalanceDest AS FLOAT) newbalanceDest,\n",
    "                CAST(Payload.isFraud AS INTEGER) isFraud,\n",
    "                CAST(Payload.isFlaggedFraud AS INTEGER) isFlaggedFraud\n",
    "\n",
    "            FROM (\n",
    "                LOCATION = '/s3/s3.amazonaws.com/trial-datasets/FraudReduction/'\n",
    "                AUTHORIZATION = Repositories.PubAuth\n",
    "    ) D\n",
    "    '''\n",
    "    cur.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-deadline",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Data Loads for KMeans Clustering Demo ##\n",
    "- **demo_ofs.UK_Retail_Data**\n",
    "\n",
    "**As of JAN-2023 drop, using Teradataml due to errors with teradatasql batch loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "soviet-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # /* -------------------------------------------------------- */\n",
    "# # -- Perform this as SYSDBA.\n",
    "# # -- Load demo_ofs.UK_Retail_Data  data\n",
    "# # /* -------------------------------------------------------- */\n",
    "\n",
    "# import teradatasql, json\n",
    "\n",
    "# # load vars json\n",
    "# with open('../vars.json', 'r') as f:\n",
    "#     session_vars = json.load(f)\n",
    "\n",
    "# name = session_vars['hierarchy']['SYSDBA']['username']\n",
    "# pwd = session_vars['hierarchy']['SYSDBA']['password']\n",
    "\n",
    "# with teradatasql.connect(host = session_vars['environment']['host'], \n",
    "#                      user = name, \n",
    "#                      password = pwd) as con:\n",
    "#     cur = con.cursor()\n",
    "    \n",
    "#     try:\n",
    "#         cur.execute('DROP TABLE Demo.UK_Retail_Data')\n",
    "#     except Exception as e:\n",
    "#         # Table already exists\n",
    "#         if str(e.args).find(\"3807\") >= 1:\n",
    "#             pass\n",
    "#         else:\n",
    "#             raise\n",
    "            \n",
    "    \n",
    "#     qry = '''\n",
    "# CREATE MULTISET TABLE demo.UK_Retail_Data, \n",
    "#     STORAGE = TD_OFSSTORAGE\n",
    "#      (\n",
    "#       InvoiceNo VARCHAR(10) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "#       StockCode VARCHAR(10) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "#       Description VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "#       Quantity BIGINT,\n",
    "#       InvoiceDate TIMESTAMP(6),\n",
    "#       UnitPrice FLOAT,\n",
    "#       CustomerID FLOAT,\n",
    "#       Country VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC);\n",
    "#     '''\n",
    "#     cur.execute(qry)\n",
    "    \n",
    "#     qry = '''{fn teradata_read_csv(UK_Retail_Data.csv)} insert into demo.UK_Retail_Data (?, ?, ?, ?, ?, ?, ?, ?)'''\n",
    "#     cur.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "genuine-movement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.2' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# /* -------------------------------------------------------- */\n",
    "# -- Perform this as SYSDBA.\n",
    "# -- Load demo_ofs.UK_Retail_Data  data\n",
    "# /* -------------------------------------------------------- */\n",
    "\n",
    "import json\n",
    "from teradataml import *\n",
    "\n",
    "# load vars json\n",
    "with open('../vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "\n",
    "name = session_vars['hierarchy']['SYSDBA']['username']\n",
    "pwd = session_vars['hierarchy']['SYSDBA']['password']\n",
    "\n",
    "eng = create_context(host = session_vars['environment']['host'], username = name, password = pwd)\n",
    "\n",
    "try:\n",
    "    eng.execute('DROP TABLE demo_ofs.UK_Retail_Data')\n",
    "except Exception as e:\n",
    "    # Table already exists\n",
    "    if str(e.args).find(\"3807\") >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "qry = '''\n",
    "CREATE MULTISET TABLE demo_ofs.UK_Retail_Data\n",
    "    --STORAGE = TD_OFSSTORAGE\n",
    "     (\n",
    "      InvoiceNo VARCHAR(10) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "      StockCode VARCHAR(10) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "      Description VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "      Quantity BIGINT,\n",
    "      InvoiceDate TIMESTAMP(6),\n",
    "      UnitPrice FLOAT,\n",
    "      CustomerID FLOAT,\n",
    "      Country VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC);\n",
    "    '''\n",
    "    \n",
    "eng.execute(qry)\n",
    "\n",
    "df = pd.read_csv('UK_Retail_Data.csv', header = None, names = ['InvoiceNo', \n",
    "                                                               'StockCode', \n",
    "                                                               'Description', \n",
    "                                                               'Quantity', \n",
    "                                                               'InvoiceDate', \n",
    "                                                               'UnitPrice', \n",
    "                                                               'CustomerID', \n",
    "                                                               'Country'])\n",
    "\n",
    "# Cast underlying datatype as string since NULLs inferred as FLOAT\n",
    "df['Description'] = df['Description'].astype(str)\n",
    "\n",
    "copy_to_sql(df.dropna(), table_name = 'UK_Retail_Data', schema_name = 'demo_ofs', if_exists = 'append')\n",
    "\n",
    "remove_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-sending",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
