{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header style=\"padding:10px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<p style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>Optimize Customer Segmentation using ClearScape Analytic Functions and Open-Source LLMs</b></p>\n",
    "</header>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b style = 'font-size:24px;font-family:Arial;color:#E37C4D'>Leverage highly-scalable native processing functions to create ideal customer segments using word embeddings and clustering algorithms</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Vector embedding</b> is a numerical representation of data that captures semantic relationships and similarities, making it possible to perform mathematical operations and comparisons on the data for various tasks like text analysis and recommendation systems.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>K-means clustering</b> is one of the most popular <b>unsupervised</b> machine learning algorithms.  Essentially, the algorithm seeks to group similar data points together by minimizing the average (\"means\" in K-means) distance for all data points from each cluster's center (centroid).</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Using <b style = 'color:#00b2b1'>Teradata Vantage</b> and <b style = 'color:#00b2b1'>ClearScape Analytics</b>, we can combine these advanced AI and ML techniques to <b>rapidly</b> find the ideal number of customer segments based on the semantic meaning of their comments history.  This segmentation can be used on its own for marketing and other tasts, or used in further predictive analytics use cases.</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '50%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial'>\n",
    "                <li>Create a Vector Embedding table using open-source LLMs applied at scale in the database</li>\n",
    "                <br>\n",
    "                <li>Rapidly iterate over multiple K-means models, evaluating each</li>\n",
    "                <br>\n",
    "                <li>Visualize the experimental results to indicate the best cluster</li>\n",
    "            </ol>\n",
    "        </td>\n",
    "        <td><img src = 'images/comparative_superlative_small.jpg' width = '250'></td>\n",
    "        <td><img src = 'images/K-means_convergence.gif' width = '250'></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(teradatasql://data_scientist:***@44.225.54.151)\n"
     ]
    }
   ],
   "source": [
    "from teradataml import *\n",
    "from teradatasqlalchemy.types import VARCHAR\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from IPython.display import display as ipydisplay\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "\n",
    "dims = [f\"v{i}\" for i in range(1, 51)]\n",
    "\n",
    "# load vars json\n",
    "with open('../../vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "# Create the SQLAlchemy Context\n",
    "host = session_vars['environment']['host']\n",
    "username = session_vars['hierarchy']['users']['business_users'][1]['username']\n",
    "password = session_vars['hierarchy']['users']['business_users'][1]['password']\n",
    "\n",
    "eng = create_context(host=host, username=username, password=password)\n",
    "\n",
    "eng.execute(f'''SET SESSION COMPUTE GROUP {session_vars['hierarchy']['users']['business_users'][1]['compute_group']}''')\n",
    "\n",
    "# confirm connection\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Step 1 - Data Preparation using an LLM to create a Vector Table</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we will inspect the original data set, and use native vector embedding functions to generate features</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Inspect the rows of the Customer Comments table</li>\n",
    "    <li>Inspect the GloVe Model table</li>\n",
    "    <li>Use TD_WordEmbeddings function to create the vector table</li>\n",
    "    </ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'>1.1 - Inspect the Data</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Simple DataFrame methods to show the data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>comment_id</th>\n",
       "\t\t<th>customer_id</th>\n",
       "\t\t<th>comment_text</th>\n",
       "\t\t<th>comment_summary</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>1080</td>\n",
       "\t\t<td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.</td>\n",
       "\t\t<td>None</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>767</td>\n",
       "\t\t<td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
       "\t\t<td>None</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "   comment_id  customer_id                                                                                                                                                                                                                                                                                                     comment_text comment_summary\n",
       "0           1         1080  Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.            None\n",
       "1           0          767                                                                                                                                                                                                                                                            Absolutely wonderful - silky and sexy and comfortable            None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tdf_comments = DataFrame('\"demo_ofs\".\"web_comment\"')\n",
    "\n",
    "ipydisplay(tdf_comments.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'>1.2 - Model table</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We format the model table as in the documentation: a column for the token, and a column for each dimension of the vector space. This example uses the GloVe 50-dimensional pre-trained embeddings. We filter out non-ASCII characters to comply with the function's requirements.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>doc_id</th>\n",
       "\t\t<th>v1</th>\n",
       "\t\t<th>v2</th>\n",
       "\t\t<th>v3</th>\n",
       "\t\t<th>v4</th>\n",
       "\t\t<th>v5</th>\n",
       "\t\t<th>v6</th>\n",
       "\t\t<th>v7</th>\n",
       "\t\t<th>v8</th>\n",
       "\t\t<th>v9</th>\n",
       "\t\t<th>v10</th>\n",
       "\t\t<th>v11</th>\n",
       "\t\t<th>v12</th>\n",
       "\t\t<th>v13</th>\n",
       "\t\t<th>v14</th>\n",
       "\t\t<th>v15</th>\n",
       "\t\t<th>v16</th>\n",
       "\t\t<th>v17</th>\n",
       "\t\t<th>v18</th>\n",
       "\t\t<th>v19</th>\n",
       "\t\t<th>v20</th>\n",
       "\t\t<th>v21</th>\n",
       "\t\t<th>v22</th>\n",
       "\t\t<th>v23</th>\n",
       "\t\t<th>v24</th>\n",
       "\t\t<th>v25</th>\n",
       "\t\t<th>v26</th>\n",
       "\t\t<th>v27</th>\n",
       "\t\t<th>v28</th>\n",
       "\t\t<th>v29</th>\n",
       "\t\t<th>v30</th>\n",
       "\t\t<th>v31</th>\n",
       "\t\t<th>v32</th>\n",
       "\t\t<th>v33</th>\n",
       "\t\t<th>v34</th>\n",
       "\t\t<th>v35</th>\n",
       "\t\t<th>v36</th>\n",
       "\t\t<th>v37</th>\n",
       "\t\t<th>v38</th>\n",
       "\t\t<th>v39</th>\n",
       "\t\t<th>v40</th>\n",
       "\t\t<th>v41</th>\n",
       "\t\t<th>v42</th>\n",
       "\t\t<th>v43</th>\n",
       "\t\t<th>v44</th>\n",
       "\t\t<th>v45</th>\n",
       "\t\t<th>v46</th>\n",
       "\t\t<th>v47</th>\n",
       "\t\t<th>v48</th>\n",
       "\t\t<th>v49</th>\n",
       "\t\t<th>v50</th>\n",
       "\t\t<th>sampleid</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>ucv</td>\n",
       "\t\t<td>-0.022189</td>\n",
       "\t\t<td>0.44481</td>\n",
       "\t\t<td>0.52391</td>\n",
       "\t\t<td>-0.14189</td>\n",
       "\t\t<td>-0.845</td>\n",
       "\t\t<td>-0.93256</td>\n",
       "\t\t<td>0.81306</td>\n",
       "\t\t<td>0.43285</td>\n",
       "\t\t<td>-0.41164</td>\n",
       "\t\t<td>0.26634</td>\n",
       "\t\t<td>0.04269</td>\n",
       "\t\t<td>0.074201</td>\n",
       "\t\t<td>1.5193</td>\n",
       "\t\t<td>0.4125</td>\n",
       "\t\t<td>-0.24922</td>\n",
       "\t\t<td>-0.28994</td>\n",
       "\t\t<td>-0.59489</td>\n",
       "\t\t<td>0.95419</td>\n",
       "\t\t<td>-0.19229</td>\n",
       "\t\t<td>1.0741</td>\n",
       "\t\t<td>-0.0029063</td>\n",
       "\t\t<td>-0.25252</td>\n",
       "\t\t<td>0.33543</td>\n",
       "\t\t<td>0.31278</td>\n",
       "\t\t<td>0.03351</td>\n",
       "\t\t<td>0.183</td>\n",
       "\t\t<td>0.40653</td>\n",
       "\t\t<td>0.33132</td>\n",
       "\t\t<td>-0.36604</td>\n",
       "\t\t<td>-0.58472</td>\n",
       "\t\t<td>-0.88902</td>\n",
       "\t\t<td>0.5033</td>\n",
       "\t\t<td>0.36401</td>\n",
       "\t\t<td>-0.027376</td>\n",
       "\t\t<td>-1.1281</td>\n",
       "\t\t<td>0.13693</td>\n",
       "\t\t<td>-0.255</td>\n",
       "\t\t<td>-0.70753</td>\n",
       "\t\t<td>0.18968</td>\n",
       "\t\t<td>-0.21943</td>\n",
       "\t\t<td>0.80443</td>\n",
       "\t\t<td>0.21876</td>\n",
       "\t\t<td>0.39038</td>\n",
       "\t\t<td>-0.52274</td>\n",
       "\t\t<td>-0.95675</td>\n",
       "\t\t<td>0.35871</td>\n",
       "\t\t<td>-0.107</td>\n",
       "\t\t<td>-0.099909</td>\n",
       "\t\t<td>-0.37285</td>\n",
       "\t\t<td>0.30371</td>\n",
       "\t\t<td>1</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>entranced</td>\n",
       "\t\t<td>0.33526</td>\n",
       "\t\t<td>-0.63793</td>\n",
       "\t\t<td>0.087276</td>\n",
       "\t\t<td>-0.88306</td>\n",
       "\t\t<td>0.46038</td>\n",
       "\t\t<td>-0.2735</td>\n",
       "\t\t<td>-0.40723</td>\n",
       "\t\t<td>0.20643</td>\n",
       "\t\t<td>-0.60165</td>\n",
       "\t\t<td>0.66712</td>\n",
       "\t\t<td>0.42047</td>\n",
       "\t\t<td>0.081288</td>\n",
       "\t\t<td>0.34458</td>\n",
       "\t\t<td>0.49505</td>\n",
       "\t\t<td>0.36456</td>\n",
       "\t\t<td>0.39566</td>\n",
       "\t\t<td>-0.27138</td>\n",
       "\t\t<td>0.77577</td>\n",
       "\t\t<td>0.18781</td>\n",
       "\t\t<td>-0.15157</td>\n",
       "\t\t<td>-0.42017</td>\n",
       "\t\t<td>0.87944</td>\n",
       "\t\t<td>0.12775</td>\n",
       "\t\t<td>0.54916</td>\n",
       "\t\t<td>1.3216</td>\n",
       "\t\t<td>0.0096211</td>\n",
       "\t\t<td>-0.73064</td>\n",
       "\t\t<td>0.47867</td>\n",
       "\t\t<td>-0.0523</td>\n",
       "\t\t<td>0.13637</td>\n",
       "\t\t<td>-0.77537</td>\n",
       "\t\t<td>0.23747</td>\n",
       "\t\t<td>1.0094</td>\n",
       "\t\t<td>-0.57026</td>\n",
       "\t\t<td>-0.37371</td>\n",
       "\t\t<td>0.052287</td>\n",
       "\t\t<td>-0.34237</td>\n",
       "\t\t<td>0.56059</td>\n",
       "\t\t<td>-0.76679</td>\n",
       "\t\t<td>-0.59283</td>\n",
       "\t\t<td>-0.084147</td>\n",
       "\t\t<td>-0.0015369</td>\n",
       "\t\t<td>-0.11245</td>\n",
       "\t\t<td>0.6495</td>\n",
       "\t\t<td>-0.088724</td>\n",
       "\t\t<td>0.14205</td>\n",
       "\t\t<td>-0.37438</td>\n",
       "\t\t<td>-0.85604</td>\n",
       "\t\t<td>-0.35605</td>\n",
       "\t\t<td>-0.45099</td>\n",
       "\t\t<td>1</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "      doc_id        v1       v2        v3       v4       v5       v6       v7       v8       v9      v10      v11       v12      v13      v14      v15      v16      v17      v18      v19      v20       v21      v22      v23      v24      v25       v26      v27      v28      v29      v30      v31      v32      v33       v34      v35       v36      v37      v38      v39      v40       v41       v42      v43      v44       v45      v46      v47       v48      v49      v50  sampleid\n",
       "0        ucv -0.022189  0.44481  0.523910 -0.14189 -0.84500 -0.93256  0.81306  0.43285 -0.41164  0.26634  0.04269  0.074201  1.51930  0.41250 -0.24922 -0.28994 -0.59489  0.95419 -0.19229  1.07410 -0.002906 -0.25252  0.33543  0.31278  0.03351  0.183000  0.40653  0.33132 -0.36604 -0.58472 -0.88902  0.50330  0.36401 -0.027376 -1.12810  0.136930 -0.25500 -0.70753  0.18968 -0.21943  0.804430  0.218760  0.39038 -0.52274 -0.956750  0.35871 -0.10700 -0.099909 -0.37285  0.30371         1\n",
       "1  entranced  0.335260 -0.63793  0.087276 -0.88306  0.46038 -0.27350 -0.40723  0.20643 -0.60165  0.66712  0.42047  0.081288  0.34458  0.49505  0.36456  0.39566 -0.27138  0.77577  0.18781 -0.15157 -0.420170  0.87944  0.12775  0.54916  1.32160  0.009621 -0.73064  0.47867 -0.05230  0.13637 -0.77537  0.23747  1.00940 -0.570260 -0.37371  0.052287 -0.34237  0.56059 -0.76679 -0.59283 -0.084147 -0.001537 -0.11245  0.64950 -0.088724  0.14205 -0.37438 -0.856040 -0.35605 -0.45099         1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(367468, 51)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tdf_glove_50d = DataFrame('\"demo_ofs\".\"glove_6B_50d\"')\n",
    "ipydisplay(tdf_glove_50d.sample(2))\n",
    "ipydisplay(tdf_glove_50d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'>1.3 - Embeddings</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>TD_WordEmbeddings can perform four operations: token-embedding, doc-embedding, token2token-similarity, and doc2doc-similarity. This notebook shows the first two.  We will use doc-embedding as the basis for our Segmentation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>comment_id</th>\n",
       "\t\t<th>TD_Token</th>\n",
       "\t\t<th>TD_TokenCount</th>\n",
       "\t\t<th>v1</th>\n",
       "\t\t<th>v2</th>\n",
       "\t\t<th>v3</th>\n",
       "\t\t<th>v4</th>\n",
       "\t\t<th>v5</th>\n",
       "\t\t<th>v6</th>\n",
       "\t\t<th>v7</th>\n",
       "\t\t<th>v8</th>\n",
       "\t\t<th>v9</th>\n",
       "\t\t<th>v10</th>\n",
       "\t\t<th>v11</th>\n",
       "\t\t<th>v12</th>\n",
       "\t\t<th>v13</th>\n",
       "\t\t<th>v14</th>\n",
       "\t\t<th>v15</th>\n",
       "\t\t<th>v16</th>\n",
       "\t\t<th>v17</th>\n",
       "\t\t<th>v18</th>\n",
       "\t\t<th>v19</th>\n",
       "\t\t<th>v20</th>\n",
       "\t\t<th>v21</th>\n",
       "\t\t<th>v22</th>\n",
       "\t\t<th>v23</th>\n",
       "\t\t<th>v24</th>\n",
       "\t\t<th>v25</th>\n",
       "\t\t<th>v26</th>\n",
       "\t\t<th>v27</th>\n",
       "\t\t<th>v28</th>\n",
       "\t\t<th>v29</th>\n",
       "\t\t<th>v30</th>\n",
       "\t\t<th>v31</th>\n",
       "\t\t<th>v32</th>\n",
       "\t\t<th>v33</th>\n",
       "\t\t<th>v34</th>\n",
       "\t\t<th>v35</th>\n",
       "\t\t<th>v36</th>\n",
       "\t\t<th>v37</th>\n",
       "\t\t<th>v38</th>\n",
       "\t\t<th>v39</th>\n",
       "\t\t<th>v40</th>\n",
       "\t\t<th>v41</th>\n",
       "\t\t<th>v42</th>\n",
       "\t\t<th>v43</th>\n",
       "\t\t<th>v44</th>\n",
       "\t\t<th>v45</th>\n",
       "\t\t<th>v46</th>\n",
       "\t\t<th>v47</th>\n",
       "\t\t<th>v48</th>\n",
       "\t\t<th>v49</th>\n",
       "\t\t<th>v50</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>and</td>\n",
       "\t\t<td>2</td>\n",
       "\t\t<td>0.26818</td>\n",
       "\t\t<td>0.14346</td>\n",
       "\t\t<td>-0.27877</td>\n",
       "\t\t<td>0.016257</td>\n",
       "\t\t<td>0.11384</td>\n",
       "\t\t<td>0.69923</td>\n",
       "\t\t<td>-0.51332</td>\n",
       "\t\t<td>-0.47368</td>\n",
       "\t\t<td>-0.33075</td>\n",
       "\t\t<td>-0.13834</td>\n",
       "\t\t<td>0.2702</td>\n",
       "\t\t<td>0.30938</td>\n",
       "\t\t<td>-0.45012</td>\n",
       "\t\t<td>-0.4127</td>\n",
       "\t\t<td>-0.09932</td>\n",
       "\t\t<td>0.038085</td>\n",
       "\t\t<td>0.029749</td>\n",
       "\t\t<td>0.10076</td>\n",
       "\t\t<td>-0.25058</td>\n",
       "\t\t<td>-0.51818</td>\n",
       "\t\t<td>0.34558</td>\n",
       "\t\t<td>0.44922</td>\n",
       "\t\t<td>0.48791</td>\n",
       "\t\t<td>-0.080866</td>\n",
       "\t\t<td>-0.10121</td>\n",
       "\t\t<td>-1.3777</td>\n",
       "\t\t<td>-0.10866</td>\n",
       "\t\t<td>-0.23201</td>\n",
       "\t\t<td>0.012839</td>\n",
       "\t\t<td>-0.46508</td>\n",
       "\t\t<td>3.8463</td>\n",
       "\t\t<td>0.31362</td>\n",
       "\t\t<td>0.13643</td>\n",
       "\t\t<td>-0.52244</td>\n",
       "\t\t<td>0.3302</td>\n",
       "\t\t<td>0.33707</td>\n",
       "\t\t<td>-0.35601</td>\n",
       "\t\t<td>0.32431</td>\n",
       "\t\t<td>0.12041</td>\n",
       "\t\t<td>0.3512</td>\n",
       "\t\t<td>-0.069043</td>\n",
       "\t\t<td>0.36885</td>\n",
       "\t\t<td>0.25168</td>\n",
       "\t\t<td>-0.24517</td>\n",
       "\t\t<td>0.25381</td>\n",
       "\t\t<td>0.1367</td>\n",
       "\t\t<td>-0.31178</td>\n",
       "\t\t<td>-0.6321</td>\n",
       "\t\t<td>-0.25028</td>\n",
       "\t\t<td>-0.38097</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>absolutely</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>0.36582</td>\n",
       "\t\t<td>-0.43975</td>\n",
       "\t\t<td>-0.35016</td>\n",
       "\t\t<td>0.096443</td>\n",
       "\t\t<td>0.99511</td>\n",
       "\t\t<td>-0.16116</td>\n",
       "\t\t<td>0.50959</td>\n",
       "\t\t<td>0.29773</td>\n",
       "\t\t<td>-0.099699</td>\n",
       "\t\t<td>0.60155</td>\n",
       "\t\t<td>-0.42716</td>\n",
       "\t\t<td>0.31336</td>\n",
       "\t\t<td>-0.77696</td>\n",
       "\t\t<td>-0.4178</td>\n",
       "\t\t<td>1.0255</td>\n",
       "\t\t<td>0.32461</td>\n",
       "\t\t<td>1.1111</td>\n",
       "\t\t<td>0.40362</td>\n",
       "\t\t<td>0.25327</td>\n",
       "\t\t<td>-0.47051</td>\n",
       "\t\t<td>-0.67384</td>\n",
       "\t\t<td>0.95534</td>\n",
       "\t\t<td>0.1788</td>\n",
       "\t\t<td>-0.16676</td>\n",
       "\t\t<td>1.1174</td>\n",
       "\t\t<td>-1.3922</td>\n",
       "\t\t<td>-1.1538</td>\n",
       "\t\t<td>0.94848</td>\n",
       "\t\t<td>1.3498</td>\n",
       "\t\t<td>-0.33948</td>\n",
       "\t\t<td>2.1633</td>\n",
       "\t\t<td>-0.085271</td>\n",
       "\t\t<td>-0.2314</td>\n",
       "\t\t<td>-0.64229</td>\n",
       "\t\t<td>-0.76036</td>\n",
       "\t\t<td>-0.33164</td>\n",
       "\t\t<td>0.75103</td>\n",
       "\t\t<td>0.11934</td>\n",
       "\t\t<td>-0.39501</td>\n",
       "\t\t<td>-0.38973</td>\n",
       "\t\t<td>-0.00025582</td>\n",
       "\t\t<td>-0.47844</td>\n",
       "\t\t<td>0.18316</td>\n",
       "\t\t<td>0.25634</td>\n",
       "\t\t<td>-0.28993</td>\n",
       "\t\t<td>0.32992</td>\n",
       "\t\t<td>-1.1011</td>\n",
       "\t\t<td>0.8687</td>\n",
       "\t\t<td>0.68687</td>\n",
       "\t\t<td>0.96048</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>comfortable</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>-0.21425</td>\n",
       "\t\t<td>0.068749</td>\n",
       "\t\t<td>-0.081586</td>\n",
       "\t\t<td>-0.27136</td>\n",
       "\t\t<td>0.99847</td>\n",
       "\t\t<td>-0.33449</td>\n",
       "\t\t<td>-0.49247</td>\n",
       "\t\t<td>0.2351</td>\n",
       "\t\t<td>-0.62932</td>\n",
       "\t\t<td>0.12907</td>\n",
       "\t\t<td>-0.45034</td>\n",
       "\t\t<td>-0.677</td>\n",
       "\t\t<td>-0.17766</td>\n",
       "\t\t<td>0.29644</td>\n",
       "\t\t<td>-0.11985</td>\n",
       "\t\t<td>0.6188</td>\n",
       "\t\t<td>0.22896</td>\n",
       "\t\t<td>-0.2552</td>\n",
       "\t\t<td>0.46635</td>\n",
       "\t\t<td>-1.182</td>\n",
       "\t\t<td>-0.74713</td>\n",
       "\t\t<td>0.92787</td>\n",
       "\t\t<td>-0.47856</td>\n",
       "\t\t<td>0.45844</td>\n",
       "\t\t<td>0.62039</td>\n",
       "\t\t<td>-0.60133</td>\n",
       "\t\t<td>0.11921</td>\n",
       "\t\t<td>0.69953</td>\n",
       "\t\t<td>0.94607</td>\n",
       "\t\t<td>0.035007</td>\n",
       "\t\t<td>2.4995</td>\n",
       "\t\t<td>1.1263</td>\n",
       "\t\t<td>0.29125</td>\n",
       "\t\t<td>0.12052</td>\n",
       "\t\t<td>0.1805</td>\n",
       "\t\t<td>-0.098443</td>\n",
       "\t\t<td>0.18226</td>\n",
       "\t\t<td>1.6886</td>\n",
       "\t\t<td>-0.31017</td>\n",
       "\t\t<td>-1.0232</td>\n",
       "\t\t<td>0.090747</td>\n",
       "\t\t<td>-0.27259</td>\n",
       "\t\t<td>0.35584</td>\n",
       "\t\t<td>1.1213</td>\n",
       "\t\t<td>-0.37477</td>\n",
       "\t\t<td>0.39062</td>\n",
       "\t\t<td>-0.43588</td>\n",
       "\t\t<td>-0.5285</td>\n",
       "\t\t<td>0.35525</td>\n",
       "\t\t<td>0.70676</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>sexy</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>-0.18216</td>\n",
       "\t\t<td>0.097173</td>\n",
       "\t\t<td>-0.91049</td>\n",
       "\t\t<td>-0.29208</td>\n",
       "\t\t<td>0.2616</td>\n",
       "\t\t<td>0.37649</td>\n",
       "\t\t<td>0.34825</td>\n",
       "\t\t<td>-0.92324</td>\n",
       "\t\t<td>-0.63641</td>\n",
       "\t\t<td>1.0532</td>\n",
       "\t\t<td>-0.15582</td>\n",
       "\t\t<td>0.22872</td>\n",
       "\t\t<td>-0.32468</td>\n",
       "\t\t<td>0.85363</td>\n",
       "\t\t<td>0.29449</td>\n",
       "\t\t<td>-0.015068</td>\n",
       "\t\t<td>-0.18929</td>\n",
       "\t\t<td>0.67549</td>\n",
       "\t\t<td>0.44233</td>\n",
       "\t\t<td>-0.63204</td>\n",
       "\t\t<td>-0.70315</td>\n",
       "\t\t<td>1.3187</td>\n",
       "\t\t<td>0.33291</td>\n",
       "\t\t<td>0.95469</td>\n",
       "\t\t<td>-0.039136</td>\n",
       "\t\t<td>-0.68223</td>\n",
       "\t\t<td>-1.5678</td>\n",
       "\t\t<td>1.1764</td>\n",
       "\t\t<td>0.84656</td>\n",
       "\t\t<td>-0.69379</td>\n",
       "\t\t<td>1.1227</td>\n",
       "\t\t<td>0.36665</td>\n",
       "\t\t<td>0.26621</td>\n",
       "\t\t<td>0.41286</td>\n",
       "\t\t<td>0.17698</td>\n",
       "\t\t<td>0.16484</td>\n",
       "\t\t<td>-0.24153</td>\n",
       "\t\t<td>0.19944</td>\n",
       "\t\t<td>-0.95562</td>\n",
       "\t\t<td>-1.4336</td>\n",
       "\t\t<td>0.2826</td>\n",
       "\t\t<td>0.33355</td>\n",
       "\t\t<td>0.4972</td>\n",
       "\t\t<td>-0.24011</td>\n",
       "\t\t<td>0.83822</td>\n",
       "\t\t<td>-0.83901</td>\n",
       "\t\t<td>0.49013</td>\n",
       "\t\t<td>-1.1877</td>\n",
       "\t\t<td>0.4906</td>\n",
       "\t\t<td>1.2877</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>wonderful</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>0.23533</td>\n",
       "\t\t<td>0.9132</td>\n",
       "\t\t<td>-1.2008</td>\n",
       "\t\t<td>0.0065595</td>\n",
       "\t\t<td>1.2843</td>\n",
       "\t\t<td>-0.10495</td>\n",
       "\t\t<td>-0.46928</td>\n",
       "\t\t<td>-0.16064</td>\n",
       "\t\t<td>-0.0023046</td>\n",
       "\t\t<td>0.88219</td>\n",
       "\t\t<td>-0.58227</td>\n",
       "\t\t<td>0.49887</td>\n",
       "\t\t<td>0.28537</td>\n",
       "\t\t<td>0.021317</td>\n",
       "\t\t<td>0.70205</td>\n",
       "\t\t<td>-0.24932</td>\n",
       "\t\t<td>0.63965</td>\n",
       "\t\t<td>0.68058</td>\n",
       "\t\t<td>-0.096489</td>\n",
       "\t\t<td>-0.69284</td>\n",
       "\t\t<td>-0.14633</td>\n",
       "\t\t<td>1.1343</td>\n",
       "\t\t<td>-0.15865</td>\n",
       "\t\t<td>-0.034477</td>\n",
       "\t\t<td>1.4644</td>\n",
       "\t\t<td>-0.46223</td>\n",
       "\t\t<td>-1.3821</td>\n",
       "\t\t<td>0.45211</td>\n",
       "\t\t<td>0.9922</td>\n",
       "\t\t<td>-0.55959</td>\n",
       "\t\t<td>2.0021</td>\n",
       "\t\t<td>0.54034</td>\n",
       "\t\t<td>-0.080539</td>\n",
       "\t\t<td>-0.021476</td>\n",
       "\t\t<td>0.026856</td>\n",
       "\t\t<td>0.42905</td>\n",
       "\t\t<td>-0.1189</td>\n",
       "\t\t<td>0.69764</td>\n",
       "\t\t<td>-0.029882</td>\n",
       "\t\t<td>-0.58077</td>\n",
       "\t\t<td>0.20491</td>\n",
       "\t\t<td>0.095888</td>\n",
       "\t\t<td>-0.39682</td>\n",
       "\t\t<td>-0.18709</td>\n",
       "\t\t<td>0.21904</td>\n",
       "\t\t<td>0.57694</td>\n",
       "\t\t<td>0.066142</td>\n",
       "\t\t<td>-0.16162</td>\n",
       "\t\t<td>-0.02467</td>\n",
       "\t\t<td>0.84626</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>silky</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>-0.26831</td>\n",
       "\t\t<td>-0.13454</td>\n",
       "\t\t<td>-1.8179</td>\n",
       "\t\t<td>0.36332</td>\n",
       "\t\t<td>0.34287</td>\n",
       "\t\t<td>0.84508</td>\n",
       "\t\t<td>0.20526</td>\n",
       "\t\t<td>-0.42332</td>\n",
       "\t\t<td>0.46929</td>\n",
       "\t\t<td>0.17958</td>\n",
       "\t\t<td>0.27243</td>\n",
       "\t\t<td>0.37917</td>\n",
       "\t\t<td>0.56063</td>\n",
       "\t\t<td>0.20263</td>\n",
       "\t\t<td>-1.2165</td>\n",
       "\t\t<td>-0.43508</td>\n",
       "\t\t<td>-0.02032</td>\n",
       "\t\t<td>0.057007</td>\n",
       "\t\t<td>-0.093196</td>\n",
       "\t\t<td>-1.3579</td>\n",
       "\t\t<td>-1.5306</td>\n",
       "\t\t<td>0.69662</td>\n",
       "\t\t<td>0.62579</td>\n",
       "\t\t<td>-0.53322</td>\n",
       "\t\t<td>-0.0063314</td>\n",
       "\t\t<td>0.56397</td>\n",
       "\t\t<td>-0.049352</td>\n",
       "\t\t<td>1.4671</td>\n",
       "\t\t<td>0.26434</td>\n",
       "\t\t<td>-0.51571</td>\n",
       "\t\t<td>0.79537</td>\n",
       "\t\t<td>-0.052818</td>\n",
       "\t\t<td>0.26291</td>\n",
       "\t\t<td>0.85787</td>\n",
       "\t\t<td>0.16713</td>\n",
       "\t\t<td>0.028354</td>\n",
       "\t\t<td>-0.89476</td>\n",
       "\t\t<td>0.52989</td>\n",
       "\t\t<td>-0.42234</td>\n",
       "\t\t<td>-0.85901</td>\n",
       "\t\t<td>0.60424</td>\n",
       "\t\t<td>0.30946</td>\n",
       "\t\t<td>-0.16478</td>\n",
       "\t\t<td>0.26658</td>\n",
       "\t\t<td>0.54582</td>\n",
       "\t\t<td>-0.48803</td>\n",
       "\t\t<td>0.67927</td>\n",
       "\t\t<td>-0.38916</td>\n",
       "\t\t<td>-0.46679</td>\n",
       "\t\t<td>0.2561</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "   comment_id     TD_Token  TD_TokenCount       v1        v2        v3        v4       v5       v6       v7       v8        v9      v10      v11      v12      v13       v14      v15       v16       v17       v18       v19      v20      v21      v22      v23       v24       v25      v26       v27      v28       v29       v30      v31       v32       v33       v34       v35       v36      v37      v38       v39      v40       v41       v42      v43      v44      v45      v46       v47      v48      v49      v50\n",
       "0           0          and              2  0.26818  0.143460 -0.278770  0.016257  0.11384  0.69923 -0.51332 -0.47368 -0.330750 -0.13834  0.27020  0.30938 -0.45012 -0.412700 -0.09932  0.038085  0.029749  0.100760 -0.250580 -0.51818  0.34558  0.44922  0.48791 -0.080866 -0.101210 -1.37770 -0.108660 -0.23201  0.012839 -0.465080  3.84630  0.313620  0.136430 -0.522440  0.330200  0.337070 -0.35601  0.32431  0.120410  0.35120 -0.069043  0.368850  0.25168 -0.24517  0.25381  0.13670 -0.311780 -0.63210 -0.25028 -0.38097\n",
       "1           0   absolutely              1  0.36582 -0.439750 -0.350160  0.096443  0.99511 -0.16116  0.50959  0.29773 -0.099699  0.60155 -0.42716  0.31336 -0.77696 -0.417800  1.02550  0.324610  1.111100  0.403620  0.253270 -0.47051 -0.67384  0.95534  0.17880 -0.166760  1.117400 -1.39220 -1.153800  0.94848  1.349800 -0.339480  2.16330 -0.085271 -0.231400 -0.642290 -0.760360 -0.331640  0.75103  0.11934 -0.395010 -0.38973 -0.000256 -0.478440  0.18316  0.25634 -0.28993  0.32992 -1.101100  0.86870  0.68687  0.96048\n",
       "2           0         sexy              1 -0.18216  0.097173 -0.910490 -0.292080  0.26160  0.37649  0.34825 -0.92324 -0.636410  1.05320 -0.15582  0.22872 -0.32468  0.853630  0.29449 -0.015068 -0.189290  0.675490  0.442330 -0.63204 -0.70315  1.31870  0.33291  0.954690 -0.039136 -0.68223 -1.567800  1.17640  0.846560 -0.693790  1.12270  0.366650  0.266210  0.412860  0.176980  0.164840 -0.24153  0.19944 -0.955620 -1.43360  0.282600  0.333550  0.49720 -0.24011  0.83822 -0.83901  0.490130 -1.18770  0.49060  1.28770\n",
       "3           0  comfortable              1 -0.21425  0.068749 -0.081586 -0.271360  0.99847 -0.33449 -0.49247  0.23510 -0.629320  0.12907 -0.45034 -0.67700 -0.17766  0.296440 -0.11985  0.618800  0.228960 -0.255200  0.466350 -1.18200 -0.74713  0.92787 -0.47856  0.458440  0.620390 -0.60133  0.119210  0.69953  0.946070  0.035007  2.49950  1.126300  0.291250  0.120520  0.180500 -0.098443  0.18226  1.68860 -0.310170 -1.02320  0.090747 -0.272590  0.35584  1.12130 -0.37477  0.39062 -0.435880 -0.52850  0.35525  0.70676\n",
       "4           0    wonderful              1  0.23533  0.913200 -1.200800  0.006560  1.28430 -0.10495 -0.46928 -0.16064 -0.002305  0.88219 -0.58227  0.49887  0.28537  0.021317  0.70205 -0.249320  0.639650  0.680580 -0.096489 -0.69284 -0.14633  1.13430 -0.15865 -0.034477  1.464400 -0.46223 -1.382100  0.45211  0.992200 -0.559590  2.00210  0.540340 -0.080539 -0.021476  0.026856  0.429050 -0.11890  0.69764 -0.029882 -0.58077  0.204910  0.095888 -0.39682 -0.18709  0.21904  0.57694  0.066142 -0.16162 -0.02467  0.84626\n",
       "5           0        silky              1 -0.26831 -0.134540 -1.817900  0.363320  0.34287  0.84508  0.20526 -0.42332  0.469290  0.17958  0.27243  0.37917  0.56063  0.202630 -1.21650 -0.435080 -0.020320  0.057007 -0.093196 -1.35790 -1.53060  0.69662  0.62579 -0.533220 -0.006331  0.56397 -0.049352  1.46710  0.264340 -0.515710  0.79537 -0.052818  0.262910  0.857870  0.167130  0.028354 -0.89476  0.52989 -0.422340 -0.85901  0.604240  0.309460 -0.16478  0.26658  0.54582 -0.48803  0.679270 -0.38916 -0.46679  0.25610"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordEmbeddings(\n",
    "    data=tdf_comments.head(1),\n",
    "    model=DataFrame(\"glove_6B_50d\"),\n",
    "    id_column=\"comment_id\",\n",
    "    model_text_column=\"doc_id\",\n",
    "    model_vector_columns=dims,\n",
    "    primary_column=\"comment_text\",\n",
    "    operation=\"token-embedding\"\n",
    "    ).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>comment_id</th>\n",
       "\t\t<th>v1</th>\n",
       "\t\t<th>v2</th>\n",
       "\t\t<th>v3</th>\n",
       "\t\t<th>v4</th>\n",
       "\t\t<th>v5</th>\n",
       "\t\t<th>v6</th>\n",
       "\t\t<th>v7</th>\n",
       "\t\t<th>v8</th>\n",
       "\t\t<th>v9</th>\n",
       "\t\t<th>v10</th>\n",
       "\t\t<th>v11</th>\n",
       "\t\t<th>v12</th>\n",
       "\t\t<th>v13</th>\n",
       "\t\t<th>v14</th>\n",
       "\t\t<th>v15</th>\n",
       "\t\t<th>v16</th>\n",
       "\t\t<th>v17</th>\n",
       "\t\t<th>v18</th>\n",
       "\t\t<th>v19</th>\n",
       "\t\t<th>v20</th>\n",
       "\t\t<th>v21</th>\n",
       "\t\t<th>v22</th>\n",
       "\t\t<th>v23</th>\n",
       "\t\t<th>v24</th>\n",
       "\t\t<th>v25</th>\n",
       "\t\t<th>v26</th>\n",
       "\t\t<th>v27</th>\n",
       "\t\t<th>v28</th>\n",
       "\t\t<th>v29</th>\n",
       "\t\t<th>v30</th>\n",
       "\t\t<th>v31</th>\n",
       "\t\t<th>v32</th>\n",
       "\t\t<th>v33</th>\n",
       "\t\t<th>v34</th>\n",
       "\t\t<th>v35</th>\n",
       "\t\t<th>v36</th>\n",
       "\t\t<th>v37</th>\n",
       "\t\t<th>v38</th>\n",
       "\t\t<th>v39</th>\n",
       "\t\t<th>v40</th>\n",
       "\t\t<th>v41</th>\n",
       "\t\t<th>v42</th>\n",
       "\t\t<th>v43</th>\n",
       "\t\t<th>v44</th>\n",
       "\t\t<th>v45</th>\n",
       "\t\t<th>v46</th>\n",
       "\t\t<th>v47</th>\n",
       "\t\t<th>v48</th>\n",
       "\t\t<th>v49</th>\n",
       "\t\t<th>v50</th>\n",
       "\t\t<th>comment_text</th>\n",
       "\t\t<th>customer_id</th>\n",
       "\t\t<th>sampleid</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>160</td>\n",
       "\t\t<td>0.18649992941176458</td>\n",
       "\t\t<td>0.1381223117647059</td>\n",
       "\t\t<td>-0.14518482329411764</td>\n",
       "\t\t<td>-0.17033232588235292</td>\n",
       "\t\t<td>0.4924078823529411</td>\n",
       "\t\t<td>0.1266697529411765</td>\n",
       "\t\t<td>-0.22457151882352946</td>\n",
       "\t\t<td>-0.10956805294117651</td>\n",
       "\t\t<td>-0.19954282294117648</td>\n",
       "\t\t<td>-0.12467671482352943</td>\n",
       "\t\t<td>0.0012475999999999971</td>\n",
       "\t\t<td>0.09972123764705886</td>\n",
       "\t\t<td>-0.366763211764706</td>\n",
       "\t\t<td>0.030452901176470537</td>\n",
       "\t\t<td>0.35111699411764713</td>\n",
       "\t\t<td>0.37506626470588234</td>\n",
       "\t\t<td>0.0490888705882353</td>\n",
       "\t\t<td>0.00016377764705882244</td>\n",
       "\t\t<td>-0.31176063411764704</td>\n",
       "\t\t<td>-0.5686542235294115</td>\n",
       "\t\t<td>-0.06987224705882353</td>\n",
       "\t\t<td>0.13327040941176474</td>\n",
       "\t\t<td>0.12429368941176462</td>\n",
       "\t\t<td>-0.02644435082352942</td>\n",
       "\t\t<td>0.1393320352941177</td>\n",
       "\t\t<td>-1.542058398823529</td>\n",
       "\t\t<td>-0.48209997294117646</td>\n",
       "\t\t<td>0.4537561529411765</td>\n",
       "\t\t<td>0.42994752705882355</td>\n",
       "\t\t<td>-0.41906450941176465</td>\n",
       "\t\t<td>2.9625996</td>\n",
       "\t\t<td>0.2490074</td>\n",
       "\t\t<td>-0.2195969882352941</td>\n",
       "\t\t<td>-0.08694030588235295</td>\n",
       "\t\t<td>0.00883266435294118</td>\n",
       "\t\t<td>0.0716945823529412</td>\n",
       "\t\t<td>0.07125201176470587</td>\n",
       "\t\t<td>0.18453883058823528</td>\n",
       "\t\t<td>0.057990901176470544</td>\n",
       "\t\t<td>-0.32578476470588236</td>\n",
       "\t\t<td>-0.06037704235294119</td>\n",
       "\t\t<td>0.12713582588235298</td>\n",
       "\t\t<td>-0.044505708235294164</td>\n",
       "\t\t<td>0.1490522289411764</td>\n",
       "\t\t<td>-0.06504272941176473</td>\n",
       "\t\t<td>0.06700453176470585</td>\n",
       "\t\t<td>0.10986651882352941</td>\n",
       "\t\t<td>-0.2738920470588236</td>\n",
       "\t\t<td>-0.014398082352941174</td>\n",
       "\t\t<td>-0.10726456235294118</td>\n",
       "\t\t<td>Love everything about this beautiful coat except the way it fits on me.  it is just perfect in the shoulders but once it flares out at the bottom, i look like a clown costume.  if i size down it will not fit in my shoulders.  perhaps a tailor can install buckles that match the neckline buckle to the sides of the coat to fold in the flare.  on another note the buckle at the neckline feels very hard and fake, not sure if it's real leather.</td>\n",
       "\t\t<td>1126</td>\n",
       "\t\t<td>1</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>340</td>\n",
       "\t\t<td>0.24744045945945944</td>\n",
       "\t\t<td>0.2369031405405405</td>\n",
       "\t\t<td>-0.02899770270270271</td>\n",
       "\t\t<td>-0.024747354054054052</td>\n",
       "\t\t<td>0.47118845945945953</td>\n",
       "\t\t<td>0.10218305405405408</td>\n",
       "\t\t<td>-0.39652302972972975</td>\n",
       "\t\t<td>-0.3486041270270271</td>\n",
       "\t\t<td>0.0049582454054054054</td>\n",
       "\t\t<td>-0.08788071432432427</td>\n",
       "\t\t<td>0.06866605405405408</td>\n",
       "\t\t<td>0.04331103243243244</td>\n",
       "\t\t<td>-0.15532181081081076</td>\n",
       "\t\t<td>-0.05748424324324325</td>\n",
       "\t\t<td>0.3311527027027027</td>\n",
       "\t\t<td>0.18108415675675676</td>\n",
       "\t\t<td>-0.06536105135135135</td>\n",
       "\t\t<td>-0.0033889459459459496</td>\n",
       "\t\t<td>-0.34089732972972975</td>\n",
       "\t\t<td>-0.5306248648648649</td>\n",
       "\t\t<td>0.1252006216216216</td>\n",
       "\t\t<td>-0.037033024324324315</td>\n",
       "\t\t<td>0.31915072972972974</td>\n",
       "\t\t<td>0.003051513513513507</td>\n",
       "\t\t<td>-0.045488648648648655</td>\n",
       "\t\t<td>-1.3271846216216217</td>\n",
       "\t\t<td>-0.37852594594594596</td>\n",
       "\t\t<td>0.29493367567567574</td>\n",
       "\t\t<td>0.3557702432432433</td>\n",
       "\t\t<td>-0.30499364864864864</td>\n",
       "\t\t<td>3.3765864864864863</td>\n",
       "\t\t<td>-0.017899905405405432</td>\n",
       "\t\t<td>-0.12094256756756762</td>\n",
       "\t\t<td>-0.2718735675675676</td>\n",
       "\t\t<td>0.07203261945945946</td>\n",
       "\t\t<td>0.11953644864864868</td>\n",
       "\t\t<td>0.11536871081081083</td>\n",
       "\t\t<td>0.28871675675675673</td>\n",
       "\t\t<td>-0.0611638108108108</td>\n",
       "\t\t<td>-0.2623387027027027</td>\n",
       "\t\t<td>0.10018477567567569</td>\n",
       "\t\t<td>-0.01939732432432432</td>\n",
       "\t\t<td>0.09124229729729731</td>\n",
       "\t\t<td>0.11225381081081082</td>\n",
       "\t\t<td>-0.07799627027027028</td>\n",
       "\t\t<td>0.121074</td>\n",
       "\t\t<td>-0.015311637837837835</td>\n",
       "\t\t<td>-0.1921174324324324</td>\n",
       "\t\t<td>0.00733383783783783</td>\n",
       "\t\t<td>-0.05573537837837839</td>\n",
       "\t\t<td>Ordered the shirt online. beautiful print and good quality material. runs very large - size down 1 may be 2 sizes as the material on the body is very wide. i will be exchanging it in the store.</td>\n",
       "\t\t<td>844</td>\n",
       "\t\t<td>1</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "   comment_id       v1        v2        v3        v4        v5        v6        v7        v8        v9       v10       v11       v12       v13       v14       v15       v16       v17       v18       v19       v20       v21       v22       v23       v24       v25       v26       v27       v28       v29       v30       v31       v32       v33       v34       v35       v36       v37       v38       v39       v40       v41       v42       v43       v44       v45       v46       v47       v48       v49       v50                                                                                                                                                                                                                                                                                                                                                                                                                                               comment_text  customer_id  sampleid\n",
       "0         160  0.18650  0.138122 -0.145185 -0.170332  0.492408  0.126670 -0.224572 -0.109568 -0.199543 -0.124677  0.001248  0.099721 -0.366763  0.030453  0.351117  0.375066  0.049089  0.000164 -0.311761 -0.568654 -0.069872  0.133270  0.124294 -0.026444  0.139332 -1.542058 -0.482100  0.453756  0.429948 -0.419065  2.962600  0.249007 -0.219597 -0.086940  0.008833  0.071695  0.071252  0.184539  0.057991 -0.325785 -0.060377  0.127136 -0.044506  0.149052 -0.065043  0.067005  0.109867 -0.273892 -0.014398 -0.107265  Love everything about this beautiful coat except the way it fits on me.  it is just perfect in the shoulders but once it flares out at the bottom, i look like a clown costume.  if i size down it will not fit in my shoulders.  perhaps a tailor can install buckles that match the neckline buckle to the sides of the coat to fold in the flare.  on another note the buckle at the neckline feels very hard and fake, not sure if it's real leather.         1126         1\n",
       "1         340  0.24744  0.236903 -0.028998 -0.024747  0.471188  0.102183 -0.396523 -0.348604  0.004958 -0.087881  0.068666  0.043311 -0.155322 -0.057484  0.331153  0.181084 -0.065361 -0.003389 -0.340897 -0.530625  0.125201 -0.037033  0.319151  0.003052 -0.045489 -1.327185 -0.378526  0.294934  0.355770 -0.304994  3.376586 -0.017900 -0.120943 -0.271874  0.072033  0.119536  0.115369  0.288717 -0.061164 -0.262339  0.100185 -0.019397  0.091242  0.112254 -0.077996  0.121074 -0.015312 -0.192117  0.007334 -0.055735                                                                                                                                                                                                                                                          Ordered the shirt online. beautiful print and good quality material. runs very large - size down 1 may be 2 sizes as the material on the body is very wide. i will be exchanging it in the store.          844         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf_embeddings = WordEmbeddings(\n",
    "                data=tdf_comments.iloc[:1000],\n",
    "                model=DataFrame(\"glove_6B_50d\"),\n",
    "                id_column=\"comment_id\",\n",
    "                model_text_column=\"doc_id\",\n",
    "                model_vector_columns=dims,\n",
    "                primary_column=\"comment_text\",\n",
    "                operation=\"doc-embedding\",\n",
    "                accumulate=['comment_text', 'customer_id']\n",
    "                ).result\n",
    "copy_to_sql(tdf_embeddings, table_name = 'comments_embedded', if_exists = 'replace')\n",
    "tdf_embeddings = DataFrame('comments_embedded')\n",
    "tdf_embeddings.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Step 2 - Find the Ideal K-means Model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>As discussed above, the K-means algorithm takes a number of clusters \"k\", chooses a random starting point for each centroid, and iterates until a hard limit or an optimium value is reached.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Other Function Parameters Include (but are not limited to)</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Input dataframe</li>\n",
    "    <li>StopThreshold - The algorithm converges if the distance between the centroids from the previous iteration and the current iteration is less than the specified value.</li>\n",
    "    <li>MaxIterNum</li>Specify the maximum number of iterations for the K-means algorithm. The algorithm stops after performing the specified number of iterations even if the convergence criterion is not met.\n",
    "    </ul>\n",
    "    \n",
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'>1.1 - Example Model - 4-cluster test</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The example below uses an arbitrary number of clusters to create the first model.  Note the output metadata provides information such as the number of iterations, converged or not, etc.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>td_withinss_kmeans</th>\n",
       "      <th>td_modelinfo_kmeans</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>td_clusterid_kmeans</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>81.976225</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>129.716516</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>104.739689</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td></td>\n",
       "      <td>Number of Iterations : 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td></td>\n",
       "      <td>Total_WithinSS : 3.16432430370140E+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td></td>\n",
       "      <td>Between_SS : 6.39009068661489E+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td></td>\n",
       "      <td>Method for InitialCentroids : Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td></td>\n",
       "      <td>Number of Clusters : 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td></td>\n",
       "      <td>Converged : True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    td_withinss_kmeans                    td_modelinfo_kmeans\n",
       "td_clusterid_kmeans                                                          \n",
       "0.0                                0.0                                       \n",
       "1.0                          81.976225                                       \n",
       "2.0                         129.716516                                       \n",
       "3.0                         104.739689                                       \n",
       "NaN                                                  Number of Iterations : 8\n",
       "NaN                                     Total_WithinSS : 3.16432430370140E+02\n",
       "NaN                                         Between_SS : 6.39009068661489E+02\n",
       "NaN                                      Method for InitialCentroids : Random\n",
       "NaN                                                    Number of Clusters : 4\n",
       "NaN                                                          Converged : True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KMeans(data = tdf_embeddings, \n",
    "        id_column = 'comment_id', \n",
    "        target_columns = dims, \n",
    "        num_clusters = 4, \n",
    "        iter_max = 100, \n",
    "        threshold=0.0295).result.to_pandas()[['td_withinss_kmeans', 'td_modelinfo_kmeans']].fillna('').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'>2.2 - Finding an Ideal value for K</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '50%'>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Typically, data scientists will build the model using various values for \"k\", and plot the \"WCSS\" (Within Cluster Sum-of-Squares) value on a series of each value chosen for k.  The \"elbow\" point (where the slope changes) is usually a good value for k.  <a href = 'https://docs.teradata.com/r/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Model-Training-Functions/TD_KMeans'>KMeans</a> function will return this value as \"TotalWithinSS : ###\" as a row in the \"td_modelinfo_kmeans\" column.</p>\n",
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the below example, we will iterate over this function using values from 2 to 8 for \"k\".  Due to the highly-scalable nature of the native training function, we can perform this analysis incredibly rapidly.</p>\n",
    "        </td>\n",
    "        <td><img src = 'images/WCSS_elbow.png' width = '300'></td>\n",
    "    </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 clusters, WCSS = 391.6025566020835\n",
      "3 clusters, WCSS = 337.3253945025208\n",
      "4 clusters, WCSS = 315.4733292457968\n",
      "5 clusters, WCSS = 304.2086745509382\n",
      "6 clusters, WCSS = 297.04374324964283\n",
      "7 clusters, WCSS = 289.9330039186299\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for k in range(2,9):\n",
    "    kmeans_model = KMeans(data = tdf_embeddings, \n",
    "                        id_column = 'comment_id', \n",
    "                        target_columns = dims, \n",
    "                        num_clusters = k, \n",
    "                        iter_max = 100, \n",
    "                        threshold=0.0295)\n",
    "    wss = kmeans_model.result.to_pandas()[['td_withinss_kmeans']].sum()[0]\n",
    "    a.append([k, wss])\n",
    "    print(f'{str(k)} clusters, WCSS = {str(wss)}')\n",
    "\n",
    "df = pd.DataFrame(a, columns = ['k', 'WCSS']).set_index('k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Step 3 - Find the ideal number of Customer Segments</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>A simple plot will show the \"elbow\" point indicating an ideal number of clusters or segments.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Conclusion</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>From our simple demonstration above, we can see how data practitioners can rapidly derive powerful and unique predictive features by combining the latest AI with traditional Machine Learning <b>at scale</b>.  Furthermore, we can easily operationalize this process by combining this vector embedding and segmentation into traditional Customer 360, analytics, or additional predicitve modeling tasks - all on the same platform.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Cleanup</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_drop_table('comments_embedded')\n",
    "remove_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
